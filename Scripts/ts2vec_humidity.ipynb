{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TS2Vec + Humidity for Hand Washing Detection (Frozen TS2Vec — like Biobank_humidity)\n",
        "\n",
        "Uses **TS2Vec** (self-supervised time series representations) for IMU windows and the **same humidity handcrafted features** as Biobank_humidity, then trains a classifier on the concatenated representation.\n",
        "\n",
        "**Pipeline (aligned with Biobank_humidity.ipynb):**\n",
        "- Same data: `data/` and `new_data/`, labels from `lables/`, **clean_humidity** applied.\n",
        "- Same windowing: window_size=500, step_size=250; IMU (acc_x, acc_y, acc_z) + humidity per window.\n",
        "- Per window: (1) **TS2Vec** encodes the IMU time series → fixed-size embedding. (2) **advanced_humid_features** (11 stats) computed from the window’s humidity. (3) Concatenate [humid_features * 2, ts2vec_embedding], scale, optional augment + SMOTETomek, then train the same MLP (focal loss, class weights).\n",
        "- LOSO, same excluded_subjects; medfilt on predictions; accuracy and F1 per subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from glob import glob\n",
        "from scipy.signal import find_peaks, medfilt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, GaussianNoise\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from ts2vec import TS2Vec\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = \"/Users/sonalimanoharan/Desktop/scientific_research/hw\"\n",
        "data_folders = [\"data\", \"new_data\"]\n",
        "label_files = [\"labels.csv\", \"lables_new.csv\"]\n",
        "save_model_path = os.path.join(base_path, \"ts2vec_saved_model\")\n",
        "os.makedirs(save_model_path, exist_ok=True)\n",
        "\n",
        "window_size = 500\n",
        "step_size = 250\n",
        "imu_cols = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
        "humid_col = [\"humid\"]\n",
        "REPR_DIMS = 128\n",
        "TS2VEC_EPOCHS = 50\n",
        "humidity_weight = 2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_humidity(df):\n",
        "    if \"humid\" in df.columns:\n",
        "        artifact_value = 79.1318359375\n",
        "        df = df.copy()\n",
        "        df[\"humid\"] = df[\"humid\"].replace(artifact_value, np.nan)\n",
        "        df[\"humid\"] = df[\"humid\"].interpolate(method='linear', limit_direction='both')\n",
        "        df[\"humid\"] = df[\"humid\"].ffill().bfill()\n",
        "    return df\n",
        "\n",
        "def load_recs():\n",
        "    all_dfs = []\n",
        "    for data_folder, label_file in zip(data_folders, label_files):\n",
        "        data_path = os.path.join(base_path, data_folder, \"*.csv\")\n",
        "        label_path = os.path.join(base_path, \"lables\", os.path.basename(label_file))\n",
        "        for fname in glob(data_path):\n",
        "            df = pd.read_csv(fname)\n",
        "            df = clean_humidity(df)\n",
        "            subject_id_full = os.path.basename(fname).replace(\".csv\", \"\")\n",
        "            all_dfs.append((fname, df, label_path, subject_id_full, data_folder))\n",
        "    return all_dfs\n",
        "\n",
        "def convert_to_binlabel(x):\n",
        "    return 0 if x in [\"Null\", \"dry\"] else 1\n",
        "\n",
        "def apply_labels(dfs):\n",
        "    l_dfs = []\n",
        "    for fname, df, label_path, subject_id, folder in dfs:\n",
        "        label_df = pd.read_csv(label_path)\n",
        "        label_df[\"filename\"] = label_df[\"datetime\"].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "        file_basename = os.path.basename(fname).strip()\n",
        "        matched_row = label_df[label_df[\"filename\"].apply(lambda x: x.endswith(file_basename))]\n",
        "        if matched_row.empty:\n",
        "            continue\n",
        "        df = df.copy()\n",
        "        df[\"label\"] = \"Null\"\n",
        "        label_info = json.loads(matched_row.iloc[0][\"label\"])\n",
        "        for d in label_info:\n",
        "            df.loc[d[\"start\"]:d[\"end\"], \"label\"] = d[\"timeserieslabels\"][0]\n",
        "        df[\"binlabel\"] = df[\"label\"].apply(convert_to_binlabel)\n",
        "        df[\"subject\"] = subject_id\n",
        "        df[\"source_folder\"] = folder\n",
        "        l_dfs.append(df)\n",
        "    return l_dfs\n",
        "\n",
        "def advanced_humid_features(humid):\n",
        "    humid = pd.Series(humid)\n",
        "    diff = humid.diff().fillna(0)\n",
        "    peaks, _ = find_peaks(humid, height=55)\n",
        "    return np.array([\n",
        "        np.mean(humid), np.std(humid),\n",
        "        np.max(humid), np.min(humid),\n",
        "        np.median(humid), np.sum(humid > 50),\n",
        "        humid.iloc[-1] - humid.iloc[0],\n",
        "        np.percentile(humid, 90) - np.percentile(humid, 10),\n",
        "        np.mean(diff), np.std(diff),\n",
        "        len(peaks)\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "def create_windows(df, window_size, step_size):\n",
        "    \"\"\"Returns (X_imu_windows, humid_features, labels). Same structure as Biobank_humidity but IMU raw for TS2Vec.\"\"\"\n",
        "    imu_windows, humid_features, labels = [], [], []\n",
        "    for start in range(0, len(df) - window_size + 1, step_size):\n",
        "        window = df.iloc[start:start + window_size]\n",
        "        if not all(c in window.columns for c in imu_cols):\n",
        "            continue\n",
        "        imu = window[imu_cols].values.astype(np.float32)\n",
        "        if \"humid\" in window.columns:\n",
        "            humid = window[\"humid\"].values.squeeze()\n",
        "            hf = advanced_humid_features(humid)\n",
        "        else:\n",
        "            hf = np.zeros(11, dtype=np.float32)\n",
        "        label_mode = window[\"binlabel\"].mode()\n",
        "        lab = label_mode.iloc[0] if not label_mode.empty else int(window[\"binlabel\"].iloc[0])\n",
        "        imu_windows.append(imu)\n",
        "        humid_features.append(hf)\n",
        "        labels.append(lab)\n",
        "    if not imu_windows:\n",
        "        return np.zeros((0, window_size, len(imu_cols)), dtype=np.float32), np.zeros((0, 11), dtype=np.float32), np.array([], dtype=np.int64)\n",
        "    return np.stack(imu_windows, axis=0), np.stack(humid_features, axis=0), np.array(labels, dtype=np.int64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def augment_data(X, y, humid_dim, augment_ratio=0.5):\n",
        "    \"\"\"Augment class 1 only; humid_dim = number of humidity features (first columns).\"\"\"\n",
        "    X_aug, y_aug = [], []\n",
        "    for i in range(len(X)):\n",
        "        if y[i] != 1:\n",
        "            continue\n",
        "        x_sample = X[i]\n",
        "        repr_part = x_sample[humid_dim:].copy()\n",
        "        humid_part = x_sample[:humid_dim]\n",
        "        if np.random.rand() < augment_ratio:\n",
        "            repr_part += np.random.normal(0, 0.01, size=repr_part.shape)\n",
        "        X_aug.append(np.concatenate([humid_part, repr_part]))\n",
        "        y_aug.append(y[i])\n",
        "    return np.array(X_aug), np.array(y_aug).reshape(-1, 1)\n",
        "\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        eps = 1e-7\n",
        "        y_pred = tf.clip_by_value(y_pred, eps, 1.0 - eps)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        return -tf.reduce_mean(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
        "    return loss\n",
        "\n",
        "def build_model(input_dim):\n",
        "    inp = Input(shape=(input_dim,))\n",
        "    x = GaussianNoise(0.1)(inp)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inp, x)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4), loss=focal_loss(), metrics=[\"accuracy\"])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 18 subjects (after exclusions)\n"
          ]
        }
      ],
      "source": [
        "all_dfs = load_recs()\n",
        "labeled_dfs = apply_labels(all_dfs)\n",
        "excluded_subjects = {\n",
        "    \"2025-01-18-22-38-29_37959204-490b-4cd9-b647-94e743071951\",\n",
        "    \"2025-01-28-21-43-21_e4380fee-3c78-4e38-936f-acd60513e279\"\n",
        "}\n",
        "filtered_dfs = [df for df in labeled_dfs if df[\"subject\"].iloc[0] not in excluded_subjects]\n",
        "subjects = sorted(set(df[\"subject\"].iloc[0] for df in filtered_dfs))\n",
        "print(f\"Found {len(subjects)} subjects (after exclusions)\")\n",
        "results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretraining TS2Vec on 12927 IMU windows (all subjects) ...\n"
          ]
        }
      ],
      "source": [
        "# Build per-subject windows once, then pretrain TS2Vec on all IMU data (frozen encoder)\n",
        "subject_windows = {}\n",
        "for df in filtered_dfs:\n",
        "    sid = df[\"subject\"].iloc[0]\n",
        "    if sid not in subject_windows:\n",
        "        subject_windows[sid] = {\"imu\": [], \"humid\": [], \"y\": []}\n",
        "    imu_w, humid_f, label = create_windows(df, window_size, step_size)\n",
        "    subject_windows[sid][\"imu\"].append(imu_w)\n",
        "    subject_windows[sid][\"humid\"].append(humid_f)\n",
        "    subject_windows[sid][\"y\"].append(label)\n",
        "\n",
        "for sid in subject_windows:\n",
        "    subject_windows[sid][\"imu\"] = np.concatenate(subject_windows[sid][\"imu\"], axis=0)\n",
        "    subject_windows[sid][\"humid\"] = np.concatenate(subject_windows[sid][\"humid\"], axis=0)\n",
        "    subject_windows[sid][\"y\"] = np.concatenate(subject_windows[sid][\"y\"], axis=0)\n",
        "\n",
        "X_all_imu = np.concatenate([subject_windows[s][\"imu\"] for s in subjects], axis=0)\n",
        "print(f\"Pretraining TS2Vec on {X_all_imu.shape[0]} IMU windows (all subjects) ...\")\n",
        "\n",
        "use_gpu = bool(tf.config.list_physical_devices(\"GPU\"))\n",
        "device_ts2vec = 0 if use_gpu else 'cpu'\n",
        "ts2vec_model = TS2Vec(\n",
        "    input_dims=X_all_imu.shape[2],\n",
        "    output_dims=REPR_DIMS,\n",
        "    device=device_ts2vec,\n",
        "    batch_size=32,\n",
        ")\n",
        "ts2vec_model.fit(X_all_imu, n_epochs=TS2VEC_EPOCHS, verbose=True)\n",
        "print(\"TS2Vec pretrained and frozen. LOSO will use encode() only.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LOSO: frozen TS2Vec — encode only; train MLP on [humid_features * weight, ts2vec_embedding]\n",
        "for subject in subjects:\n",
        "    print(f\"\\nLOSO fold — test subject: {subject}\")\n",
        "    train_subs = [s for s in subjects if s != subject]\n",
        "    X_train_imu = np.concatenate([subject_windows[s][\"imu\"] for s in train_subs], axis=0)\n",
        "    X_train_humid = np.concatenate([subject_windows[s][\"humid\"] for s in train_subs], axis=0)\n",
        "    y_train = np.concatenate([subject_windows[s][\"y\"] for s in train_subs], axis=0)\n",
        "    X_test_imu = subject_windows[subject][\"imu\"]\n",
        "    X_test_humid = subject_windows[subject][\"humid\"]\n",
        "    y_test = subject_windows[subject][\"y\"]\n",
        "\n",
        "    if X_train_imu.shape[0] < 2 or X_test_imu.shape[0] == 0:\n",
        "        print(\"  Skipping: not enough data.\")\n",
        "        results.append({\"subject\": subject, \"accuracy\": np.nan, \"f1_score\": np.nan})\n",
        "        continue\n",
        "\n",
        "    # Frozen TS2Vec: encode only (no training)\n",
        "    train_repr = ts2vec_model.encode(X_train_imu, encoding_window='full_series')\n",
        "    test_repr = ts2vec_model.encode(X_test_imu, encoding_window='full_series')\n",
        "\n",
        "    # Same concatenation as Biobank_humidity: [humid_features * weight, imu_repr]\n",
        "    X_train_humid_scaled = X_train_humid * humidity_weight\n",
        "    X_test_humid_scaled = X_test_humid * humidity_weight\n",
        "    X_train = np.concatenate([X_train_humid_scaled, train_repr], axis=1)\n",
        "    X_test = np.concatenate([X_test_humid_scaled, test_repr], axis=1)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    humid_dim = X_train_humid.shape[1]\n",
        "    y_train_2d = y_train.reshape(-1, 1)\n",
        "    X_aug, y_aug = augment_data(X_train, y_train, humid_dim=humid_dim)\n",
        "    X_train = np.vstack([X_train, X_aug])\n",
        "    y_train_2d = np.vstack([y_train_2d, y_aug])\n",
        "\n",
        "    X_train, y_train_2d = SMOTETomek(random_state=42).fit_resample(X_train, y_train_2d.flatten())\n",
        "    y_train_2d = y_train_2d.reshape(-1, 1)\n",
        "\n",
        "    cw = compute_class_weight(\"balanced\", classes=np.unique(y_train_2d), y=y_train_2d.flatten())\n",
        "    class_weight_dict = {i: float(cw[i]) for i in range(len(cw))}\n",
        "\n",
        "    model = build_model(X_train.shape[1])\n",
        "    model.fit(X_train, y_train_2d, validation_data=(X_test, y_test.reshape(-1, 1)), epochs=50, batch_size=32,\n",
        "              class_weight=class_weight_dict,\n",
        "              callbacks=[EarlyStopping(patience=5, restore_best_weights=True)], verbose=0)\n",
        "\n",
        "    y_pred_prob = model.predict(X_test, verbose=0)\n",
        "    y_pred_raw = (y_pred_prob > 0.5).astype(\"int32\").flatten()\n",
        "    y_pred = medfilt(y_pred_raw, kernel_size=3)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    results.append({\"subject\": subject, \"accuracy\": acc, \"f1_score\": f1})\n",
        "    print(f\"{subject} - Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TS2Vec + Humidity — LOSO Summary (frozen TS2Vec, MLP only per fold)\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string())\n",
        "valid = results_df.dropna(subset=[\"f1_score\"])\n",
        "if len(valid) > 0:\n",
        "    print(f\"\\nMean Accuracy: {valid['accuracy'].mean():.4f}\")\n",
        "    print(f\"Mean F1:      {valid['f1_score'].mean():.4f}\")\n",
        "out_path = os.path.join(save_model_path, \"TS2Vec_Humidity_frozen.csv\")\n",
        "results_df.to_csv(out_path, index=False)\n",
        "print(f\"\\nResults saved to {out_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hw (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
