{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TS2Vec IMU-Only for Hand Washing Detection (Frozen TS2Vec — like Biobank_nohumidity)\n",
        "\n",
        "Uses **TS2Vec** as a **frozen feature extractor** (analogous to Biobank_nohumidity's frozen HarNet): pretrain TS2Vec once on all IMU windows, then LOSO with **encode only** and train the MLP classifier per fold.\n",
        "\n",
        "**Pipeline (aligned with Biobank_nohumidity.ipynb):**\n",
        "- Same data: `data/` and `new_data/`, labels from `lables/` (no humidity).\n",
        "- Same windowing: window_size=500, step_size=250; IMU (acc_x, acc_y, acc_z) only.\n",
        "- **Step 1 (once):** Pretrain TS2Vec on all subjects' IMU windows; freeze.\n",
        "- **Step 2 (LOSO):** Encode train/test IMU windows with frozen TS2Vec; scale, augment, SMOTETomek, train MLP (focal loss, class weights); medfilt; accuracy and F1 per subject.\n",
        "\n",
        "Reduces runtime (~90%) vs training TS2Vec per fold; embeddings consistent across folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-23 09:49:25.194238: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/Users/sonalimanoharan/Desktop/scientific_research/hw/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from glob import glob\n",
        "from scipy.signal import medfilt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, GaussianNoise\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from ts2vec import TS2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = \"/Users/sonalimanoharan/Desktop/scientific_research/hw\"\n",
        "data_folders = [\"data\", \"new_data\"]\n",
        "label_files = [\"labels.csv\", \"lables_new.csv\"]\n",
        "save_model_path = os.path.join(base_path, \"ts2vec_no_humid_saved_model\")\n",
        "os.makedirs(save_model_path, exist_ok=True)\n",
        "\n",
        "window_size = 500\n",
        "step_size = 250\n",
        "imu_cols = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
        "REPR_DIMS = 128\n",
        "TS2VEC_EPOCHS = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_recs():\n",
        "    all_dfs = []\n",
        "    for data_folder, label_file in zip(data_folders, label_files):\n",
        "        data_path = os.path.join(base_path, data_folder, \"*.csv\")\n",
        "        label_path = os.path.join(base_path, \"lables\", label_file)\n",
        "        for fname in glob(data_path):\n",
        "            df = pd.read_csv(fname)\n",
        "            subject_id_full = os.path.basename(fname).replace(\".csv\", \"\")\n",
        "            all_dfs.append((fname, df, label_path, subject_id_full, data_folder))\n",
        "    return all_dfs\n",
        "\n",
        "def convert_to_binlabel(x):\n",
        "    return 0 if x in [\"Null\", \"dry\"] else 1\n",
        "\n",
        "def apply_labels(dfs):\n",
        "    l_dfs = []\n",
        "    for fname, df, label_path, subject_id, folder in dfs:\n",
        "        label_df = pd.read_csv(label_path)\n",
        "        label_df[\"filename\"] = label_df[\"datetime\"].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "        file_basename = os.path.basename(fname).strip()\n",
        "        matched_row = label_df[label_df[\"filename\"].apply(lambda x: x.endswith(file_basename))]\n",
        "        if matched_row.empty:\n",
        "            continue\n",
        "        df = df.copy()\n",
        "        df[\"label\"] = \"Null\"\n",
        "        label_info = json.loads(matched_row.iloc[0][\"label\"])\n",
        "        for d in label_info:\n",
        "            df.loc[d[\"start\"]:d[\"end\"], \"label\"] = d[\"timeserieslabels\"][0]\n",
        "        df[\"binlabel\"] = df[\"label\"].apply(convert_to_binlabel)\n",
        "        df[\"subject\"] = subject_id\n",
        "        df[\"source_folder\"] = folder\n",
        "        l_dfs.append(df)\n",
        "    return l_dfs\n",
        "\n",
        "def create_windows(df, window_size, step_size):\n",
        "    \"\"\"Returns (X_imu_windows, labels). X_imu: (n_windows, window_size, 3).\"\"\"\n",
        "    imu_list, labels_list = [], []\n",
        "    for start in range(0, len(df) - window_size + 1, step_size):\n",
        "        window = df.iloc[start:start + window_size]\n",
        "        if not all(c in window.columns for c in imu_cols):\n",
        "            continue\n",
        "        imu = window[imu_cols].values.astype(np.float32)\n",
        "        label_mode = window[\"binlabel\"].mode()\n",
        "        lab = label_mode.iloc[0] if not label_mode.empty else int(window[\"binlabel\"].iloc[0])\n",
        "        imu_list.append(imu)\n",
        "        labels_list.append(lab)\n",
        "    if not imu_list:\n",
        "        return np.zeros((0, window_size, len(imu_cols)), dtype=np.float32), np.array([], dtype=np.int64)\n",
        "    return np.stack(imu_list, axis=0), np.array(labels_list, dtype=np.int64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def augment_data(X, y, augment_ratio=0.5):\n",
        "    X_aug, y_aug = [], []\n",
        "    for i in range(len(X)):\n",
        "        if y[i] != 1:\n",
        "            continue\n",
        "        x_sample = X[i].copy()\n",
        "        if np.random.rand() < augment_ratio:\n",
        "            x_sample += np.random.normal(0, 0.01, size=x_sample.shape)\n",
        "        X_aug.append(x_sample)\n",
        "        y_aug.append(y[i])\n",
        "    return np.array(X_aug), np.array(y_aug).reshape(-1, 1)\n",
        "\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def loss(y_true, y_pred):\n",
        "        eps = 1e-7\n",
        "        y_pred = tf.clip_by_value(y_pred, eps, 1.0 - eps)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        return -tf.reduce_mean(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
        "    return loss\n",
        "\n",
        "def build_model(input_dim):\n",
        "    inp = Input(shape=(input_dim,))\n",
        "    x = GaussianNoise(0.1)(inp)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inp, x)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4), loss=focal_loss(), metrics=[\"accuracy\"])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 18 subjects (after exclusions)\n"
          ]
        }
      ],
      "source": [
        "all_dfs = load_recs()\n",
        "labeled_dfs = apply_labels(all_dfs)\n",
        "excluded_subjects = {\n",
        "    \"2025-01-18-22-38-29_37959204-490b-4cd9-b647-94e743071951\",\n",
        "    \"2025-01-28-21-43-21_e4380fee-3c78-4e38-936f-acd60513e279\"\n",
        "}\n",
        "filtered_dfs = [df for df in labeled_dfs if df[\"subject\"].iloc[0] not in excluded_subjects]\n",
        "subjects = sorted(set(df[\"subject\"].iloc[0] for df in filtered_dfs))\n",
        "print(f\"Found {len(subjects)} subjects (after exclusions)\")\n",
        "results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretraining TS2Vec on 12927 IMU windows (all subjects)...\n",
            "Epoch #0: loss=1540103.5995851427\n",
            "Epoch #1: loss=62571.509940097705\n",
            "Epoch #2: loss=29661.719871956422\n",
            "Epoch #3: loss=18496.4987811143\n",
            "Epoch #4: loss=12272.1525557828\n",
            "Epoch #5: loss=9758.31838360732\n",
            "Epoch #6: loss=8171.321866397527\n",
            "Epoch #7: loss=6561.42717036775\n",
            "Epoch #8: loss=6152.3666428786055\n",
            "Epoch #9: loss=4369.973463186259\n",
            "Epoch #10: loss=3548.5105368185873\n",
            "Epoch #11: loss=3859.325684502462\n",
            "Epoch #12: loss=4262.947236697668\n",
            "Epoch #13: loss=1910.1906137016808\n",
            "Epoch #14: loss=3071.276322054804\n",
            "Epoch #15: loss=3497.343320936482\n",
            "Epoch #16: loss=1635.3494913938914\n",
            "Epoch #17: loss=958.3393998441862\n",
            "Epoch #18: loss=2905.6886720113066\n",
            "Epoch #19: loss=511.04151269046605\n",
            "Epoch #20: loss=1613.8868663021117\n",
            "Epoch #21: loss=336.650642413951\n",
            "Epoch #22: loss=618.5409828356419\n",
            "Epoch #23: loss=1707.9568300838803\n",
            "Epoch #24: loss=310.3280966406129\n",
            "Epoch #25: loss=739.1338213975022\n",
            "Epoch #26: loss=132.2578472109054\n",
            "Epoch #27: loss=210.08313178542826\n",
            "Epoch #28: loss=1231.4873206183572\n",
            "Epoch #29: loss=149.37935814490686\n",
            "Epoch #30: loss=61.89639392975838\n",
            "Epoch #31: loss=126.59793247005189\n",
            "Epoch #32: loss=226.57541610111966\n",
            "Epoch #33: loss=26.187568501266593\n",
            "Epoch #34: loss=43.403302213985924\n",
            "Epoch #35: loss=105.17004778367414\n",
            "Epoch #36: loss=9.094459564455095\n",
            "Epoch #37: loss=7.439213507228691\n",
            "Epoch #38: loss=16.51687658750094\n",
            "Epoch #39: loss=401.4037903337266\n",
            "Epoch #40: loss=15.19222149718784\n",
            "Epoch #41: loss=5.958472637621404\n",
            "Epoch #42: loss=4.083056766401153\n",
            "Epoch #43: loss=3.4994602818642893\n",
            "Epoch #44: loss=3.004933479110301\n",
            "Epoch #45: loss=3.1291094536225197\n",
            "Epoch #46: loss=4.036894024453743\n",
            "Epoch #47: loss=2.681797176081844\n",
            "Epoch #48: loss=2.598139707858746\n",
            "Epoch #49: loss=311.4789652916101\n",
            "TS2Vec pretrained and frozen. LOSO will use encode() only.\n"
          ]
        }
      ],
      "source": [
        "# Build per-subject windows once; pretrain TS2Vec on all IMU data (frozen encoder)\n",
        "subject_windows = {}\n",
        "for df in filtered_dfs:\n",
        "    sid = df[\"subject\"].iloc[0]\n",
        "    if sid not in subject_windows:\n",
        "        subject_windows[sid] = {\"imu\": [], \"y\": []}\n",
        "    imu_w, label = create_windows(df, window_size, step_size)\n",
        "    subject_windows[sid][\"imu\"].append(imu_w)\n",
        "    subject_windows[sid][\"y\"].append(label)\n",
        "\n",
        "for sid in subject_windows:\n",
        "    subject_windows[sid][\"imu\"] = np.concatenate(subject_windows[sid][\"imu\"], axis=0)\n",
        "    subject_windows[sid][\"y\"] = np.concatenate(subject_windows[sid][\"y\"], axis=0)\n",
        "\n",
        "X_all_imu = np.concatenate([subject_windows[s][\"imu\"] for s in subjects], axis=0)\n",
        "print(f\"Pretraining TS2Vec on {X_all_imu.shape[0]} IMU windows (all subjects)...\")\n",
        "\n",
        "use_gpu = bool(tf.config.list_physical_devices(\"GPU\"))\n",
        "device_ts2vec = 0 if use_gpu else 'cpu'\n",
        "ts2vec_model = TS2Vec(\n",
        "    input_dims=X_all_imu.shape[2],\n",
        "    output_dims=REPR_DIMS,\n",
        "    device=device_ts2vec,\n",
        "    batch_size=32,\n",
        ")\n",
        "ts2vec_model.fit(X_all_imu, n_epochs=TS2VEC_EPOCHS, verbose=True)\n",
        "print(\"TS2Vec pretrained and frozen. LOSO will use encode() only.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "LOSO fold — test subject: 2024-12-04-18-49-30_c5c72868-633a-4672-8bdd-3a457f994ddb\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sonalimanoharan/Desktop/scientific_research/hw/lib/python3.12/site-packages/threadpoolctl.py:1226: RuntimeWarning: \n",
            "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
            "the same time. Both libraries are known to be incompatible and this\n",
            "can cause random crashes or deadlocks on Linux when loaded in the\n",
            "same Python program.\n",
            "Using threadpoolctl may cause crashes or deadlocks. For more\n",
            "information and possible workarounds, please see\n",
            "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
            "\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.9168, F1: 0.5455\n",
            "\n",
            "LOSO fold — test subject: 2024-12-08-21-41-18_c1291a19-92af-431e-9608-6044389d26b0\n",
            "  Accuracy: 0.9170, F1: 0.6503\n",
            "\n",
            "LOSO fold — test subject: 2024-12-10-19-42-27_4734a243-b638-4004-aa82-c698f3ef7aba\n",
            "  Accuracy: 0.8945, F1: 0.4737\n",
            "\n",
            "LOSO fold — test subject: 2025-01-18-13-08-43_449ee30d-3245-47ca-9769-752cf0d2edb7\n",
            "  Accuracy: 0.9344, F1: 0.5155\n",
            "\n",
            "LOSO fold — test subject: 2025-01-19-18-41-39_c4d73c9a-93b2-4c1b-9f76-492d76f7731d\n",
            "  Accuracy: 0.8419, F1: 0.2553\n",
            "\n",
            "LOSO fold — test subject: 2025-01-19-19-48-01_c2031779-881c-4c5c-9c6e-b3f4d57601a9\n",
            "  Accuracy: 0.8597, F1: 0.1803\n",
            "\n",
            "LOSO fold — test subject: 34414785-1f38-4ff1-a709-e3bd0f5e7d42\n",
            "  Accuracy: 0.9771, F1: 0.7385\n",
            "\n",
            "LOSO fold — test subject: 383ea87a-3396-400b-9497-ee6f9ad7c093\n",
            "  Accuracy: 0.9733, F1: 0.6429\n",
            "\n",
            "LOSO fold — test subject: 6c516a60-1d5e-4d7c-a1dd-158099033fe7\n",
            "  Accuracy: 0.9676, F1: 0.6914\n",
            "\n",
            "LOSO fold — test subject: 8bb7b2a8-0d9b-4aaa-ad3a-c15fedb2ad31\n",
            "  Accuracy: 0.9733, F1: 0.6429\n",
            "\n",
            "LOSO fold — test subject: 8f0ce2c4-d123-4c1c-aac2-61844abfa8ca\n",
            "  Accuracy: 0.9845, F1: 0.8267\n",
            "\n",
            "LOSO fold — test subject: Participant_1_Data_4\n",
            "  Accuracy: 0.8578, F1: 0.3333\n",
            "\n",
            "LOSO fold — test subject: Participant_3_Data_1\n",
            "  Accuracy: 0.8946, F1: 0.2667\n",
            "\n",
            "LOSO fold — test subject: a43187d2-c663-42c5-8da5-750dbb9b72bd\n",
            "  Accuracy: 0.9794, F1: 0.7742\n",
            "\n",
            "LOSO fold — test subject: ab0a6b0c-b0f2-4bda-8806-a4e39175f027\n",
            "  Accuracy: 0.9905, F1: 0.7879\n",
            "\n",
            "LOSO fold — test subject: ebc39e6c-2770-4821-a747-c174a7855b30\n",
            "  Accuracy: 0.9676, F1: 0.5556\n",
            "\n",
            "LOSO fold — test subject: ebff48bd-b1c8-44e3-af35-0941b6c405b1\n",
            "  Accuracy: 0.9723, F1: 0.5714\n",
            "\n",
            "LOSO fold — test subject: fa94190b-92d3-484c-8133-744b797dfc81\n",
            "  Accuracy: 0.9626, F1: 0.5625\n"
          ]
        }
      ],
      "source": [
        "# LOSO: frozen TS2Vec — encode only; train MLP on embeddings (same flow as Biobank_nohumidity)\n",
        "for subject in subjects:\n",
        "    print(f\"\\nLOSO fold — test subject: {subject}\")\n",
        "    train_subs = [s for s in subjects if s != subject]\n",
        "    X_train_imu = np.concatenate([subject_windows[s][\"imu\"] for s in train_subs], axis=0)\n",
        "    y_train = np.concatenate([subject_windows[s][\"y\"] for s in train_subs], axis=0)\n",
        "    X_test_imu = subject_windows[subject][\"imu\"]\n",
        "    y_test = subject_windows[subject][\"y\"]\n",
        "\n",
        "    if X_train_imu.shape[0] < 2 or X_test_imu.shape[0] == 0:\n",
        "        print(\"  Skipping: not enough data.\")\n",
        "        results.append({\"subject\": subject, \"accuracy\": np.nan, \"f1_score\": np.nan})\n",
        "        continue\n",
        "\n",
        "    # Frozen TS2Vec: encode only\n",
        "    train_repr = ts2vec_model.encode(X_train_imu, encoding_window='full_series')\n",
        "    test_repr = ts2vec_model.encode(X_test_imu, encoding_window='full_series')\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(train_repr)\n",
        "    X_test = scaler.transform(test_repr)\n",
        "\n",
        "    y_train_2d = y_train.reshape(-1, 1)\n",
        "    X_aug, y_aug = augment_data(X_train, y_train)\n",
        "    X_train = np.vstack([X_train, X_aug])\n",
        "    y_train_2d = np.vstack([y_train_2d, y_aug])\n",
        "\n",
        "    X_train, y_flat = SMOTETomek(random_state=42).fit_resample(X_train, y_train_2d.flatten())\n",
        "    y_train_2d = y_flat.reshape(-1, 1)\n",
        "\n",
        "    cw = compute_class_weight(\"balanced\", classes=np.unique(y_train_2d), y=y_train_2d.flatten())\n",
        "    class_weight_dict = {i: float(cw[i]) for i in range(len(cw))}\n",
        "\n",
        "    model = build_model(X_train.shape[1])\n",
        "    model.fit(X_train, y_train_2d, validation_data=(X_test, y_test.reshape(-1, 1)), epochs=50, batch_size=32,\n",
        "              class_weight=class_weight_dict,\n",
        "              callbacks=[EarlyStopping(patience=5, restore_best_weights=True)], verbose=0)\n",
        "\n",
        "    y_pred_prob = model.predict(X_test, verbose=0)\n",
        "    y_pred_raw = (y_pred_prob > 0.5).astype(\"int32\").flatten()\n",
        "    y_pred = medfilt(y_pred_raw, kernel_size=3)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    results.append({\"subject\": subject, \"accuracy\": acc, \"f1_score\": f1})\n",
        "    print(f\"  Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TS2Vec IMU-Only — LOSO Summary (frozen TS2Vec, MLP only per fold)\n",
            "============================================================\n",
            "                                                     subject  accuracy  f1_score\n",
            "0   2024-12-04-18-49-30_c5c72868-633a-4672-8bdd-3a457f994ddb  0.916805  0.545455\n",
            "1   2024-12-08-21-41-18_c1291a19-92af-431e-9608-6044389d26b0  0.917031  0.650307\n",
            "2   2024-12-10-19-42-27_4734a243-b638-4004-aa82-c698f3ef7aba  0.894459  0.473684\n",
            "3   2025-01-18-13-08-43_449ee30d-3245-47ca-9769-752cf0d2edb7  0.934449  0.515464\n",
            "4   2025-01-19-18-41-39_c4d73c9a-93b2-4c1b-9f76-492d76f7731d  0.841867  0.255319\n",
            "5   2025-01-19-19-48-01_c2031779-881c-4c5c-9c6e-b3f4d57601a9  0.859748  0.180328\n",
            "6                       34414785-1f38-4ff1-a709-e3bd0f5e7d42  0.977058  0.738462\n",
            "7                       383ea87a-3396-400b-9497-ee6f9ad7c093  0.973262  0.642857\n",
            "8                       6c516a60-1d5e-4d7c-a1dd-158099033fe7  0.967617  0.691358\n",
            "9                       8bb7b2a8-0d9b-4aaa-ad3a-c15fedb2ad31  0.973262  0.642857\n",
            "10                      8f0ce2c4-d123-4c1c-aac2-61844abfa8ca  0.984542  0.826667\n",
            "11                                      Participant_1_Data_4  0.857805  0.333333\n",
            "12                                      Participant_3_Data_1  0.894569  0.266667\n",
            "13                      a43187d2-c663-42c5-8da5-750dbb9b72bd  0.979442  0.774194\n",
            "14                      ab0a6b0c-b0f2-4bda-8806-a4e39175f027  0.990502  0.787879\n",
            "15                      ebc39e6c-2770-4821-a747-c174a7855b30  0.967568  0.555556\n",
            "16                      ebff48bd-b1c8-44e3-af35-0941b6c405b1  0.972259  0.571429\n",
            "17                      fa94190b-92d3-484c-8133-744b797dfc81  0.962617  0.562500\n",
            "\n",
            "Mean Accuracy: 0.9369\n",
            "Mean F1:      0.5564\n",
            "\n",
            "Results saved to /Users/sonalimanoharan/Desktop/scientific_research/hw/ts2vec_no_humid_saved_model/TS2Vec_IMU_Only_frozen.csv\n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TS2Vec IMU-Only — LOSO Summary (frozen TS2Vec, MLP only per fold)\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string())\n",
        "valid = results_df.dropna(subset=[\"f1_score\"])\n",
        "if len(valid) > 0:\n",
        "    print(f\"\\nMean Accuracy: {valid['accuracy'].mean():.4f}\")\n",
        "    print(f\"Mean F1:      {valid['f1_score'].mean():.4f}\")\n",
        "out_path = os.path.join(save_model_path, \"TS2Vec_IMU_Only_frozen.csv\")\n",
        "results_df.to_csv(out_path, index=False)\n",
        "print(f\"\\nResults saved to {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hw (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
