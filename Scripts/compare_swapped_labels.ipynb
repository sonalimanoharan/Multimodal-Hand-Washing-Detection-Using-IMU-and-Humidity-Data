{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-20 19:27:29.942870: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/Users/sonalimanoharan/Desktop/scientific_research/hw/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout,\n",
        "    BatchNormalization, Concatenate\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from scipy.signal import medfilt\n",
        "from glob import glob\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = \"/Users/sonalimanoharan/Desktop/scientific_research/hw\"\n",
        "data_folders = [\"data\", \"new_data\"]\n",
        "label_files = [\"lables/labels.csv\", \"lables/lables_new.csv\"]\n",
        "save_model_path = os.path.join(base_path, \"fair_model_swapped_labels\")\n",
        "os.makedirs(save_model_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAMPLING_RATE = 50\n",
        "WINDOW_DURATION = 3\n",
        "WINDOW_SIZE = int(SAMPLING_RATE * WINDOW_DURATION)\n",
        "STEP_SIZE = WINDOW_SIZE // 2\n",
        "MIN_DURATION_SAMPLES = int(1.0 * SAMPLING_RATE)\n",
        "FIXED_THRESHOLD = 0.5\n",
        "VAL_FRACTION = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_humidity(df):\n",
        "    if \"humid\" in df.columns:\n",
        "        artifact_value = 79.1318359375\n",
        "        df[\"humid\"] = df[\"humid\"].replace(artifact_value, np.nan)\n",
        "        df[\"humid\"] = df[\"humid\"].interpolate(method='linear', limit_direction='both')\n",
        "        df[\"humid\"] = df[\"humid\"].ffill().bfill()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_recs():\n",
        "    all_dfs = []\n",
        "    for data_folder, label_file in zip(data_folders, label_files):\n",
        "        data_path = os.path.join(base_path, data_folder, \"*.csv\")\n",
        "        label_path = os.path.join(base_path, label_file)\n",
        "        for fname in glob(data_path):\n",
        "            df = pd.read_csv(fname)\n",
        "            df = clean_humidity(df)\n",
        "            subject_id = os.path.basename(fname).replace(\".csv\", \"\")\n",
        "            all_dfs.append((fname, df, label_path, subject_id))\n",
        "    return all_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def convert_to_binlabel(x):\n",
        "    return 1 if x in [\"Null\", \"dry\"] else 0\n",
        "\n",
        "def apply_labels(dfs):\n",
        "    l_dfs = []\n",
        "    for fname, df, label_path, subject_id in dfs:\n",
        "        label_df = pd.read_csv(label_path)\n",
        "        label_df[\"filename\"] = label_df[\"datetime\"].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "        file_basename = os.path.basename(fname).strip()\n",
        "        matched_row = label_df[label_df[\"filename\"].apply(lambda x: x.endswith(file_basename))]\n",
        "        if matched_row.empty:\n",
        "            continue\n",
        "        df[\"label\"] = \"Null\"\n",
        "        label_info = json.loads(matched_row.iloc[0][\"label\"])\n",
        "        for d in label_info:\n",
        "            df.loc[d[\"start\"]:d[\"end\"], \"label\"] = d[\"timeserieslabels\"][0]\n",
        "        df[\"binlabel\"] = df[\"label\"].apply(convert_to_binlabel)\n",
        "        df[\"subject\"] = subject_id\n",
        "        l_dfs.append(df)\n",
        "    return l_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_binlabel(x):\n",
        "    return 1 if x in [\"Null\", \"dry\"] else 0\n",
        "\n",
        "def apply_labels(dfs):\n",
        "    l_dfs = []\n",
        "    for fname, df, label_path, subject_id in dfs:\n",
        "        label_df = pd.read_csv(label_path)\n",
        "        label_df[\"filename\"] = label_df[\"datetime\"].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "        file_basename = os.path.basename(fname).strip()\n",
        "        matched_row = label_df[label_df[\"filename\"].apply(lambda x: x.endswith(file_basename))]\n",
        "        if matched_row.empty:\n",
        "            continue\n",
        "        df[\"label\"] = \"Null\"\n",
        "        label_info = json.loads(matched_row.iloc[0][\"label\"])\n",
        "        for d in label_info:\n",
        "            df.loc[d[\"start\"]:d[\"end\"], \"label\"] = d[\"timeserieslabels\"][0]\n",
        "        df[\"binlabel\"] = df[\"label\"].apply(convert_to_binlabel)\n",
        "        df[\"subject\"] = subject_id\n",
        "        l_dfs.append(df)\n",
        "    return l_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_magnitude_features(window):\n",
        "    acc_mag = np.sqrt(window[\"acc_x\"]**2 + window[\"acc_y\"]**2 + window[\"acc_z\"]**2)\n",
        "    gyro_mag = np.sqrt(window[\"gyro_x\"]**2 + window[\"gyro_y\"]**2 + window[\"gyro_z\"]**2)\n",
        "    features = [np.mean(acc_mag), np.std(acc_mag), np.min(acc_mag), np.max(acc_mag),\n",
        "                np.mean(gyro_mag), np.std(gyro_mag), np.min(gyro_mag), np.max(gyro_mag)]\n",
        "    return np.column_stack([acc_mag, gyro_mag]), np.array(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_humidity_slope(window):\n",
        "    if \"humid\" not in window.columns:\n",
        "        return np.zeros(5)\n",
        "    humid = window[\"humid\"].values\n",
        "    if len(humid) < 2:\n",
        "        return np.zeros(5)\n",
        "    slope = np.diff(humid)\n",
        "    return np.array([np.mean(slope), np.std(slope), np.max(slope), np.min(slope), humid[-1] - humid[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_windows(df, window_size, step_size):\n",
        "    magnitude_sequences, magnitude_features, humidity_features, labels = [], [], [], []\n",
        "    for start in range(0, len(df) - window_size + 1, step_size):\n",
        "        window = df.iloc[start:start + window_size]\n",
        "        mag_seq, mag_feat = extract_magnitude_features(window)\n",
        "        magnitude_sequences.append(mag_seq)\n",
        "        magnitude_features.append(mag_feat)\n",
        "        humidity_features.append(extract_humidity_slope(window))\n",
        "        label_mode = window[\"binlabel\"].mode()\n",
        "        labels.append(label_mode.iloc[0] if not label_mode.empty else int(window[\"binlabel\"].iloc[0]))\n",
        "    return (np.array(magnitude_sequences), np.array(magnitude_features), np.array(humidity_features), np.array(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        eps = 1e-7\n",
        "        y_pred = tf.clip_by_value(y_pred, eps, 1.0 - eps)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        return -tf.reduce_mean(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
        "    return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_cnn_lstm_model(sequence_shape, feature_dim):\n",
        "    seq_input = Input(shape=sequence_shape, name='magnitude_sequences')\n",
        "    x = Conv1D(64, kernel_size=5, activation='relu', padding='same')(seq_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv1D(64, kernel_size=5, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = LSTM(128, return_sequences=True)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = LSTM(64, return_sequences=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    cnn_lstm_output = Dropout(0.3)(x)\n",
        "    feat_input = Input(shape=(feature_dim,), name='handcrafted_features')\n",
        "    feat_dense = Dense(64, activation='relu')(feat_input)\n",
        "    feat_dense = BatchNormalization()(feat_dense)\n",
        "    feat_output = Dropout(0.3)(feat_dense)\n",
        "    combined = Concatenate()([cnn_lstm_output, feat_output])\n",
        "    combined = Dense(128, activation='relu')(combined)\n",
        "    combined = BatchNormalization()(combined)\n",
        "    combined = Dropout(0.4)(combined)\n",
        "    combined = Dense(64, activation='relu')(combined)\n",
        "    output = Dense(1, activation='sigmoid')(combined)\n",
        "    return Model(inputs=[seq_input, feat_input], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def apply_fixed_pipeline(y_pred_prob, threshold=0.5, kernel_size=5, min_duration_samples=None, step_size=None):\n",
        "    y_pred_smooth = medfilt(y_pred_prob.flatten(), kernel_size=kernel_size)\n",
        "    y_pred_binary = (y_pred_smooth > threshold).astype(int)\n",
        "    if min_duration_samples is not None and step_size is not None:\n",
        "        min_consecutive_windows = max(1, min_duration_samples // step_size)\n",
        "        y_out = y_pred_binary.copy()\n",
        "        i = 0\n",
        "        while i < len(y_out):\n",
        "            if y_out[i] == 1:\n",
        "                start = i\n",
        "                while i < len(y_out) and y_out[i] == 1:\n",
        "                    i += 1\n",
        "                if (i - start) < min_consecutive_windows:\n",
        "                    y_out[start:i] = 0\n",
        "            else:\n",
        "                i += 1\n",
        "        return y_out\n",
        "    return y_pred_binary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def threshold_from_validation(y_val, y_val_prob):\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_prob)\n",
        "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "    best_idx = np.argmax(f1_scores)\n",
        "    return thresholds[best_idx] if best_idx < len(thresholds) else 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Found 20 subjects\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading data...\")\n",
        "all_dfs = load_recs()\n",
        "labeled_dfs = apply_labels(all_dfs)\n",
        "subjects = sorted(set(df[\"subject\"].iloc[0] for df in labeled_dfs))\n",
        "print(f\"Found {len(subjects)} subjects\")\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Test subject: 2024-12-04-18-49-30_c5c72868-633a-4672-8bdd-3a457f994ddb\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 81ms/step - accuracy: 0.9435 - loss: 0.0020 - val_accuracy: 0.9614 - val_loss: 0.0016\n",
            "Epoch 2/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 74ms/step - accuracy: 0.9601 - loss: 0.0015 - val_accuracy: 0.9658 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 85ms/step - accuracy: 0.9625 - loss: 0.0013 - val_accuracy: 0.8983 - val_loss: 0.0019\n",
            "Epoch 4/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9622 - loss: 0.0013 - val_accuracy: 0.9675 - val_loss: 9.6284e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9636 - loss: 0.0013 - val_accuracy: 0.9696 - val_loss: 9.1139e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9690 - val_loss: 9.2747e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9651 - loss: 0.0012 - val_accuracy: 0.9625 - val_loss: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9682 - val_loss: 9.2822e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9706 - val_loss: 8.7358e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 91ms/step - accuracy: 0.9659 - loss: 0.0012 - val_accuracy: 0.9677 - val_loss: 8.7052e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 92ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9711 - val_loss: 8.5330e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 100ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9692 - val_loss: 8.9111e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 96ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9696 - val_loss: 8.8097e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 102ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9685 - val_loss: 9.1316e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 88ms/step - accuracy: 0.9674 - loss: 0.0011 - val_accuracy: 0.9674 - val_loss: 8.8039e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9671 - loss: 0.0011 - val_accuracy: 0.9696 - val_loss: 8.1701e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9676 - loss: 0.0011 - val_accuracy: 0.9547 - val_loss: 0.0011\n",
            "Epoch 18/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9679 - loss: 0.0011 - val_accuracy: 0.9695 - val_loss: 9.1179e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9674 - val_loss: 8.5164e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9697 - val_loss: 8.3761e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9703 - val_loss: 8.6182e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9719 - val_loss: 7.7463e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9694 - loss: 0.0010 - val_accuracy: 0.9656 - val_loss: 9.2052e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9697 - loss: 0.0011 - val_accuracy: 0.9633 - val_loss: 9.3124e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9703 - val_loss: 8.0422e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 68ms/step - accuracy: 0.9692 - loss: 0.0010 - val_accuracy: 0.9671 - val_loss: 8.5728e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9687 - loss: 0.0010 - val_accuracy: 0.9719 - val_loss: 8.1447e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9695 - loss: 0.0010 - val_accuracy: 0.9689 - val_loss: 9.0193e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9704 - loss: 0.0010 - val_accuracy: 0.9727 - val_loss: 8.3985e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 77ms/step - accuracy: 0.9694 - loss: 0.0010 - val_accuracy: 0.9596 - val_loss: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 79ms/step - accuracy: 0.9695 - loss: 0.0010 - val_accuracy: 0.9714 - val_loss: 7.9058e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9699 - loss: 0.0011 - val_accuracy: 0.9684 - val_loss: 8.6947e-04\n",
            "Epoch 32: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9580  Acc: 0.9198\n",
            "  Fair F1 (val-chosen threshold=0.493): 0.9575  Acc: 0.9188\n",
            "\n",
            "============================================================\n",
            "Test subject: 2024-12-08-21-41-18_c1291a19-92af-431e-9608-6044389d26b0\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 81ms/step - accuracy: 0.9427 - loss: 0.0021 - val_accuracy: 0.9640 - val_loss: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9588 - loss: 0.0014 - val_accuracy: 0.9653 - val_loss: 9.8223e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 83ms/step - accuracy: 0.9649 - loss: 0.0013 - val_accuracy: 0.9652 - val_loss: 9.7009e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 78ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9661 - val_loss: 9.8510e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9682 - val_loss: 9.0766e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 8.9898e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 85ms/step - accuracy: 0.9671 - loss: 0.0011 - val_accuracy: 0.9669 - val_loss: 9.7397e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9674 - loss: 0.0011 - val_accuracy: 0.9631 - val_loss: 9.7989e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9681 - loss: 0.0011 - val_accuracy: 0.9646 - val_loss: 9.4502e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9691 - loss: 0.0011 - val_accuracy: 0.9646 - val_loss: 9.4763e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 79ms/step - accuracy: 0.9683 - loss: 0.0011 - val_accuracy: 0.9676 - val_loss: 9.6926e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 79ms/step - accuracy: 0.9694 - loss: 0.0010 - val_accuracy: 0.9689 - val_loss: 8.4746e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9692 - loss: 0.0011 - val_accuracy: 0.9675 - val_loss: 8.6763e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9681 - loss: 0.0011 - val_accuracy: 0.9710 - val_loss: 7.8660e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9696 - loss: 0.0010 - val_accuracy: 0.9697 - val_loss: 8.7267e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9694 - loss: 0.0010 - val_accuracy: 0.9692 - val_loss: 8.2732e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 79ms/step - accuracy: 0.9693 - loss: 0.0010 - val_accuracy: 0.9658 - val_loss: 9.6951e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9702 - loss: 0.0010 - val_accuracy: 0.9688 - val_loss: 8.4160e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9707 - loss: 0.0010 - val_accuracy: 0.9706 - val_loss: 8.3563e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9709 - loss: 0.0010 - val_accuracy: 0.9706 - val_loss: 8.0361e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9700 - loss: 0.0010 - val_accuracy: 0.9676 - val_loss: 8.5723e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9709 - loss: 0.0010 - val_accuracy: 0.9687 - val_loss: 8.5327e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 78ms/step - accuracy: 0.9707 - loss: 9.7810e-04 - val_accuracy: 0.9680 - val_loss: 8.0664e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 79ms/step - accuracy: 0.9698 - loss: 9.7217e-04 - val_accuracy: 0.9691 - val_loss: 8.2629e-04\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9472  Acc: 0.8997\n",
            "  Fair F1 (val-chosen threshold=0.488): 0.9472  Acc: 0.8997\n",
            "\n",
            "============================================================\n",
            "Test subject: 2024-12-10-19-42-27_4734a243-b638-4004-aa82-c698f3ef7aba\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 78ms/step - accuracy: 0.9470 - loss: 0.0020 - val_accuracy: 0.9643 - val_loss: 0.0012\n",
            "Epoch 2/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 78ms/step - accuracy: 0.9610 - loss: 0.0014 - val_accuracy: 0.9661 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9630 - loss: 0.0013 - val_accuracy: 0.9641 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9655 - loss: 0.0012 - val_accuracy: 0.9623 - val_loss: 0.0011\n",
            "Epoch 5/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9648 - loss: 0.0012 - val_accuracy: 0.9669 - val_loss: 9.0656e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9653 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9526 - val_loss: 0.0012\n",
            "Epoch 8/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9657 - loss: 0.0011 - val_accuracy: 0.9674 - val_loss: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9615 - val_loss: 0.0011\n",
            "Epoch 10/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9678 - loss: 0.0012 - val_accuracy: 0.9678 - val_loss: 9.3084e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9677 - loss: 0.0011 - val_accuracy: 0.9675 - val_loss: 9.1150e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9691 - loss: 0.0011 - val_accuracy: 0.9652 - val_loss: 9.7405e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 76ms/step - accuracy: 0.9682 - loss: 0.0011 - val_accuracy: 0.9685 - val_loss: 8.7658e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9689 - loss: 0.0011 - val_accuracy: 0.9701 - val_loss: 9.1014e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9691 - loss: 0.0011 - val_accuracy: 0.9657 - val_loss: 0.0011\n",
            "Epoch 16/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9689 - val_loss: 9.2208e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9693 - loss: 0.0010 - val_accuracy: 0.9685 - val_loss: 8.4889e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9693 - loss: 0.0010 - val_accuracy: 0.9677 - val_loss: 9.2364e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 78ms/step - accuracy: 0.9694 - loss: 0.0011 - val_accuracy: 0.9654 - val_loss: 9.7007e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9691 - loss: 0.0011 - val_accuracy: 0.9678 - val_loss: 8.6939e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9690 - loss: 0.0010 - val_accuracy: 0.9613 - val_loss: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9696 - loss: 0.0011 - val_accuracy: 0.9626 - val_loss: 0.0011\n",
            "Epoch 23/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9697 - loss: 0.0010 - val_accuracy: 0.9703 - val_loss: 8.6437e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9701 - loss: 9.9404e-04 - val_accuracy: 0.9690 - val_loss: 8.8572e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 78ms/step - accuracy: 0.9708 - loss: 0.0010 - val_accuracy: 0.9698 - val_loss: 8.7024e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9698 - loss: 0.0010 - val_accuracy: 0.9687 - val_loss: 8.7758e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 76ms/step - accuracy: 0.9708 - loss: 0.0010 - val_accuracy: 0.9704 - val_loss: 8.5282e-04\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9633  Acc: 0.9292\n",
            "  Fair F1 (val-chosen threshold=0.505): 0.9639  Acc: 0.9304\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-18-13-08-43_449ee30d-3245-47ca-9769-752cf0d2edb7\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 94ms/step - accuracy: 0.9400 - loss: 0.0022 - val_accuracy: 0.9647 - val_loss: 0.0012\n",
            "Epoch 2/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.9590 - loss: 0.0016 - val_accuracy: 0.9622 - val_loss: 0.0012\n",
            "Epoch 3/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9615 - loss: 0.0014 - val_accuracy: 0.9641 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9628 - loss: 0.0013 - val_accuracy: 0.9653 - val_loss: 0.0013\n",
            "Epoch 5/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9617 - loss: 0.0014 - val_accuracy: 0.9666 - val_loss: 9.6948e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9633 - loss: 0.0013 - val_accuracy: 0.9661 - val_loss: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9644 - loss: 0.0013 - val_accuracy: 0.9637 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 76ms/step - accuracy: 0.9654 - loss: 0.0013 - val_accuracy: 0.9666 - val_loss: 0.0012\n",
            "Epoch 9/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9658 - loss: 0.0013 - val_accuracy: 0.9661 - val_loss: 9.4854e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9629 - val_loss: 0.0011\n",
            "Epoch 11/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 74ms/step - accuracy: 0.9659 - loss: 0.0013 - val_accuracy: 0.9665 - val_loss: 9.3686e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9655 - loss: 0.0012 - val_accuracy: 0.9677 - val_loss: 9.7864e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9681 - val_loss: 9.1205e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9657 - val_loss: 9.4782e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9672 - loss: 0.0012 - val_accuracy: 0.9671 - val_loss: 9.3694e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9673 - loss: 0.0012 - val_accuracy: 0.9679 - val_loss: 9.3852e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9672 - loss: 0.0012 - val_accuracy: 0.9692 - val_loss: 8.8025e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9690 - val_loss: 8.7119e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9691 - val_loss: 9.3982e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9670 - loss: 0.0011 - val_accuracy: 0.9680 - val_loss: 9.2212e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9672 - loss: 0.0011 - val_accuracy: 0.9676 - val_loss: 9.9838e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9677 - loss: 0.0012 - val_accuracy: 0.9666 - val_loss: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9671 - loss: 0.0011 - val_accuracy: 0.9693 - val_loss: 8.6609e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9680 - loss: 0.0011 - val_accuracy: 0.9696 - val_loss: 9.1350e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9682 - loss: 0.0011 - val_accuracy: 0.9661 - val_loss: 9.5441e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9688 - loss: 0.0011 - val_accuracy: 0.9694 - val_loss: 9.0606e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9694 - val_loss: 8.9247e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9688 - loss: 0.0011 - val_accuracy: 0.9693 - val_loss: 8.7538e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9682 - loss: 0.0011 - val_accuracy: 0.9704 - val_loss: 8.8651e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 74ms/step - accuracy: 0.9683 - loss: 0.0011 - val_accuracy: 0.9664 - val_loss: 9.3687e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9690 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 9.0301e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9707 - val_loss: 9.0084e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9694 - loss: 0.0011 - val_accuracy: 0.9695 - val_loss: 8.9179e-04\n",
            "Epoch 33: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9786  Acc: 0.9586\n",
            "  Fair F1 (val-chosen threshold=0.544): 0.9792  Acc: 0.9599\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-18-22-38-29_37959204-490b-4cd9-b647-94e743071951\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 72ms/step - accuracy: 0.9367 - loss: 0.0025 - val_accuracy: 0.9652 - val_loss: 0.0012\n",
            "Epoch 2/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9547 - loss: 0.0017 - val_accuracy: 0.9671 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9582 - loss: 0.0015 - val_accuracy: 0.9674 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 74ms/step - accuracy: 0.9615 - loss: 0.0014 - val_accuracy: 0.9649 - val_loss: 0.0011\n",
            "Epoch 5/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9628 - loss: 0.0014 - val_accuracy: 0.9674 - val_loss: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9632 - loss: 0.0014 - val_accuracy: 0.9658 - val_loss: 0.0012\n",
            "Epoch 7/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9633 - loss: 0.0013 - val_accuracy: 0.9692 - val_loss: 9.7350e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9639 - loss: 0.0013 - val_accuracy: 0.9696 - val_loss: 9.8186e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9643 - loss: 0.0013 - val_accuracy: 0.9587 - val_loss: 0.0014\n",
            "Epoch 10/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9646 - loss: 0.0013 - val_accuracy: 0.9691 - val_loss: 0.0011\n",
            "Epoch 11/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9650 - loss: 0.0013 - val_accuracy: 0.9680 - val_loss: 9.8268e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9663 - loss: 0.0013 - val_accuracy: 0.9703 - val_loss: 9.6069e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9654 - loss: 0.0012 - val_accuracy: 0.9691 - val_loss: 9.3896e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9649 - loss: 0.0012 - val_accuracy: 0.9707 - val_loss: 8.8439e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9645 - loss: 0.0013 - val_accuracy: 0.9691 - val_loss: 9.1184e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9705 - val_loss: 8.5716e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9652 - loss: 0.0012 - val_accuracy: 0.9697 - val_loss: 8.8325e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9649 - loss: 0.0012 - val_accuracy: 0.9688 - val_loss: 9.5445e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 104ms/step - accuracy: 0.9668 - loss: 0.0012 - val_accuracy: 0.9709 - val_loss: 9.2871e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.9669 - loss: 0.0012 - val_accuracy: 0.9707 - val_loss: 9.3648e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9723 - val_loss: 9.2911e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9698 - val_loss: 9.4051e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9678 - loss: 0.0011 - val_accuracy: 0.9720 - val_loss: 9.3018e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9669 - loss: 0.0012 - val_accuracy: 0.9725 - val_loss: 8.7904e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9678 - loss: 0.0011 - val_accuracy: 0.9727 - val_loss: 8.6275e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9677 - loss: 0.0012 - val_accuracy: 0.9729 - val_loss: 8.7044e-04\n",
            "Epoch 26: early stopping\n",
            "Restoring model weights from the end of the best epoch: 16.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9873  Acc: 0.9751\n",
            "  Fair F1 (val-chosen threshold=0.546): 0.9709  Acc: 0.9441\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-19-18-41-39_c4d73c9a-93b2-4c1b-9f76-492d76f7731d\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 77ms/step - accuracy: 0.9394 - loss: 0.0022 - val_accuracy: 0.9578 - val_loss: 0.0014\n",
            "Epoch 2/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9598 - loss: 0.0016 - val_accuracy: 0.9600 - val_loss: 0.0012\n",
            "Epoch 3/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9614 - loss: 0.0014 - val_accuracy: 0.9628 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9628 - loss: 0.0014 - val_accuracy: 0.9632 - val_loss: 0.0011\n",
            "Epoch 5/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9617 - loss: 0.0014 - val_accuracy: 0.9612 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 78ms/step - accuracy: 0.9624 - loss: 0.0013 - val_accuracy: 0.9635 - val_loss: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9640 - loss: 0.0013 - val_accuracy: 0.9646 - val_loss: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9644 - loss: 0.0013 - val_accuracy: 0.9632 - val_loss: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9650 - loss: 0.0013 - val_accuracy: 0.9639 - val_loss: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 77ms/step - accuracy: 0.9649 - loss: 0.0012 - val_accuracy: 0.9627 - val_loss: 0.0011\n",
            "Epoch 11/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9644 - loss: 0.0012 - val_accuracy: 0.9586 - val_loss: 0.0011\n",
            "Epoch 12/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9652 - loss: 0.0012 - val_accuracy: 0.9604 - val_loss: 0.0011\n",
            "Epoch 13/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9656 - loss: 0.0012 - val_accuracy: 0.9637 - val_loss: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9649 - val_loss: 9.7137e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9639 - val_loss: 0.0011\n",
            "Epoch 16/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9653 - val_loss: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 76ms/step - accuracy: 0.9671 - loss: 0.0012 - val_accuracy: 0.9625 - val_loss: 0.0011\n",
            "Epoch 18/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9655 - loss: 0.0012 - val_accuracy: 0.9612 - val_loss: 0.0011\n",
            "Epoch 19/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9645 - val_loss: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9666 - val_loss: 9.7788e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9669 - loss: 0.0011 - val_accuracy: 0.9650 - val_loss: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 76ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9640 - val_loss: 9.9905e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9678 - loss: 0.0011 - val_accuracy: 0.9669 - val_loss: 9.7975e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9671 - loss: 0.0011 - val_accuracy: 0.9608 - val_loss: 0.0011\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9887  Acc: 0.9779\n",
            "  Fair F1 (val-chosen threshold=0.559): 0.9896  Acc: 0.9797\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-19-19-48-01_c2031779-881c-4c5c-9c6e-b3f4d57601a9\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.9455 - loss: 0.0022 - val_accuracy: 0.9544 - val_loss: 0.0014\n",
            "Epoch 2/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9577 - loss: 0.0016 - val_accuracy: 0.9590 - val_loss: 0.0013\n",
            "Epoch 3/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 76ms/step - accuracy: 0.9606 - loss: 0.0014 - val_accuracy: 0.9618 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9634 - loss: 0.0014 - val_accuracy: 0.9622 - val_loss: 0.0011\n",
            "Epoch 5/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9634 - loss: 0.0014 - val_accuracy: 0.9625 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9626 - loss: 0.0014 - val_accuracy: 0.9614 - val_loss: 0.0012\n",
            "Epoch 7/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9639 - loss: 0.0013 - val_accuracy: 0.9625 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 76ms/step - accuracy: 0.9644 - loss: 0.0013 - val_accuracy: 0.9610 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9648 - loss: 0.0013 - val_accuracy: 0.9622 - val_loss: 0.0011\n",
            "Epoch 10/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9644 - loss: 0.0013 - val_accuracy: 0.9597 - val_loss: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9659 - loss: 0.0013 - val_accuracy: 0.9515 - val_loss: 0.0013\n",
            "Epoch 12/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9659 - loss: 0.0012 - val_accuracy: 0.9641 - val_loss: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9655 - loss: 0.0012 - val_accuracy: 0.9649 - val_loss: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9631 - val_loss: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - accuracy: 0.9656 - loss: 0.0012 - val_accuracy: 0.9636 - val_loss: 9.7001e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9661 - loss: 0.0012 - val_accuracy: 0.9631 - val_loss: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 87ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9656 - val_loss: 9.7754e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 87ms/step - accuracy: 0.9669 - loss: 0.0012 - val_accuracy: 0.9635 - val_loss: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9681 - loss: 0.0012 - val_accuracy: 0.9666 - val_loss: 9.5863e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 87ms/step - accuracy: 0.9688 - loss: 0.0012 - val_accuracy: 0.9641 - val_loss: 9.9842e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 87ms/step - accuracy: 0.9675 - loss: 0.0012 - val_accuracy: 0.9660 - val_loss: 9.5583e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9682 - loss: 0.0012 - val_accuracy: 0.9643 - val_loss: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9679 - loss: 0.0012 - val_accuracy: 0.9607 - val_loss: 0.0012\n",
            "Epoch 24/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9680 - loss: 0.0011 - val_accuracy: 0.9637 - val_loss: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 88ms/step - accuracy: 0.9673 - loss: 0.0012 - val_accuracy: 0.9660 - val_loss: 9.7097e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9649 - val_loss: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 89ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9643 - val_loss: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 89ms/step - accuracy: 0.9681 - loss: 0.0012 - val_accuracy: 0.9690 - val_loss: 9.5004e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9684 - loss: 0.0012 - val_accuracy: 0.9669 - val_loss: 9.7009e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 89ms/step - accuracy: 0.9689 - loss: 0.0011 - val_accuracy: 0.9680 - val_loss: 9.3374e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9681 - loss: 0.0011 - val_accuracy: 0.9655 - val_loss: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9690 - loss: 0.0011 - val_accuracy: 0.9623 - val_loss: 0.0012\n",
            "Epoch 33/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 89ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9656 - val_loss: 9.8330e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9621 - val_loss: 0.0011\n",
            "Epoch 35/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 90ms/step - accuracy: 0.9690 - loss: 0.0011 - val_accuracy: 0.9687 - val_loss: 8.8569e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 89ms/step - accuracy: 0.9696 - loss: 0.0011 - val_accuracy: 0.9674 - val_loss: 9.8762e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9694 - loss: 0.0011 - val_accuracy: 0.9643 - val_loss: 9.6126e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9697 - loss: 0.0011 - val_accuracy: 0.9667 - val_loss: 9.8191e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9702 - loss: 0.0011 - val_accuracy: 0.9667 - val_loss: 9.8759e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9697 - loss: 0.0011 - val_accuracy: 0.9677 - val_loss: 9.2997e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9701 - loss: 0.0011 - val_accuracy: 0.9688 - val_loss: 8.9963e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9698 - loss: 0.0010 - val_accuracy: 0.9666 - val_loss: 8.9266e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9697 - loss: 0.0011 - val_accuracy: 0.9689 - val_loss: 9.8684e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9694 - loss: 0.0011 - val_accuracy: 0.9672 - val_loss: 9.9558e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 91ms/step - accuracy: 0.9707 - loss: 0.0010 - val_accuracy: 0.9686 - val_loss: 9.5171e-04\n",
            "Epoch 45: early stopping\n",
            "Restoring model weights from the end of the best epoch: 35.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9866  Acc: 0.9739\n",
            "  Fair F1 (val-chosen threshold=0.490): 0.9860  Acc: 0.9727\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-28-21-43-21_e4380fee-3c78-4e38-936f-acd60513e279\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 93ms/step - accuracy: 0.9482 - loss: 0.0020 - val_accuracy: 0.9631 - val_loss: 0.0012\n",
            "Epoch 2/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 90ms/step - accuracy: 0.9593 - loss: 0.0015 - val_accuracy: 0.9615 - val_loss: 0.0013\n",
            "Epoch 3/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 92ms/step - accuracy: 0.9609 - loss: 0.0015 - val_accuracy: 0.9639 - val_loss: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 92ms/step - accuracy: 0.9615 - loss: 0.0014 - val_accuracy: 0.9590 - val_loss: 0.0012\n",
            "Epoch 5/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 91ms/step - accuracy: 0.9627 - loss: 0.0014 - val_accuracy: 0.9638 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 92ms/step - accuracy: 0.9634 - loss: 0.0014 - val_accuracy: 0.9652 - val_loss: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 93ms/step - accuracy: 0.9642 - loss: 0.0013 - val_accuracy: 0.9651 - val_loss: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 92ms/step - accuracy: 0.9644 - loss: 0.0013 - val_accuracy: 0.9632 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 93ms/step - accuracy: 0.9657 - loss: 0.0013 - val_accuracy: 0.9665 - val_loss: 9.7478e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 93ms/step - accuracy: 0.9654 - loss: 0.0013 - val_accuracy: 0.9659 - val_loss: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 94ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9640 - val_loss: 9.8289e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9657 - loss: 0.0012 - val_accuracy: 0.9641 - val_loss: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 94ms/step - accuracy: 0.9660 - loss: 0.0013 - val_accuracy: 0.9671 - val_loss: 9.7315e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 93ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9672 - val_loss: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9649 - val_loss: 9.4210e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9682 - val_loss: 9.8463e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 95ms/step - accuracy: 0.9653 - loss: 0.0012 - val_accuracy: 0.9654 - val_loss: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 94ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 9.4358e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 95ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9666 - val_loss: 9.6592e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 93ms/step - accuracy: 0.9672 - loss: 0.0012 - val_accuracy: 0.9674 - val_loss: 9.4076e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9656 - val_loss: 9.5674e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9673 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 9.1176e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 93ms/step - accuracy: 0.9672 - loss: 0.0012 - val_accuracy: 0.9663 - val_loss: 9.6848e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 95ms/step - accuracy: 0.9669 - loss: 0.0011 - val_accuracy: 0.9635 - val_loss: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 93ms/step - accuracy: 0.9676 - loss: 0.0012 - val_accuracy: 0.9670 - val_loss: 9.0941e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9675 - loss: 0.0012 - val_accuracy: 0.9655 - val_loss: 9.6468e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 94ms/step - accuracy: 0.9676 - loss: 0.0011 - val_accuracy: 0.9660 - val_loss: 9.4740e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 8.9336e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9663 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 9.1133e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 95ms/step - accuracy: 0.9672 - loss: 0.0011 - val_accuracy: 0.9694 - val_loss: 8.7447e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9682 - val_loss: 9.1517e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9686 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 9.2734e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 94ms/step - accuracy: 0.9680 - loss: 0.0011 - val_accuracy: 0.9681 - val_loss: 8.9321e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9691 - loss: 0.0011 - val_accuracy: 0.9690 - val_loss: 9.1043e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9686 - loss: 0.0011 - val_accuracy: 0.9616 - val_loss: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 94ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9647 - val_loss: 9.5278e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 93ms/step - accuracy: 0.9679 - loss: 0.0011 - val_accuracy: 0.9691 - val_loss: 9.2624e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 95ms/step - accuracy: 0.9695 - loss: 0.0011 - val_accuracy: 0.9648 - val_loss: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 94ms/step - accuracy: 0.9695 - loss: 0.0011 - val_accuracy: 0.9700 - val_loss: 9.3016e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 94ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9679 - val_loss: 9.1614e-04\n",
            "Epoch 40: early stopping\n",
            "Restoring model weights from the end of the best epoch: 30.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9862  Acc: 0.9728\n",
            "  Fair F1 (val-chosen threshold=0.513): 0.9851  Acc: 0.9707\n",
            "\n",
            "============================================================\n",
            "Test subject: 34414785-1f38-4ff1-a709-e3bd0f5e7d42\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 93ms/step - accuracy: 0.9433 - loss: 0.0022 - val_accuracy: 0.9443 - val_loss: 0.0017\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 91ms/step - accuracy: 0.9577 - loss: 0.0016 - val_accuracy: 0.9434 - val_loss: 0.0015\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 92ms/step - accuracy: 0.9597 - loss: 0.0015 - val_accuracy: 0.9648 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 91ms/step - accuracy: 0.9605 - loss: 0.0014 - val_accuracy: 0.9636 - val_loss: 0.0012\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9608 - loss: 0.0014 - val_accuracy: 0.9655 - val_loss: 0.0012\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9626 - loss: 0.0014 - val_accuracy: 0.9612 - val_loss: 0.0012\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9628 - loss: 0.0013 - val_accuracy: 0.9668 - val_loss: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9632 - loss: 0.0013 - val_accuracy: 0.9672 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 87ms/step - accuracy: 0.9632 - loss: 0.0013 - val_accuracy: 0.9645 - val_loss: 0.0011\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 90ms/step - accuracy: 0.9637 - loss: 0.0013 - val_accuracy: 0.9669 - val_loss: 0.0011\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 94ms/step - accuracy: 0.9644 - loss: 0.0013 - val_accuracy: 0.9685 - val_loss: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 113ms/step - accuracy: 0.9655 - loss: 0.0012 - val_accuracy: 0.9668 - val_loss: 9.8835e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 89ms/step - accuracy: 0.9651 - loss: 0.0012 - val_accuracy: 0.9683 - val_loss: 9.3696e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 87ms/step - accuracy: 0.9645 - loss: 0.0012 - val_accuracy: 0.9663 - val_loss: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9653 - loss: 0.0012 - val_accuracy: 0.9683 - val_loss: 9.2559e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 89ms/step - accuracy: 0.9646 - loss: 0.0012 - val_accuracy: 0.9683 - val_loss: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9656 - loss: 0.0013 - val_accuracy: 0.9671 - val_loss: 9.6279e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9676 - val_loss: 9.1575e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 93ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9672 - val_loss: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9666 - loss: 0.0012 - val_accuracy: 0.9670 - val_loss: 9.4803e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9661 - loss: 0.0012 - val_accuracy: 0.9624 - val_loss: 0.0011\n",
            "Epoch 22/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9697 - val_loss: 9.2048e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9677 - val_loss: 9.9576e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9596 - val_loss: 0.0011\n",
            "Epoch 25/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 94ms/step - accuracy: 0.9668 - loss: 0.0012 - val_accuracy: 0.9657 - val_loss: 0.0011\n",
            "Epoch 26/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 93ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9696 - val_loss: 9.5361e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9659 - loss: 0.0012 - val_accuracy: 0.9707 - val_loss: 9.6485e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9669 - loss: 0.0012 - val_accuracy: 0.9699 - val_loss: 9.0856e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9678 - loss: 0.0012 - val_accuracy: 0.9676 - val_loss: 9.9313e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9668 - loss: 0.0011 - val_accuracy: 0.9697 - val_loss: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 109ms/step - accuracy: 0.9682 - loss: 0.0011 - val_accuracy: 0.9623 - val_loss: 0.0011\n",
            "Epoch 32/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 96ms/step - accuracy: 0.9678 - loss: 0.0011 - val_accuracy: 0.9702 - val_loss: 9.3335e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 100ms/step - accuracy: 0.9677 - loss: 0.0011 - val_accuracy: 0.9705 - val_loss: 9.9333e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 101ms/step - accuracy: 0.9698 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 9.6168e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 103ms/step - accuracy: 0.9680 - loss: 0.0011 - val_accuracy: 0.9698 - val_loss: 9.0816e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 103ms/step - accuracy: 0.9672 - loss: 0.0011 - val_accuracy: 0.9707 - val_loss: 8.7568e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 104ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9652 - val_loss: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 104ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9695 - val_loss: 9.4595e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 104ms/step - accuracy: 0.9686 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 8.8854e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 106ms/step - accuracy: 0.9688 - loss: 0.0011 - val_accuracy: 0.9657 - val_loss: 9.7839e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 103ms/step - accuracy: 0.9692 - loss: 0.0011 - val_accuracy: 0.9665 - val_loss: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 117ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9683 - val_loss: 9.4672e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 100ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9702 - val_loss: 8.6090e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 108ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9697 - val_loss: 9.5068e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9690 - loss: 0.0010 - val_accuracy: 0.9667 - val_loss: 9.9001e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9695 - loss: 0.0010 - val_accuracy: 0.9695 - val_loss: 9.2058e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 72ms/step - accuracy: 0.9695 - loss: 0.0011 - val_accuracy: 0.9709 - val_loss: 8.6658e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.9699 - loss: 0.0010 - val_accuracy: 0.9698 - val_loss: 8.9205e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9695 - loss: 0.0011 - val_accuracy: 0.9722 - val_loss: 8.6707e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9687 - loss: 0.0010 - val_accuracy: 0.9714 - val_loss: 8.6726e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.9702 - loss: 0.0010 - val_accuracy: 0.9707 - val_loss: 8.8607e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 72ms/step - accuracy: 0.9691 - loss: 0.0010 - val_accuracy: 0.9709 - val_loss: 8.5566e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 73ms/step - accuracy: 0.9699 - loss: 0.0010 - val_accuracy: 0.9723 - val_loss: 8.5534e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9700 - loss: 0.0010 - val_accuracy: 0.9705 - val_loss: 0.0010\n",
            "Epoch 55/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 74ms/step - accuracy: 0.9705 - loss: 0.0010 - val_accuracy: 0.9695 - val_loss: 8.8303e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9695 - loss: 0.0010 - val_accuracy: 0.9702 - val_loss: 8.9602e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 76ms/step - accuracy: 0.9702 - loss: 0.0010 - val_accuracy: 0.9713 - val_loss: 9.0315e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9693 - loss: 0.0011 - val_accuracy: 0.9651 - val_loss: 0.0011\n",
            "Epoch 59/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9705 - loss: 0.0010 - val_accuracy: 0.9669 - val_loss: 9.4228e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9696 - loss: 0.0010 - val_accuracy: 0.9722 - val_loss: 8.7911e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 79ms/step - accuracy: 0.9711 - loss: 0.0010 - val_accuracy: 0.9654 - val_loss: 9.5127e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9696 - loss: 0.0010 - val_accuracy: 0.9738 - val_loss: 8.7320e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 79ms/step - accuracy: 0.9704 - loss: 0.0010 - val_accuracy: 0.9702 - val_loss: 8.8986e-04\n",
            "Epoch 63: early stopping\n",
            "Restoring model weights from the end of the best epoch: 53.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9933  Acc: 0.9871\n",
            "  Fair F1 (val-chosen threshold=0.494): 0.9940  Acc: 0.9883\n",
            "\n",
            "============================================================\n",
            "Test subject: 383ea87a-3396-400b-9497-ee6f9ad7c093\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 81ms/step - accuracy: 0.9470 - loss: 0.0021 - val_accuracy: 0.9631 - val_loss: 0.0012\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9585 - loss: 0.0016 - val_accuracy: 0.9623 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9608 - loss: 0.0015 - val_accuracy: 0.9644 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9613 - loss: 0.0015 - val_accuracy: 0.9611 - val_loss: 0.0012\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9605 - loss: 0.0014 - val_accuracy: 0.9531 - val_loss: 0.0013\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9610 - loss: 0.0014 - val_accuracy: 0.9652 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9626 - loss: 0.0014 - val_accuracy: 0.9666 - val_loss: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9626 - loss: 0.0013 - val_accuracy: 0.9654 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9628 - loss: 0.0013 - val_accuracy: 0.9633 - val_loss: 0.0012\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 84ms/step - accuracy: 0.9631 - loss: 0.0014 - val_accuracy: 0.9645 - val_loss: 0.0011\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 85ms/step - accuracy: 0.9641 - loss: 0.0013 - val_accuracy: 0.9669 - val_loss: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9638 - loss: 0.0013 - val_accuracy: 0.9665 - val_loss: 0.0011\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9640 - loss: 0.0013 - val_accuracy: 0.9673 - val_loss: 9.8822e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 85ms/step - accuracy: 0.9645 - loss: 0.0013 - val_accuracy: 0.9671 - val_loss: 9.8097e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9649 - loss: 0.0012 - val_accuracy: 0.9669 - val_loss: 9.8424e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9655 - loss: 0.0012 - val_accuracy: 0.9651 - val_loss: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9660 - val_loss: 0.0011\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9656 - loss: 0.0013 - val_accuracy: 0.9663 - val_loss: 0.0011\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9652 - loss: 0.0012 - val_accuracy: 0.9619 - val_loss: 0.0012\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9659 - loss: 0.0012 - val_accuracy: 0.9683 - val_loss: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9671 - val_loss: 9.5674e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9658 - loss: 0.0013 - val_accuracy: 0.9665 - val_loss: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9622 - val_loss: 0.0011\n",
            "Epoch 24/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9668 - loss: 0.0012 - val_accuracy: 0.9684 - val_loss: 9.7208e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9675 - loss: 0.0012 - val_accuracy: 0.9687 - val_loss: 9.5681e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9672 - loss: 0.0012 - val_accuracy: 0.9694 - val_loss: 9.3009e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9684 - val_loss: 9.5284e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9682 - val_loss: 9.3482e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9653 - loss: 0.0012 - val_accuracy: 0.9660 - val_loss: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9653 - val_loss: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9681 - loss: 0.0011 - val_accuracy: 0.9691 - val_loss: 9.2291e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9673 - loss: 0.0012 - val_accuracy: 0.9679 - val_loss: 9.9616e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9652 - val_loss: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9677 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 9.4815e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9678 - loss: 0.0012 - val_accuracy: 0.9675 - val_loss: 9.5985e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9661 - loss: 0.0011 - val_accuracy: 0.9658 - val_loss: 9.5455e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9688 - loss: 0.0011 - val_accuracy: 0.9689 - val_loss: 8.9075e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9680 - loss: 0.0011 - val_accuracy: 0.9682 - val_loss: 9.1454e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9689 - loss: 0.0011 - val_accuracy: 0.9688 - val_loss: 9.5718e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9692 - loss: 0.0011 - val_accuracy: 0.9694 - val_loss: 9.2277e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9697 - val_loss: 9.3569e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9696 - loss: 0.0011 - val_accuracy: 0.9702 - val_loss: 9.5584e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9698 - loss: 0.0011 - val_accuracy: 0.9687 - val_loss: 9.7939e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9691 - loss: 0.0011 - val_accuracy: 0.9676 - val_loss: 9.7046e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9703 - loss: 0.0011 - val_accuracy: 0.9649 - val_loss: 9.8809e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9695 - loss: 0.0011 - val_accuracy: 0.9641 - val_loss: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9701 - loss: 0.0011 - val_accuracy: 0.9708 - val_loss: 8.9591e-04\n",
            "Epoch 47: early stopping\n",
            "Restoring model weights from the end of the best epoch: 37.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9965  Acc: 0.9932\n",
            "  Fair F1 (val-chosen threshold=0.412): 0.9947  Acc: 0.9896\n",
            "\n",
            "============================================================\n",
            "Test subject: 6c516a60-1d5e-4d7c-a1dd-158099033fe7\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 81ms/step - accuracy: 0.9363 - loss: 0.0025 - val_accuracy: 0.9619 - val_loss: 0.0012\n",
            "Epoch 2/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9569 - loss: 0.0017 - val_accuracy: 0.9617 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9605 - loss: 0.0015 - val_accuracy: 0.9648 - val_loss: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9604 - loss: 0.0015 - val_accuracy: 0.9630 - val_loss: 0.0011\n",
            "Epoch 5/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9622 - loss: 0.0014 - val_accuracy: 0.9646 - val_loss: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9624 - loss: 0.0014 - val_accuracy: 0.9663 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9627 - loss: 0.0014 - val_accuracy: 0.9666 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9629 - loss: 0.0013 - val_accuracy: 0.9678 - val_loss: 9.4808e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9634 - loss: 0.0013 - val_accuracy: 0.9664 - val_loss: 9.4138e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9641 - loss: 0.0013 - val_accuracy: 0.9658 - val_loss: 9.5702e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9644 - loss: 0.0013 - val_accuracy: 0.9679 - val_loss: 9.1691e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9642 - loss: 0.0013 - val_accuracy: 0.9657 - val_loss: 0.0011\n",
            "Epoch 13/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9646 - loss: 0.0013 - val_accuracy: 0.9577 - val_loss: 0.0012\n",
            "Epoch 14/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9651 - loss: 0.0013 - val_accuracy: 0.9683 - val_loss: 9.7899e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 9.1970e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9646 - loss: 0.0013 - val_accuracy: 0.9691 - val_loss: 9.4672e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9656 - loss: 0.0012 - val_accuracy: 0.9696 - val_loss: 8.7499e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9633 - loss: 0.0013 - val_accuracy: 0.9681 - val_loss: 9.2530e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9654 - loss: 0.0012 - val_accuracy: 0.9666 - val_loss: 9.3820e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9692 - val_loss: 9.1723e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9655 - loss: 0.0012 - val_accuracy: 0.9677 - val_loss: 9.4710e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 9.0574e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9661 - loss: 0.0012 - val_accuracy: 0.9707 - val_loss: 9.1786e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9652 - loss: 0.0012 - val_accuracy: 0.9694 - val_loss: 8.7158e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9694 - val_loss: 8.6035e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9676 - val_loss: 9.3813e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9672 - loss: 0.0012 - val_accuracy: 0.9705 - val_loss: 9.6242e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9691 - val_loss: 9.1412e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9690 - val_loss: 9.4912e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9655 - val_loss: 9.4981e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9683 - loss: 0.0011 - val_accuracy: 0.9667 - val_loss: 8.9506e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 8.7588e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9677 - loss: 0.0012 - val_accuracy: 0.9690 - val_loss: 9.3135e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9696 - val_loss: 9.1773e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9700 - val_loss: 8.8716e-04\n",
            "Epoch 35: early stopping\n",
            "Restoring model weights from the end of the best epoch: 25.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9915  Acc: 0.9837\n",
            "  Fair F1 (val-chosen threshold=0.505): 0.9915  Acc: 0.9837\n",
            "\n",
            "============================================================\n",
            "Test subject: 8bb7b2a8-0d9b-4aaa-ad3a-c15fedb2ad31\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 80ms/step - accuracy: 0.9450 - loss: 0.0021 - val_accuracy: 0.9627 - val_loss: 0.0014\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 79ms/step - accuracy: 0.9571 - loss: 0.0017 - val_accuracy: 0.9646 - val_loss: 0.0012\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9597 - loss: 0.0016 - val_accuracy: 0.9645 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9623 - loss: 0.0015 - val_accuracy: 0.9620 - val_loss: 0.0012\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9613 - loss: 0.0014 - val_accuracy: 0.9635 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9631 - loss: 0.0014 - val_accuracy: 0.9677 - val_loss: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9638 - loss: 0.0014 - val_accuracy: 0.9664 - val_loss: 0.0012\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9629 - loss: 0.0014 - val_accuracy: 0.9661 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9638 - loss: 0.0013 - val_accuracy: 0.9662 - val_loss: 9.7993e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9647 - loss: 0.0013 - val_accuracy: 0.9658 - val_loss: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9646 - loss: 0.0013 - val_accuracy: 0.9652 - val_loss: 0.0011\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9656 - loss: 0.0013 - val_accuracy: 0.9676 - val_loss: 9.9902e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9657 - loss: 0.0013 - val_accuracy: 0.9638 - val_loss: 0.0011\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9651 - loss: 0.0013 - val_accuracy: 0.9669 - val_loss: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9634 - loss: 0.0013 - val_accuracy: 0.9664 - val_loss: 9.5839e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9668 - loss: 0.0012 - val_accuracy: 0.9675 - val_loss: 9.8718e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9656 - loss: 0.0012 - val_accuracy: 0.9671 - val_loss: 9.5541e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9603 - val_loss: 0.0011\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9667 - val_loss: 9.7763e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9675 - loss: 0.0013 - val_accuracy: 0.9665 - val_loss: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9675 - val_loss: 9.6225e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9674 - val_loss: 9.5884e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9673 - val_loss: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9668 - loss: 0.0012 - val_accuracy: 0.9687 - val_loss: 9.9326e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9674 - loss: 0.0011 - val_accuracy: 0.9653 - val_loss: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9674 - loss: 0.0012 - val_accuracy: 0.9674 - val_loss: 9.8818e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9678 - val_loss: 9.6167e-04\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 17.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9884  Acc: 0.9776\n",
            "  Fair F1 (val-chosen threshold=0.528): 0.9876  Acc: 0.9760\n",
            "\n",
            "============================================================\n",
            "Test subject: 8f0ce2c4-d123-4c1c-aac2-61844abfa8ca\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 80ms/step - accuracy: 0.9485 - loss: 0.0021 - val_accuracy: 0.9601 - val_loss: 0.0014\n",
            "Epoch 2/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9586 - loss: 0.0015 - val_accuracy: 0.9613 - val_loss: 0.0012\n",
            "Epoch 3/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9612 - loss: 0.0015 - val_accuracy: 0.9651 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9612 - loss: 0.0014 - val_accuracy: 0.9636 - val_loss: 0.0014\n",
            "Epoch 5/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9620 - loss: 0.0014 - val_accuracy: 0.9626 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9630 - loss: 0.0014 - val_accuracy: 0.9561 - val_loss: 0.0012\n",
            "Epoch 7/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9625 - loss: 0.0013 - val_accuracy: 0.9648 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9636 - loss: 0.0013 - val_accuracy: 0.9642 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9638 - loss: 0.0013 - val_accuracy: 0.9593 - val_loss: 0.0012\n",
            "Epoch 10/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9631 - loss: 0.0013 - val_accuracy: 0.9658 - val_loss: 9.9888e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9649 - loss: 0.0013 - val_accuracy: 0.9672 - val_loss: 0.0011\n",
            "Epoch 12/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9642 - loss: 0.0013 - val_accuracy: 0.9580 - val_loss: 0.0011\n",
            "Epoch 13/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9646 - loss: 0.0012 - val_accuracy: 0.9690 - val_loss: 9.6565e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9649 - loss: 0.0013 - val_accuracy: 0.9644 - val_loss: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9664 - val_loss: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9656 - loss: 0.0012 - val_accuracy: 0.9688 - val_loss: 9.7469e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 82ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9623 - val_loss: 0.0011\n",
            "Epoch 18/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9650 - loss: 0.0012 - val_accuracy: 0.9678 - val_loss: 9.7300e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9668 - loss: 0.0012 - val_accuracy: 0.9658 - val_loss: 9.9256e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9673 - val_loss: 9.6326e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9646 - val_loss: 9.9563e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9671 - loss: 0.0012 - val_accuracy: 0.9673 - val_loss: 9.7872e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9666 - loss: 0.0011 - val_accuracy: 0.9681 - val_loss: 9.5324e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9670 - loss: 0.0011 - val_accuracy: 0.9643 - val_loss: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9667 - val_loss: 9.8660e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9649 - val_loss: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9668 - loss: 0.0011 - val_accuracy: 0.9676 - val_loss: 9.4699e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9629 - val_loss: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 82ms/step - accuracy: 0.9670 - loss: 0.0011 - val_accuracy: 0.9674 - val_loss: 9.4741e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9671 - val_loss: 9.8077e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9671 - loss: 0.0011 - val_accuracy: 0.9662 - val_loss: 9.6399e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9671 - val_loss: 9.2712e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9676 - loss: 0.0011 - val_accuracy: 0.9608 - val_loss: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 81ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9633 - val_loss: 9.7923e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9678 - loss: 0.0011 - val_accuracy: 0.9617 - val_loss: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9686 - loss: 0.0011 - val_accuracy: 0.9621 - val_loss: 0.0011\n",
            "Epoch 37/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9686 - loss: 0.0011 - val_accuracy: 0.9639 - val_loss: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9689 - loss: 0.0011 - val_accuracy: 0.9665 - val_loss: 9.3083e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9688 - val_loss: 9.3326e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9671 - val_loss: 9.4444e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 82ms/step - accuracy: 0.9698 - loss: 0.0010 - val_accuracy: 0.9687 - val_loss: 9.4262e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9691 - loss: 0.0010 - val_accuracy: 0.9678 - val_loss: 9.5748e-04\n",
            "Epoch 42: early stopping\n",
            "Restoring model weights from the end of the best epoch: 32.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9916  Acc: 0.9840\n",
            "  Fair F1 (val-chosen threshold=0.443): 0.9919  Acc: 0.9843\n",
            "\n",
            "============================================================\n",
            "Test subject: Participant_1_Data_4\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 84ms/step - accuracy: 0.9444 - loss: 0.0021 - val_accuracy: 0.9572 - val_loss: 0.0015\n",
            "Epoch 2/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9603 - loss: 0.0015 - val_accuracy: 0.9607 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9618 - loss: 0.0014 - val_accuracy: 0.9658 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9633 - loss: 0.0013 - val_accuracy: 0.9653 - val_loss: 0.0011\n",
            "Epoch 5/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9636 - loss: 0.0013 - val_accuracy: 0.9673 - val_loss: 9.8214e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9642 - loss: 0.0013 - val_accuracy: 0.9658 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9653 - loss: 0.0013 - val_accuracy: 0.9629 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9667 - val_loss: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9649 - loss: 0.0012 - val_accuracy: 0.9648 - val_loss: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9652 - loss: 0.0012 - val_accuracy: 0.9659 - val_loss: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9652 - loss: 0.0012 - val_accuracy: 0.9667 - val_loss: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9659 - loss: 0.0012 - val_accuracy: 0.9660 - val_loss: 9.8820e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 78ms/step - accuracy: 0.9661 - loss: 0.0012 - val_accuracy: 0.9675 - val_loss: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9663 - loss: 0.0011 - val_accuracy: 0.9683 - val_loss: 9.4994e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9657 - loss: 0.0012 - val_accuracy: 0.9676 - val_loss: 9.9000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9671 - val_loss: 0.0011\n",
            "Epoch 17/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9638 - val_loss: 0.0011\n",
            "Epoch 18/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9669 - loss: 0.0011 - val_accuracy: 0.9693 - val_loss: 9.2652e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9670 - loss: 0.0011 - val_accuracy: 0.9684 - val_loss: 9.9702e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9684 - val_loss: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9627 - val_loss: 0.0011\n",
            "Epoch 22/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9669 - loss: 0.0011 - val_accuracy: 0.9687 - val_loss: 9.6645e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9687 - val_loss: 9.8093e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9669 - loss: 0.0011 - val_accuracy: 0.9620 - val_loss: 0.0011\n",
            "Epoch 25/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9686 - val_loss: 9.9781e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9677 - loss: 0.0011 - val_accuracy: 0.9681 - val_loss: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9674 - loss: 0.0011 - val_accuracy: 0.9627 - val_loss: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9679 - loss: 0.0011 - val_accuracy: 0.9674 - val_loss: 9.9959e-04\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 18.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9835  Acc: 0.9681\n",
            "  Fair F1 (val-chosen threshold=0.442): 0.9812  Acc: 0.9634\n",
            "\n",
            "============================================================\n",
            "Test subject: Participant_3_Data_1\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 81ms/step - accuracy: 0.9490 - loss: 0.0019 - val_accuracy: 0.9650 - val_loss: 0.0013\n",
            "Epoch 2/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9586 - loss: 0.0016 - val_accuracy: 0.9653 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9604 - loss: 0.0014 - val_accuracy: 0.9624 - val_loss: 0.0011\n",
            "Epoch 4/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9633 - loss: 0.0013 - val_accuracy: 0.9655 - val_loss: 9.8762e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9632 - loss: 0.0013 - val_accuracy: 0.9679 - val_loss: 9.7475e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9638 - loss: 0.0013 - val_accuracy: 0.9665 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9653 - loss: 0.0013 - val_accuracy: 0.9693 - val_loss: 9.7222e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9642 - loss: 0.0013 - val_accuracy: 0.9674 - val_loss: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9645 - loss: 0.0012 - val_accuracy: 0.9665 - val_loss: 9.9316e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9654 - loss: 0.0013 - val_accuracy: 0.9627 - val_loss: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9652 - loss: 0.0012 - val_accuracy: 0.9692 - val_loss: 8.8345e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9657 - loss: 0.0012 - val_accuracy: 0.9663 - val_loss: 0.0011\n",
            "Epoch 13/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9676 - loss: 0.0012 - val_accuracy: 0.9681 - val_loss: 9.3744e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9662 - loss: 0.0012 - val_accuracy: 0.9676 - val_loss: 9.7282e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9694 - val_loss: 9.0087e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9675 - loss: 0.0012 - val_accuracy: 0.9705 - val_loss: 8.8296e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9665 - loss: 0.0011 - val_accuracy: 0.9450 - val_loss: 0.0014\n",
            "Epoch 18/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9679 - loss: 0.0012 - val_accuracy: 0.9675 - val_loss: 9.2854e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 84ms/step - accuracy: 0.9665 - loss: 0.0011 - val_accuracy: 0.9645 - val_loss: 9.7362e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9672 - loss: 0.0011 - val_accuracy: 0.9692 - val_loss: 8.6813e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9670 - loss: 0.0011 - val_accuracy: 0.9676 - val_loss: 9.4106e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 81ms/step - accuracy: 0.9666 - loss: 0.0011 - val_accuracy: 0.9695 - val_loss: 8.9772e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 79ms/step - accuracy: 0.9674 - loss: 0.0011 - val_accuracy: 0.9696 - val_loss: 8.8212e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9692 - loss: 0.0011 - val_accuracy: 0.9711 - val_loss: 9.0469e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9678 - val_loss: 9.6073e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9703 - val_loss: 9.2730e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 83ms/step - accuracy: 0.9688 - loss: 0.0011 - val_accuracy: 0.9701 - val_loss: 8.7339e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 82ms/step - accuracy: 0.9682 - loss: 0.0011 - val_accuracy: 0.9664 - val_loss: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9694 - loss: 0.0011 - val_accuracy: 0.9656 - val_loss: 9.6987e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9686 - loss: 0.0010 - val_accuracy: 0.9637 - val_loss: 0.0010\n",
            "Epoch 30: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9776  Acc: 0.9569\n",
            "  Fair F1 (val-chosen threshold=0.420): 0.9797  Acc: 0.9607\n",
            "\n",
            "============================================================\n",
            "Test subject: a43187d2-c663-42c5-8da5-750dbb9b72bd\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 82ms/step - accuracy: 0.9374 - loss: 0.0025 - val_accuracy: 0.9615 - val_loss: 0.0013\n",
            "Epoch 2/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9563 - loss: 0.0017 - val_accuracy: 0.9634 - val_loss: 0.0012\n",
            "Epoch 3/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9598 - loss: 0.0016 - val_accuracy: 0.9613 - val_loss: 0.0013\n",
            "Epoch 4/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9605 - loss: 0.0015 - val_accuracy: 0.9587 - val_loss: 0.0013\n",
            "Epoch 5/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9608 - loss: 0.0015 - val_accuracy: 0.9651 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9630 - loss: 0.0014 - val_accuracy: 0.9651 - val_loss: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9625 - loss: 0.0014 - val_accuracy: 0.9630 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9633 - loss: 0.0014 - val_accuracy: 0.9667 - val_loss: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9639 - loss: 0.0013 - val_accuracy: 0.9651 - val_loss: 9.8896e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9650 - loss: 0.0013 - val_accuracy: 0.9651 - val_loss: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9647 - loss: 0.0013 - val_accuracy: 0.9672 - val_loss: 0.0011\n",
            "Epoch 12/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9644 - loss: 0.0013 - val_accuracy: 0.9658 - val_loss: 9.9240e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9647 - loss: 0.0013 - val_accuracy: 0.9652 - val_loss: 9.8370e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 83ms/step - accuracy: 0.9657 - loss: 0.0013 - val_accuracy: 0.9664 - val_loss: 9.4504e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9659 - loss: 0.0012 - val_accuracy: 0.9668 - val_loss: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9658 - loss: 0.0012 - val_accuracy: 0.9621 - val_loss: 0.0011\n",
            "Epoch 17/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9661 - loss: 0.0012 - val_accuracy: 0.9663 - val_loss: 9.6372e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9657 - val_loss: 9.8583e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9671 - loss: 0.0012 - val_accuracy: 0.9655 - val_loss: 0.0011\n",
            "Epoch 20/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9660 - loss: 0.0012 - val_accuracy: 0.9632 - val_loss: 0.0011\n",
            "Epoch 21/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9655 - loss: 0.0012 - val_accuracy: 0.9309 - val_loss: 0.0016\n",
            "Epoch 22/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9661 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 9.6015e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9668 - loss: 0.0012 - val_accuracy: 0.9648 - val_loss: 0.0011\n",
            "Epoch 24/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9671 - loss: 0.0012 - val_accuracy: 0.9679 - val_loss: 9.5994e-04\n",
            "Epoch 24: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9939  Acc: 0.9881\n",
            "  Fair F1 (val-chosen threshold=0.528): 0.9948  Acc: 0.9899\n",
            "\n",
            "============================================================\n",
            "Test subject: ab0a6b0c-b0f2-4bda-8806-a4e39175f027\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 82ms/step - accuracy: 0.9480 - loss: 0.0020 - val_accuracy: 0.9590 - val_loss: 0.0013\n",
            "Epoch 2/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9593 - loss: 0.0016 - val_accuracy: 0.9603 - val_loss: 0.0013\n",
            "Epoch 3/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9600 - loss: 0.0015 - val_accuracy: 0.9540 - val_loss: 0.0013\n",
            "Epoch 4/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9609 - loss: 0.0014 - val_accuracy: 0.9651 - val_loss: 0.0011\n",
            "Epoch 5/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9631 - loss: 0.0014 - val_accuracy: 0.9643 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9626 - loss: 0.0014 - val_accuracy: 0.9624 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9633 - loss: 0.0013 - val_accuracy: 0.9649 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9643 - loss: 0.0013 - val_accuracy: 0.9656 - val_loss: 0.0011\n",
            "Epoch 9/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9640 - loss: 0.0013 - val_accuracy: 0.9654 - val_loss: 0.0011\n",
            "Epoch 10/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9651 - loss: 0.0013 - val_accuracy: 0.9648 - val_loss: 0.0011\n",
            "Epoch 11/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 82ms/step - accuracy: 0.9651 - loss: 0.0013 - val_accuracy: 0.9647 - val_loss: 0.0011\n",
            "Epoch 12/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9657 - loss: 0.0013 - val_accuracy: 0.9519 - val_loss: 0.0013\n",
            "Epoch 13/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9661 - loss: 0.0013 - val_accuracy: 0.9669 - val_loss: 0.0011\n",
            "Epoch 14/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 86ms/step - accuracy: 0.9658 - loss: 0.0013 - val_accuracy: 0.9644 - val_loss: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 86ms/step - accuracy: 0.9654 - loss: 0.0013 - val_accuracy: 0.9651 - val_loss: 0.0011\n",
            "Epoch 16/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9662 - loss: 0.0013 - val_accuracy: 0.9644 - val_loss: 0.0011\n",
            "Epoch 17/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 88ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9657 - val_loss: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 90ms/step - accuracy: 0.9669 - loss: 0.0013 - val_accuracy: 0.9650 - val_loss: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9654 - loss: 0.0012 - val_accuracy: 0.9651 - val_loss: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9664 - val_loss: 9.8092e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 96ms/step - accuracy: 0.9675 - loss: 0.0012 - val_accuracy: 0.9677 - val_loss: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 98ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9672 - val_loss: 0.0011\n",
            "Epoch 23/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 100ms/step - accuracy: 0.9681 - loss: 0.0012 - val_accuracy: 0.9658 - val_loss: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 102ms/step - accuracy: 0.9675 - loss: 0.0012 - val_accuracy: 0.9666 - val_loss: 9.5313e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 103ms/step - accuracy: 0.9674 - loss: 0.0012 - val_accuracy: 0.9668 - val_loss: 9.5628e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 104ms/step - accuracy: 0.9681 - loss: 0.0011 - val_accuracy: 0.9669 - val_loss: 9.6055e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 104ms/step - accuracy: 0.9672 - loss: 0.0012 - val_accuracy: 0.9666 - val_loss: 9.6250e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 109ms/step - accuracy: 0.9682 - loss: 0.0011 - val_accuracy: 0.9679 - val_loss: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 108ms/step - accuracy: 0.9680 - loss: 0.0012 - val_accuracy: 0.9680 - val_loss: 9.5448e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 111ms/step - accuracy: 0.9678 - loss: 0.0011 - val_accuracy: 0.9672 - val_loss: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 115ms/step - accuracy: 0.9686 - loss: 0.0011 - val_accuracy: 0.9685 - val_loss: 9.5210e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 113ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9663 - val_loss: 0.0011\n",
            "Epoch 33/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 116ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9661 - val_loss: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 118ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9666 - val_loss: 9.4642e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 119ms/step - accuracy: 0.9692 - loss: 0.0011 - val_accuracy: 0.9666 - val_loss: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 119ms/step - accuracy: 0.9682 - loss: 0.0011 - val_accuracy: 0.9660 - val_loss: 9.7046e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 120ms/step - accuracy: 0.9694 - loss: 0.0011 - val_accuracy: 0.9672 - val_loss: 9.5348e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 121ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9688 - val_loss: 9.7086e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 122ms/step - accuracy: 0.9691 - loss: 0.0011 - val_accuracy: 0.9671 - val_loss: 9.5740e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 122ms/step - accuracy: 0.9689 - loss: 0.0011 - val_accuracy: 0.9600 - val_loss: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9689 - loss: 0.0011 - val_accuracy: 0.9673 - val_loss: 9.4149e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 123ms/step - accuracy: 0.9688 - loss: 0.0011 - val_accuracy: 0.9687 - val_loss: 9.3652e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9706 - loss: 0.0010 - val_accuracy: 0.9687 - val_loss: 9.7393e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9698 - loss: 0.0011 - val_accuracy: 0.9671 - val_loss: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9690 - loss: 0.0011 - val_accuracy: 0.9692 - val_loss: 9.2938e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 115ms/step - accuracy: 0.9695 - loss: 0.0011 - val_accuracy: 0.9662 - val_loss: 9.8652e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 121ms/step - accuracy: 0.9684 - loss: 0.0011 - val_accuracy: 0.9471 - val_loss: 0.0013\n",
            "Epoch 48/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 124ms/step - accuracy: 0.9692 - loss: 0.0011 - val_accuracy: 0.9675 - val_loss: 0.0010\n",
            "Epoch 49/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9694 - loss: 0.0011 - val_accuracy: 0.9655 - val_loss: 0.0010\n",
            "Epoch 50/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 128ms/step - accuracy: 0.9700 - loss: 0.0011 - val_accuracy: 0.9646 - val_loss: 0.0011\n",
            "Epoch 51/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 124ms/step - accuracy: 0.9700 - loss: 0.0011 - val_accuracy: 0.9676 - val_loss: 9.5363e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 125ms/step - accuracy: 0.9702 - loss: 0.0011 - val_accuracy: 0.9669 - val_loss: 9.4007e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 125ms/step - accuracy: 0.9697 - loss: 0.0011 - val_accuracy: 0.9656 - val_loss: 0.0010\n",
            "Epoch 54/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 125ms/step - accuracy: 0.9694 - loss: 0.0010 - val_accuracy: 0.9658 - val_loss: 0.0010\n",
            "Epoch 55/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 126ms/step - accuracy: 0.9700 - loss: 0.0010 - val_accuracy: 0.9658 - val_loss: 9.8817e-04\n",
            "Epoch 55: early stopping\n",
            "Restoring model weights from the end of the best epoch: 45.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9919  Acc: 0.9841\n",
            "  Fair F1 (val-chosen threshold=0.481): 0.9913  Acc: 0.9829\n",
            "\n",
            "============================================================\n",
            "Test subject: ebc39e6c-2770-4821-a747-c174a7855b30\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 131ms/step - accuracy: 0.9444 - loss: 0.0021 - val_accuracy: 0.9633 - val_loss: 0.0013\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 127ms/step - accuracy: 0.9579 - loss: 0.0016 - val_accuracy: 0.9639 - val_loss: 0.0012\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 127ms/step - accuracy: 0.9595 - loss: 0.0015 - val_accuracy: 0.9643 - val_loss: 0.0012\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 129ms/step - accuracy: 0.9619 - loss: 0.0015 - val_accuracy: 0.9649 - val_loss: 0.0012\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 129ms/step - accuracy: 0.9615 - loss: 0.0014 - val_accuracy: 0.9651 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 130ms/step - accuracy: 0.9625 - loss: 0.0014 - val_accuracy: 0.9649 - val_loss: 0.0012\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 129ms/step - accuracy: 0.9638 - loss: 0.0013 - val_accuracy: 0.9672 - val_loss: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 131ms/step - accuracy: 0.9636 - loss: 0.0014 - val_accuracy: 0.9673 - val_loss: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 133ms/step - accuracy: 0.9643 - loss: 0.0014 - val_accuracy: 0.9665 - val_loss: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 132ms/step - accuracy: 0.9640 - loss: 0.0013 - val_accuracy: 0.9664 - val_loss: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 133ms/step - accuracy: 0.9645 - loss: 0.0013 - val_accuracy: 0.9684 - val_loss: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 131ms/step - accuracy: 0.9640 - loss: 0.0013 - val_accuracy: 0.9665 - val_loss: 0.0013\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 136ms/step - accuracy: 0.9646 - loss: 0.0013 - val_accuracy: 0.9663 - val_loss: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 134ms/step - accuracy: 0.9653 - loss: 0.0013 - val_accuracy: 0.9679 - val_loss: 9.8323e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 136ms/step - accuracy: 0.9657 - loss: 0.0013 - val_accuracy: 0.9679 - val_loss: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 136ms/step - accuracy: 0.9652 - loss: 0.0013 - val_accuracy: 0.9682 - val_loss: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 136ms/step - accuracy: 0.9654 - loss: 0.0013 - val_accuracy: 0.9673 - val_loss: 9.8232e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 134ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9686 - val_loss: 9.7866e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 137ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9677 - val_loss: 9.6353e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 135ms/step - accuracy: 0.9657 - loss: 0.0013 - val_accuracy: 0.9693 - val_loss: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 137ms/step - accuracy: 0.9657 - loss: 0.0013 - val_accuracy: 0.9677 - val_loss: 9.3335e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 136ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9692 - val_loss: 9.7427e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 137ms/step - accuracy: 0.9666 - loss: 0.0012 - val_accuracy: 0.9699 - val_loss: 9.5070e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 136ms/step - accuracy: 0.9661 - loss: 0.0013 - val_accuracy: 0.9676 - val_loss: 9.9408e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 137ms/step - accuracy: 0.9652 - loss: 0.0013 - val_accuracy: 0.9668 - val_loss: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 137ms/step - accuracy: 0.9651 - loss: 0.0013 - val_accuracy: 0.9697 - val_loss: 9.2241e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 139ms/step - accuracy: 0.9667 - loss: 0.0012 - val_accuracy: 0.9713 - val_loss: 9.3755e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 141ms/step - accuracy: 0.9663 - loss: 0.0012 - val_accuracy: 0.9705 - val_loss: 9.7535e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 141ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9705 - val_loss: 9.1104e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 141ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9690 - val_loss: 9.4500e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 143ms/step - accuracy: 0.9671 - loss: 0.0012 - val_accuracy: 0.9710 - val_loss: 9.2696e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 141ms/step - accuracy: 0.9672 - loss: 0.0011 - val_accuracy: 0.9685 - val_loss: 9.6941e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 143ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9706 - val_loss: 9.9641e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 145ms/step - accuracy: 0.9674 - loss: 0.0012 - val_accuracy: 0.9705 - val_loss: 8.9487e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 154ms/step - accuracy: 0.9679 - loss: 0.0011 - val_accuracy: 0.9731 - val_loss: 9.4260e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 152ms/step - accuracy: 0.9670 - loss: 0.0012 - val_accuracy: 0.9702 - val_loss: 9.1710e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 149ms/step - accuracy: 0.9681 - loss: 0.0012 - val_accuracy: 0.9712 - val_loss: 9.1168e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 142ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9706 - val_loss: 9.2586e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 135ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9693 - val_loss: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 133ms/step - accuracy: 0.9688 - loss: 0.0011 - val_accuracy: 0.9706 - val_loss: 9.0470e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 129ms/step - accuracy: 0.9675 - loss: 0.0011 - val_accuracy: 0.9685 - val_loss: 9.6743e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 125ms/step - accuracy: 0.9673 - loss: 0.0011 - val_accuracy: 0.9693 - val_loss: 8.9837e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 120ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9707 - val_loss: 9.3930e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 118ms/step - accuracy: 0.9687 - loss: 0.0011 - val_accuracy: 0.9696 - val_loss: 9.3322e-04\n",
            "Epoch 44: early stopping\n",
            "Restoring model weights from the end of the best epoch: 34.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9904  Acc: 0.9814\n",
            "  Fair F1 (val-chosen threshold=0.502): 0.9904  Acc: 0.9814\n",
            "\n",
            "============================================================\n",
            "Test subject: ebff48bd-b1c8-44e3-af35-0941b6c405b1\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 116ms/step - accuracy: 0.9480 - loss: 0.0021 - val_accuracy: 0.9589 - val_loss: 0.0014\n",
            "Epoch 2/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 110ms/step - accuracy: 0.9591 - loss: 0.0016 - val_accuracy: 0.9655 - val_loss: 0.0011\n",
            "Epoch 3/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 108ms/step - accuracy: 0.9605 - loss: 0.0015 - val_accuracy: 0.9578 - val_loss: 0.0015\n",
            "Epoch 4/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 106ms/step - accuracy: 0.9606 - loss: 0.0015 - val_accuracy: 0.9664 - val_loss: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 104ms/step - accuracy: 0.9619 - loss: 0.0014 - val_accuracy: 0.9662 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 103ms/step - accuracy: 0.9629 - loss: 0.0014 - val_accuracy: 0.9660 - val_loss: 0.0011\n",
            "Epoch 7/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 102ms/step - accuracy: 0.9621 - loss: 0.0014 - val_accuracy: 0.9609 - val_loss: 0.0012\n",
            "Epoch 8/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 101ms/step - accuracy: 0.9646 - loss: 0.0013 - val_accuracy: 0.9623 - val_loss: 0.0012\n",
            "Epoch 9/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 101ms/step - accuracy: 0.9636 - loss: 0.0014 - val_accuracy: 0.9666 - val_loss: 0.0011\n",
            "Epoch 10/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 100ms/step - accuracy: 0.9654 - loss: 0.0013 - val_accuracy: 0.9657 - val_loss: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 99ms/step - accuracy: 0.9655 - loss: 0.0013 - val_accuracy: 0.9664 - val_loss: 0.0011\n",
            "Epoch 12/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 99ms/step - accuracy: 0.9650 - loss: 0.0013 - val_accuracy: 0.9638 - val_loss: 0.0011\n",
            "Epoch 13/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 99ms/step - accuracy: 0.9655 - loss: 0.0013 - val_accuracy: 0.9671 - val_loss: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 99ms/step - accuracy: 0.9651 - loss: 0.0013 - val_accuracy: 0.9671 - val_loss: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 97ms/step - accuracy: 0.9658 - loss: 0.0013 - val_accuracy: 0.9667 - val_loss: 0.0011\n",
            "Epoch 16/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 96ms/step - accuracy: 0.9663 - loss: 0.0013 - val_accuracy: 0.9674 - val_loss: 0.0011\n",
            "Epoch 17/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 96ms/step - accuracy: 0.9662 - loss: 0.0013 - val_accuracy: 0.9682 - val_loss: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 96ms/step - accuracy: 0.9655 - loss: 0.0013 - val_accuracy: 0.9669 - val_loss: 9.8226e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 95ms/step - accuracy: 0.9661 - loss: 0.0013 - val_accuracy: 0.9657 - val_loss: 0.0011\n",
            "Epoch 20/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9666 - loss: 0.0013 - val_accuracy: 0.9686 - val_loss: 9.9150e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9681 - loss: 0.0012 - val_accuracy: 0.9675 - val_loss: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9665 - loss: 0.0012 - val_accuracy: 0.9669 - val_loss: 0.0011\n",
            "Epoch 23/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9664 - loss: 0.0012 - val_accuracy: 0.9678 - val_loss: 9.7070e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9676 - loss: 0.0012 - val_accuracy: 0.9668 - val_loss: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9672 - loss: 0.0012 - val_accuracy: 0.9654 - val_loss: 0.0011\n",
            "Epoch 26/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9676 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 9.9286e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9683 - loss: 0.0012 - val_accuracy: 0.9682 - val_loss: 9.5450e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 94ms/step - accuracy: 0.9681 - loss: 0.0012 - val_accuracy: 0.9684 - val_loss: 9.9428e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9685 - loss: 0.0012 - val_accuracy: 0.9684 - val_loss: 9.9334e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9666 - loss: 0.0012 - val_accuracy: 0.9679 - val_loss: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9682 - loss: 0.0011 - val_accuracy: 0.9668 - val_loss: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9678 - loss: 0.0012 - val_accuracy: 0.9614 - val_loss: 0.0011\n",
            "Epoch 33/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9686 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 9.4257e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9688 - loss: 0.0012 - val_accuracy: 0.9688 - val_loss: 9.1902e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9685 - loss: 0.0011 - val_accuracy: 0.9678 - val_loss: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9691 - loss: 0.0012 - val_accuracy: 0.9706 - val_loss: 9.8270e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9693 - loss: 0.0011 - val_accuracy: 0.9675 - val_loss: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9686 - loss: 0.0011 - val_accuracy: 0.9689 - val_loss: 9.7435e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 94ms/step - accuracy: 0.9698 - loss: 0.0011 - val_accuracy: 0.9685 - val_loss: 9.7925e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9698 - loss: 0.0011 - val_accuracy: 0.9698 - val_loss: 9.4843e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9701 - loss: 0.0011 - val_accuracy: 0.9697 - val_loss: 9.5006e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 92ms/step - accuracy: 0.9694 - loss: 0.0012 - val_accuracy: 0.9679 - val_loss: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 92ms/step - accuracy: 0.9690 - loss: 0.0011 - val_accuracy: 0.9701 - val_loss: 9.5279e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9694 - loss: 0.0011 - val_accuracy: 0.9627 - val_loss: 0.0011\n",
            "Epoch 44: early stopping\n",
            "Restoring model weights from the end of the best epoch: 34.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9856  Acc: 0.9719\n",
            "  Fair F1 (val-chosen threshold=0.493): 0.9860  Acc: 0.9727\n",
            "\n",
            "============================================================\n",
            "Test subject: fa94190b-92d3-484c-8133-744b797dfc81\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 90ms/step - accuracy: 0.9439 - loss: 0.0022 - val_accuracy: 0.9615 - val_loss: 0.0013\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9570 - loss: 0.0016 - val_accuracy: 0.9624 - val_loss: 0.0013\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9595 - loss: 0.0015 - val_accuracy: 0.9662 - val_loss: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9607 - loss: 0.0014 - val_accuracy: 0.9679 - val_loss: 9.9194e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9600 - loss: 0.0015 - val_accuracy: 0.9665 - val_loss: 0.0011\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9615 - loss: 0.0014 - val_accuracy: 0.9615 - val_loss: 0.0012\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9636 - loss: 0.0014 - val_accuracy: 0.9684 - val_loss: 0.0011\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 90ms/step - accuracy: 0.9620 - loss: 0.0014 - val_accuracy: 0.9671 - val_loss: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9636 - loss: 0.0013 - val_accuracy: 0.9675 - val_loss: 9.6798e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9637 - loss: 0.0013 - val_accuracy: 0.9657 - val_loss: 0.0011\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9635 - loss: 0.0013 - val_accuracy: 0.9685 - val_loss: 9.5706e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9650 - loss: 0.0013 - val_accuracy: 0.9682 - val_loss: 9.6460e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9659 - loss: 0.0013 - val_accuracy: 0.9623 - val_loss: 0.0011\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9649 - loss: 0.0013 - val_accuracy: 0.9634 - val_loss: 0.0011\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 88ms/step - accuracy: 0.9648 - loss: 0.0013 - val_accuracy: 0.9680 - val_loss: 9.6108e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9661 - loss: 0.0012 - val_accuracy: 0.9691 - val_loss: 9.6409e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 88ms/step - accuracy: 0.9648 - loss: 0.0012 - val_accuracy: 0.9641 - val_loss: 0.0011\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 88ms/step - accuracy: 0.9648 - loss: 0.0013 - val_accuracy: 0.9625 - val_loss: 0.0012\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 88ms/step - accuracy: 0.9660 - loss: 0.0013 - val_accuracy: 0.9677 - val_loss: 9.6457e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9661 - loss: 0.0012 - val_accuracy: 0.9685 - val_loss: 9.8212e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 87ms/step - accuracy: 0.9673 - loss: 0.0012 - val_accuracy: 0.9679 - val_loss: 9.6507e-04\n",
            "Epoch 21: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.9893  Acc: 0.9792\n",
            "  Fair F1 (val-chosen threshold=0.495): 0.9909  Acc: 0.9824\n"
          ]
        }
      ],
      "source": [
        "all_y_test_list = []\n",
        "all_y_test_prob_list = []\n",
        "for test_subject in subjects:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Test subject: {test_subject}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    test_dfs = [df for df in labeled_dfs if df[\"subject\"].iloc[0] == test_subject]\n",
        "    train_dfs = [df for df in labeled_dfs if df[\"subject\"].iloc[0] != test_subject]\n",
        "\n",
        "    X_seq_train, X_feat_train, y_train = [], [], []\n",
        "    for df in train_dfs:\n",
        "        mag_seq, mag_feat, hum_feat, labels = create_windows(df, WINDOW_SIZE, STEP_SIZE)\n",
        "        X_seq_train.append(mag_seq)\n",
        "        X_feat_train.append(np.hstack([mag_feat, hum_feat]))\n",
        "        y_train.append(labels)\n",
        "    X_seq_train = np.concatenate(X_seq_train, axis=0)\n",
        "    X_feat_train = np.concatenate(X_feat_train, axis=0)\n",
        "    y_train = np.concatenate(y_train, axis=0)\n",
        "\n",
        "    X_seq_test, X_feat_test, y_test = [], [], []\n",
        "    for df in test_dfs:\n",
        "        mag_seq, mag_feat, hum_feat, labels = create_windows(df, WINDOW_SIZE, STEP_SIZE)\n",
        "        X_seq_test.append(mag_seq)\n",
        "        X_feat_test.append(np.hstack([mag_feat, hum_feat]))\n",
        "        y_test.append(labels)\n",
        "    X_seq_test = np.concatenate(X_seq_test, axis=0)\n",
        "    X_feat_test = np.concatenate(X_feat_test, axis=0)\n",
        "    y_test = np.concatenate(y_test, axis=0)\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    val_size = int(n_train * VAL_FRACTION)\n",
        "    idx = np.arange(n_train)\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(idx)\n",
        "    train_idx, val_idx = idx[val_size:], idx[:val_size]\n",
        "\n",
        "    X_seq_tr, X_seq_val = X_seq_train[train_idx], X_seq_train[val_idx]\n",
        "    X_feat_tr, X_feat_val = X_feat_train[train_idx], X_feat_train[val_idx]\n",
        "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    scaler_seq = StandardScaler()\n",
        "    scaler_feat = StandardScaler()\n",
        "    X_seq_tr_flat = X_seq_tr.reshape(-1, X_seq_tr.shape[-1])\n",
        "    scaler_seq.fit(X_seq_tr_flat)\n",
        "    X_seq_tr = scaler_seq.transform(X_seq_tr_flat).reshape(X_seq_tr.shape)\n",
        "    X_seq_val = scaler_seq.transform(X_seq_val.reshape(-1, X_seq_val.shape[-1])).reshape(X_seq_val.shape)\n",
        "    X_seq_test_norm = scaler_seq.transform(X_seq_test.reshape(-1, X_seq_test.shape[-1])).reshape(X_seq_test.shape)\n",
        "    X_feat_tr = scaler_feat.fit_transform(X_feat_tr)\n",
        "    X_feat_val = scaler_feat.transform(X_feat_val)\n",
        "    X_feat_test_norm = scaler_feat.transform(X_feat_test)\n",
        "\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_tr), y=y_tr)\n",
        "    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "    alpha = 1 - np.mean(y_tr)\n",
        "\n",
        "    sequence_shape = (X_seq_tr.shape[1], X_seq_tr.shape[2])\n",
        "    feature_dim = X_feat_tr.shape[1]\n",
        "    model = build_cnn_lstm_model(sequence_shape, feature_dim)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss=focal_loss(alpha=alpha, gamma=2.0), metrics=['accuracy'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "    model.fit(\n",
        "        [X_seq_tr, X_feat_tr], y_tr,\n",
        "        epochs=100, batch_size=32,\n",
        "        validation_data=([X_seq_val, X_feat_val], y_val),\n",
        "        class_weight=class_weight_dict, callbacks=[early_stopping], verbose=1\n",
        "    )\n",
        "\n",
        "    y_val_prob = model.predict([X_seq_val, X_feat_val], verbose=0)\n",
        "    if hasattr(y_val_prob, 'numpy'):\n",
        "        y_val_prob = y_val_prob.numpy().flatten()\n",
        "    else:\n",
        "        y_val_prob = np.array(y_val_prob).flatten()\n",
        "    optimal_threshold = threshold_from_validation(y_val, y_val_prob)\n",
        "\n",
        "    y_test_prob = model.predict([X_seq_test_norm, X_feat_test_norm], verbose=0)\n",
        "    if hasattr(y_test_prob, 'numpy'):\n",
        "        y_test_prob = y_test_prob.numpy().flatten()\n",
        "    else:\n",
        "        y_test_prob = np.array(y_test_prob).flatten()\n",
        "    all_y_test_list.append(y_test)\n",
        "    all_y_test_prob_list.append(y_test_prob)\n",
        "\n",
        "    y_pred_fixed = apply_fixed_pipeline(y_test_prob, threshold=FIXED_THRESHOLD, min_duration_samples=MIN_DURATION_SAMPLES, step_size=STEP_SIZE)\n",
        "    y_pred_val_threshold = apply_fixed_pipeline(y_test_prob, threshold=optimal_threshold, min_duration_samples=MIN_DURATION_SAMPLES, step_size=STEP_SIZE)\n",
        "\n",
        "    fair_f1_fixed = f1_score(y_test, y_pred_fixed)\n",
        "    fair_acc_fixed = accuracy_score(y_test, y_pred_fixed)\n",
        "    fair_f1_val = f1_score(y_test, y_pred_val_threshold)\n",
        "    fair_acc_val = accuracy_score(y_test, y_pred_val_threshold)\n",
        "\n",
        "    print(f\"  Fair F1 (fixed 0.5 + median filter): {fair_f1_fixed:.4f}  Acc: {fair_acc_fixed:.4f}\")\n",
        "    print(f\"  Fair F1 (val-chosen threshold={optimal_threshold:.3f}): {fair_f1_val:.4f}  Acc: {fair_acc_val:.4f}\")\n",
        "\n",
        "    results.append({\n",
        "        \"subject\": test_subject,\n",
        "        \"fair_f1_fixed\": fair_f1_fixed,\n",
        "        \"fair_acc_fixed\": fair_acc_fixed,\n",
        "        \"fair_f1_val_threshold\": fair_f1_val,\n",
        "        \"fair_acc_val_threshold\": fair_acc_val,\n",
        "        \"val_threshold\": optimal_threshold\n",
        "    })\n",
        "\n",
        "    model.save(os.path.join(save_model_path, f\"compare_swapped_{test_subject}.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "FAIR F1 SUMMARY — SWAPPED LABELS (F1 = no-handwash detection)\n",
            "============================================================\n",
            "                                                     subject  fair_f1_fixed  fair_acc_fixed  fair_f1_val_threshold  fair_acc_val_threshold  val_threshold\n",
            "0   2024-12-04-18-49-30_c5c72868-633a-4672-8bdd-3a457f994ddb       0.957974        0.919781               0.957475                0.918784       0.492592\n",
            "1   2024-12-08-21-41-18_c1291a19-92af-431e-9608-6044389d26b0       0.947223        0.899738               0.947223                0.899738       0.487971\n",
            "2   2024-12-10-19-42-27_4734a243-b638-4004-aa82-c698f3ef7aba       0.963312        0.929249               0.963905                0.930435       0.504665\n",
            "3   2025-01-18-13-08-43_449ee30d-3245-47ca-9769-752cf0d2edb7       0.978622        0.958612               0.979212                0.959866       0.544296\n",
            "4   2025-01-18-22-38-29_37959204-490b-4cd9-b647-94e743071951       0.987331        0.975092               0.970931                0.944059       0.545768\n",
            "5   2025-01-19-18-41-39_c4d73c9a-93b2-4c1b-9f76-492d76f7731d       0.988749        0.977888               0.989600                0.979693       0.558743\n",
            "6   2025-01-19-19-48-01_c2031779-881c-4c5c-9c6e-b3f4d57601a9       0.986649        0.973950               0.986012                0.972689       0.490371\n",
            "7   2025-01-28-21-43-21_e4380fee-3c78-4e38-936f-acd60513e279       0.986157        0.972768               0.985085                0.970700       0.512835\n",
            "8                       34414785-1f38-4ff1-a709-e3bd0f5e7d42       0.993322        0.987060               0.993952                0.988273       0.494346\n",
            "9                       383ea87a-3396-400b-9497-ee6f9ad7c093       0.996506        0.993195               0.994681                0.989592       0.411694\n",
            "10                      6c516a60-1d5e-4d7c-a1dd-158099033fe7       0.991463        0.983708               0.991463                0.983708       0.504906\n",
            "11                      8bb7b2a8-0d9b-4aaa-ad3a-c15fedb2ad31       0.988420        0.977582               0.987583                0.975981       0.527538\n",
            "12                      8f0ce2c4-d123-4c1c-aac2-61844abfa8ca       0.991643        0.983974               0.991897                0.984330       0.442710\n",
            "13                                      Participant_1_Data_4       0.983505        0.968070               0.981186                0.963443       0.442296\n",
            "14                                      Participant_3_Data_1       0.977623        0.956917               0.979743                0.960747       0.420471\n",
            "15                      a43187d2-c663-42c5-8da5-750dbb9b72bd       0.993873        0.988127               0.994772                0.989886       0.527648\n",
            "16                      ab0a6b0c-b0f2-4bda-8806-a4e39175f027       0.991934        0.984146               0.991322                0.982927       0.480727\n",
            "17                      ebc39e6c-2770-4821-a747-c174a7855b30       0.990433        0.981377               0.990433                0.981377       0.501672\n",
            "18                      ebff48bd-b1c8-44e3-af35-0941b6c405b1       0.985630        0.971915               0.986041                0.972706       0.493163\n",
            "19                      fa94190b-92d3-484c-8133-744b797dfc81       0.989265        0.979217               0.990935                0.982414       0.495413\n",
            "\n",
            "--- Means ---\n",
            "Mean Fair F1 [no-handwash] (fixed):     0.9835\n",
            "Mean Fair F1 [no-handwash] (val threshold):   0.9827\n",
            "Mean Fair Accuracy (fixed):                   0.9681\n",
            "Mean Fair Accuracy (val threshold):           0.9666\n",
            "\n",
            "Results saved to /Users/sonalimanoharan/Desktop/scientific_research/hw/fair_model_swapped_labels/compare_swapped_labels_results.csv\n"
          ]
        }
      ],
      "source": [
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FAIR F1 SUMMARY — SWAPPED LABELS (F1 = no-handwash detection)\")\n",
        "print(\"=\"*60)\n",
        "print(df_results.to_string())\n",
        "print(\"\\n--- Means ---\")\n",
        "print(f\"Mean Fair F1 [no-handwash] (fixed):     {df_results['fair_f1_fixed'].mean():.4f}\")\n",
        "print(f\"Mean Fair F1 [no-handwash] (val threshold):   {df_results['fair_f1_val_threshold'].mean():.4f}\")\n",
        "print(f\"Mean Fair Accuracy (fixed):                   {df_results['fair_acc_fixed'].mean():.4f}\")\n",
        "print(f\"Mean Fair Accuracy (val threshold):           {df_results['fair_acc_val_threshold'].mean():.4f}\")\n",
        "df_results.to_csv(os.path.join(save_model_path, \"compare_swapped_labels_results.csv\"), index=False)\n",
        "print(f\"\\nResults saved to {os.path.join(save_model_path, 'compare_swapped_labels_results.csv')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_all = np.concatenate(all_y_test_list)\n",
        "prob_all = np.concatenate(all_y_test_prob_list)\n",
        "fpr, tpr, thresholds = roc_curve(y_all, prob_all)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "J = tpr - fpr\n",
        "optimal_idx = np.argmax(J)\n",
        "optimal_threshold_youden = thresholds[optimal_idx]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
        "axes[0].plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "axes[0].scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=80, zorder=5,\n",
        "                label=f\"Optimal threshold = {optimal_threshold_youden:.3f}\")\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('ROC Curve (pooled test across LOSO) — Swapped labels')\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[1].bar(range(len(df_results)), df_results['val_threshold'], color='steelblue', alpha=0.8)\n",
        "axes[1].axhline(y=optimal_threshold_youden, color='red', linestyle='--', label=f'Youden optimal ({optimal_threshold_youden:.3f})')\n",
        "axes[1].set_xlabel('Subject index')\n",
        "axes[1].set_ylabel('Threshold')\n",
        "axes[1].set_title('Validation-chosen threshold per subject')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hw (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
