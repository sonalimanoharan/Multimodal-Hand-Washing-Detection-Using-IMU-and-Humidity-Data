{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fair F1 Evaluation for Hand Washing Detection\n",
        "\n",
        "Replicates **Untitled1.ipynb** (CNN-LSTM + magnitude + humidity) and evaluates with a **scientifically fair** F1 protocol:\n",
        "\n",
        "1. **Fixed pipeline:** Median filter + **fixed 0.5 threshold** for all test subjects (no tuning on test).\n",
        "2. **Validation-chosen threshold:** In each LOSO fold, train/val split; choose threshold on **validation** only; apply to **test**. No test-set tuning.\n",
        "\n",
        "Reported metrics are comparable to the iWOAR 2025 paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-26 01:49:13.013599: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/Users/sonalimanoharan/Desktop/scientific_research/hw/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(np, \"object\"):\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout,\n",
        "    BatchNormalization, Concatenate\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from scipy.signal import medfilt\n",
        "from glob import glob\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = \"/Users/sonalimanoharan/Desktop/scientific_research/hw\"\n",
        "data_folders = [\"data\", \"new_data\"]\n",
        "label_files = [\"lables/labels.csv\", \"lables/lables_new.csv\"]\n",
        "save_model_path = os.path.join(base_path, \"fair_model\")\n",
        "os.makedirs(save_model_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAMPLING_RATE = 50\n",
        "WINDOW_DURATION = 3\n",
        "WINDOW_SIZE = int(SAMPLING_RATE * WINDOW_DURATION)\n",
        "STEP_SIZE = WINDOW_SIZE // 2\n",
        "MIN_DURATION_SAMPLES = int(1.0 * SAMPLING_RATE)\n",
        "FIXED_THRESHOLD = 0.5\n",
        "VAL_FRACTION = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_humidity(df):\n",
        "    if \"humid\" in df.columns:\n",
        "        artifact_value = 79.1318359375\n",
        "        df[\"humid\"] = df[\"humid\"].replace(artifact_value, np.nan)\n",
        "        df[\"humid\"] = df[\"humid\"].interpolate(method='linear', limit_direction='both')\n",
        "        df[\"humid\"] = df[\"humid\"].ffill().bfill()\n",
        "    return df\n",
        "\n",
        "def load_recs():\n",
        "    all_dfs = []\n",
        "    for data_folder, label_file in zip(data_folders, label_files):\n",
        "        data_path = os.path.join(base_path, data_folder, \"*.csv\")\n",
        "        label_path = os.path.join(base_path, label_file)\n",
        "        for fname in glob(data_path):\n",
        "            df = pd.read_csv(fname)\n",
        "            df = clean_humidity(df)\n",
        "            subject_id = os.path.basename(fname).replace(\".csv\", \"\")\n",
        "            all_dfs.append((fname, df, label_path, subject_id))\n",
        "    return all_dfs\n",
        "\n",
        "def convert_to_binlabel(x):\n",
        "    return 0 if x in [\"Null\", \"dry\"] else 1\n",
        "\n",
        "def apply_labels(dfs):\n",
        "    l_dfs = []\n",
        "    for fname, df, label_path, subject_id in dfs:\n",
        "        label_df = pd.read_csv(label_path)\n",
        "        label_df[\"filename\"] = label_df[\"datetime\"].apply(lambda x: os.path.basename(str(x)).strip())\n",
        "        file_basename = os.path.basename(fname).strip()\n",
        "        matched_row = label_df[label_df[\"filename\"].apply(lambda x: x.endswith(file_basename))]\n",
        "        if matched_row.empty:\n",
        "            continue\n",
        "        df[\"label\"] = \"Null\"\n",
        "        label_info = json.loads(matched_row.iloc[0][\"label\"])\n",
        "        for d in label_info:\n",
        "            df.loc[d[\"start\"]:d[\"end\"], \"label\"] = d[\"timeserieslabels\"][0]\n",
        "        df[\"binlabel\"] = df[\"label\"].apply(convert_to_binlabel)\n",
        "        df[\"subject\"] = subject_id\n",
        "        l_dfs.append(df)\n",
        "    return l_dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_magnitude_features(window):\n",
        "    acc_mag = np.sqrt(window[\"acc_x\"]**2 + window[\"acc_y\"]**2 + window[\"acc_z\"]**2)\n",
        "    gyro_mag = np.sqrt(window[\"gyro_x\"]**2 + window[\"gyro_y\"]**2 + window[\"gyro_z\"]**2)\n",
        "    features = [np.mean(acc_mag), np.std(acc_mag), np.min(acc_mag), np.max(acc_mag),\n",
        "                np.mean(gyro_mag), np.std(gyro_mag), np.min(gyro_mag), np.max(gyro_mag)]\n",
        "    return np.column_stack([acc_mag, gyro_mag]), np.array(features)\n",
        "\n",
        "def extract_humidity_slope(window):\n",
        "    if \"humid\" not in window.columns:\n",
        "        return np.zeros(5)\n",
        "    humid = window[\"humid\"].values\n",
        "    if len(humid) < 2:\n",
        "        return np.zeros(5)\n",
        "    slope = np.diff(humid)\n",
        "    return np.array([np.mean(slope), np.std(slope), np.max(slope), np.min(slope), humid[-1] - humid[0]])\n",
        "\n",
        "def create_windows(df, window_size, step_size):\n",
        "    magnitude_sequences, magnitude_features, humidity_features, labels = [], [], [], []\n",
        "    for start in range(0, len(df) - window_size + 1, step_size):\n",
        "        window = df.iloc[start:start + window_size]\n",
        "        mag_seq, mag_feat = extract_magnitude_features(window)\n",
        "        magnitude_sequences.append(mag_seq)\n",
        "        magnitude_features.append(mag_feat)\n",
        "        humidity_features.append(extract_humidity_slope(window))\n",
        "        label_mode = window[\"binlabel\"].mode()\n",
        "        labels.append(label_mode.iloc[0] if not label_mode.empty else int(window[\"binlabel\"].iloc[0]))\n",
        "    return (np.array(magnitude_sequences), np.array(magnitude_features), np.array(humidity_features), np.array(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def focal_loss(alpha=0.25, gamma=2.0):\n",
        "    def loss(y_true, y_pred):\n",
        "        eps = 1e-7\n",
        "        y_pred = tf.clip_by_value(y_pred, eps, 1.0 - eps)\n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        return -tf.reduce_mean(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
        "    return loss\n",
        "\n",
        "def build_cnn_lstm_model(sequence_shape, feature_dim):\n",
        "    seq_input = Input(shape=sequence_shape, name='magnitude_sequences')\n",
        "    x = Conv1D(64, kernel_size=5, activation='relu', padding='same')(seq_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv1D(64, kernel_size=5, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = LSTM(128, return_sequences=True)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = LSTM(64, return_sequences=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    cnn_lstm_output = Dropout(0.3)(x)\n",
        "    feat_input = Input(shape=(feature_dim,), name='handcrafted_features')\n",
        "    feat_dense = Dense(64, activation='relu')(feat_input)\n",
        "    feat_dense = BatchNormalization()(feat_dense)\n",
        "    feat_output = Dropout(0.3)(feat_dense)\n",
        "    combined = Concatenate()([cnn_lstm_output, feat_output])\n",
        "    combined = Dense(128, activation='relu')(combined)\n",
        "    combined = BatchNormalization()(combined)\n",
        "    combined = Dropout(0.4)(combined)\n",
        "    combined = Dense(64, activation='relu')(combined)\n",
        "    output = Dense(1, activation='sigmoid')(combined)\n",
        "    return Model(inputs=[seq_input, feat_input], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_fixed_pipeline(y_pred_prob, threshold=0.5, kernel_size=5, min_duration_samples=None, step_size=None):\n",
        "    \"\"\"Fair evaluation: median filter + fixed threshold. Optional min-duration rule.\"\"\"\n",
        "    y_pred_smooth = medfilt(y_pred_prob.flatten(), kernel_size=kernel_size)\n",
        "    y_pred_binary = (y_pred_smooth > threshold).astype(int)\n",
        "    if min_duration_samples is not None and step_size is not None:\n",
        "        min_consecutive_windows = max(1, min_duration_samples // step_size)\n",
        "        y_out = y_pred_binary.copy()\n",
        "        i = 0\n",
        "        while i < len(y_out):\n",
        "            if y_out[i] == 1:\n",
        "                start = i\n",
        "                while i < len(y_out) and y_out[i] == 1:\n",
        "                    i += 1\n",
        "                if (i - start) < min_consecutive_windows:\n",
        "                    y_out[start:i] = 0\n",
        "            else:\n",
        "                i += 1\n",
        "        return y_out\n",
        "    return y_pred_binary\n",
        "\n",
        "def threshold_from_validation(y_val, y_val_prob):\n",
        "    \"\"\"Choose threshold that maximizes F1 on validation only.\"\"\"\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_val_prob)\n",
        "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "    best_idx = np.argmax(f1_scores)\n",
        "    return thresholds[best_idx] if best_idx < len(thresholds) else 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Found 20 subjects\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading data...\")\n",
        "all_dfs = load_recs()\n",
        "labeled_dfs = apply_labels(all_dfs)\n",
        "subjects = sorted(set(df[\"subject\"].iloc[0] for df in labeled_dfs))\n",
        "print(f\"Found {len(subjects)} subjects\")\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Test subject: 2024-12-04-18-49-30_c5c72868-633a-4672-8bdd-3a457f994ddb\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 64ms/step - accuracy: 0.9469 - loss: 0.0493 - val_accuracy: 0.9676 - val_loss: 0.0270\n",
            "Epoch 2/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 61ms/step - accuracy: 0.9610 - loss: 0.0379 - val_accuracy: 0.9660 - val_loss: 0.0253\n",
            "Epoch 3/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 68ms/step - accuracy: 0.9626 - loss: 0.0336 - val_accuracy: 0.9681 - val_loss: 0.0224\n",
            "Epoch 4/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 430ms/step - accuracy: 0.9643 - loss: 0.0315 - val_accuracy: 0.9627 - val_loss: 0.0260\n",
            "Epoch 5/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9650 - loss: 0.0308 - val_accuracy: 0.9672 - val_loss: 0.0235\n",
            "Epoch 6/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 64ms/step - accuracy: 0.9652 - loss: 0.0296 - val_accuracy: 0.9696 - val_loss: 0.0238\n",
            "Epoch 7/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 61ms/step - accuracy: 0.9665 - loss: 0.0296 - val_accuracy: 0.9567 - val_loss: 0.0285\n",
            "Epoch 8/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 61ms/step - accuracy: 0.9667 - loss: 0.0301 - val_accuracy: 0.9675 - val_loss: 0.0232\n",
            "Epoch 9/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 63ms/step - accuracy: 0.9679 - loss: 0.0289 - val_accuracy: 0.9691 - val_loss: 0.0229\n",
            "Epoch 10/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9671 - loss: 0.0285 - val_accuracy: 0.9696 - val_loss: 0.0239\n",
            "Epoch 11/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9666 - loss: 0.0289 - val_accuracy: 0.9711 - val_loss: 0.0209\n",
            "Epoch 12/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 68ms/step - accuracy: 0.9686 - loss: 0.0283 - val_accuracy: 0.9672 - val_loss: 0.0243\n",
            "Epoch 13/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9672 - loss: 0.0284 - val_accuracy: 0.9644 - val_loss: 0.0259\n",
            "Epoch 14/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9668 - loss: 0.0290 - val_accuracy: 0.9683 - val_loss: 0.0227\n",
            "Epoch 15/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9682 - loss: 0.0274 - val_accuracy: 0.9711 - val_loss: 0.0206\n",
            "Epoch 16/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 64ms/step - accuracy: 0.9682 - loss: 0.0275 - val_accuracy: 0.9689 - val_loss: 0.0222\n",
            "Epoch 17/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 64ms/step - accuracy: 0.9685 - loss: 0.0267 - val_accuracy: 0.9699 - val_loss: 0.0211\n",
            "Epoch 18/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9680 - loss: 0.0270 - val_accuracy: 0.9634 - val_loss: 0.0238\n",
            "Epoch 19/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 64ms/step - accuracy: 0.9682 - loss: 0.0269 - val_accuracy: 0.9713 - val_loss: 0.0202\n",
            "Epoch 20/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9683 - loss: 0.0274 - val_accuracy: 0.9702 - val_loss: 0.0223\n",
            "Epoch 21/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 64ms/step - accuracy: 0.9674 - loss: 0.0269 - val_accuracy: 0.9706 - val_loss: 0.0207\n",
            "Epoch 22/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 63ms/step - accuracy: 0.9684 - loss: 0.0270 - val_accuracy: 0.9703 - val_loss: 0.0208\n",
            "Epoch 23/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 63ms/step - accuracy: 0.9679 - loss: 0.0265 - val_accuracy: 0.9703 - val_loss: 0.0212\n",
            "Epoch 24/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9694 - loss: 0.0262 - val_accuracy: 0.9698 - val_loss: 0.0203\n",
            "Epoch 25/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9694 - loss: 0.0254 - val_accuracy: 0.9717 - val_loss: 0.0191\n",
            "Epoch 26/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 64ms/step - accuracy: 0.9699 - loss: 0.0262 - val_accuracy: 0.9673 - val_loss: 0.0239\n",
            "Epoch 27/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9692 - loss: 0.0252 - val_accuracy: 0.9684 - val_loss: 0.0211\n",
            "Epoch 28/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9692 - loss: 0.0256 - val_accuracy: 0.9710 - val_loss: 0.0209\n",
            "Epoch 29/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9695 - loss: 0.0262 - val_accuracy: 0.9653 - val_loss: 0.0238\n",
            "Epoch 30/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9704 - loss: 0.0252 - val_accuracy: 0.9694 - val_loss: 0.0213\n",
            "Epoch 31/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9698 - loss: 0.0252 - val_accuracy: 0.9363 - val_loss: 0.0365\n",
            "Epoch 32/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9703 - loss: 0.0255 - val_accuracy: 0.9716 - val_loss: 0.0201\n",
            "Epoch 33/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9701 - loss: 0.0249 - val_accuracy: 0.9674 - val_loss: 0.0219\n",
            "Epoch 34/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9703 - loss: 0.0248 - val_accuracy: 0.9727 - val_loss: 0.0199\n",
            "Epoch 35/100\n",
            "\u001b[1m1163/1163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - accuracy: 0.9707 - loss: 0.0244 - val_accuracy: 0.9730 - val_loss: 0.0202\n",
            "Epoch 35: early stopping\n",
            "Restoring model weights from the end of the best epoch: 25.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.1405  Acc: 0.9208\n",
            "  Fair F1 (val-chosen threshold=0.398): 0.4762  Acc: 0.9397\n",
            "\n",
            "============================================================\n",
            "Test subject: 2024-12-08-21-41-18_c1291a19-92af-431e-9608-6044389d26b0\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - accuracy: 0.9406 - loss: 0.0563 - val_accuracy: 0.9657 - val_loss: 0.0272\n",
            "Epoch 2/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9595 - loss: 0.0368 - val_accuracy: 0.9649 - val_loss: 0.0260\n",
            "Epoch 3/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9611 - loss: 0.0353 - val_accuracy: 0.9589 - val_loss: 0.0293\n",
            "Epoch 4/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9643 - loss: 0.0331 - val_accuracy: 0.9678 - val_loss: 0.0233\n",
            "Epoch 5/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9655 - loss: 0.0314 - val_accuracy: 0.9670 - val_loss: 0.0237\n",
            "Epoch 6/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9675 - loss: 0.0296 - val_accuracy: 0.9631 - val_loss: 0.0249\n",
            "Epoch 7/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9671 - loss: 0.0306 - val_accuracy: 0.9694 - val_loss: 0.0238\n",
            "Epoch 8/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.0298 - val_accuracy: 0.9600 - val_loss: 0.0297\n",
            "Epoch 9/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0291 - val_accuracy: 0.9685 - val_loss: 0.0251\n",
            "Epoch 10/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9674 - loss: 0.0288 - val_accuracy: 0.9653 - val_loss: 0.0249\n",
            "Epoch 11/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0293 - val_accuracy: 0.9671 - val_loss: 0.0233\n",
            "Epoch 12/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0286 - val_accuracy: 0.9680 - val_loss: 0.0226\n",
            "Epoch 13/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9689 - loss: 0.0280 - val_accuracy: 0.9694 - val_loss: 0.0224\n",
            "Epoch 14/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9692 - loss: 0.0271 - val_accuracy: 0.9684 - val_loss: 0.0226\n",
            "Epoch 15/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0280 - val_accuracy: 0.9686 - val_loss: 0.0228\n",
            "Epoch 16/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9687 - loss: 0.0276 - val_accuracy: 0.9682 - val_loss: 0.0228\n",
            "Epoch 17/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - accuracy: 0.9690 - loss: 0.0280 - val_accuracy: 0.9673 - val_loss: 0.0220\n",
            "Epoch 18/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - accuracy: 0.9694 - loss: 0.0269 - val_accuracy: 0.9694 - val_loss: 0.0224\n",
            "Epoch 19/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9694 - loss: 0.0277 - val_accuracy: 0.9674 - val_loss: 0.0219\n",
            "Epoch 20/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9698 - loss: 0.0273 - val_accuracy: 0.9708 - val_loss: 0.0212\n",
            "Epoch 21/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9707 - loss: 0.0270 - val_accuracy: 0.9694 - val_loss: 0.0214\n",
            "Epoch 22/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9699 - loss: 0.0265 - val_accuracy: 0.9691 - val_loss: 0.0206\n",
            "Epoch 23/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 63ms/step - accuracy: 0.9702 - loss: 0.0264 - val_accuracy: 0.9701 - val_loss: 0.0207\n",
            "Epoch 24/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 63ms/step - accuracy: 0.9702 - loss: 0.0262 - val_accuracy: 0.9693 - val_loss: 0.0227\n",
            "Epoch 25/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9708 - loss: 0.0265 - val_accuracy: 0.9698 - val_loss: 0.0216\n",
            "Epoch 26/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 63ms/step - accuracy: 0.9704 - loss: 0.0255 - val_accuracy: 0.9701 - val_loss: 0.0209\n",
            "Epoch 27/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9710 - loss: 0.0265 - val_accuracy: 0.9694 - val_loss: 0.0218\n",
            "Epoch 28/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9709 - loss: 0.0264 - val_accuracy: 0.9706 - val_loss: 0.0213\n",
            "Epoch 29/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9727 - loss: 0.0254 - val_accuracy: 0.9614 - val_loss: 0.0262\n",
            "Epoch 30/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9711 - loss: 0.0263 - val_accuracy: 0.9662 - val_loss: 0.0228\n",
            "Epoch 31/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9711 - loss: 0.0246 - val_accuracy: 0.9676 - val_loss: 0.0224\n",
            "Epoch 32/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9711 - loss: 0.0259 - val_accuracy: 0.9711 - val_loss: 0.0221\n",
            "Epoch 32: early stopping\n",
            "Restoring model weights from the end of the best epoch: 22.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.0753  Acc: 0.9037\n",
            "  Fair F1 (val-chosen threshold=0.395): 0.4564  Acc: 0.9294\n",
            "\n",
            "============================================================\n",
            "Test subject: 2024-12-10-19-42-27_4734a243-b638-4004-aa82-c698f3ef7aba\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 63ms/step - accuracy: 0.9487 - loss: 0.0484 - val_accuracy: 0.9623 - val_loss: 0.0300\n",
            "Epoch 2/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 65ms/step - accuracy: 0.9599 - loss: 0.0372 - val_accuracy: 0.9633 - val_loss: 0.0281\n",
            "Epoch 3/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9622 - loss: 0.0348 - val_accuracy: 0.9653 - val_loss: 0.0274\n",
            "Epoch 4/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - accuracy: 0.9643 - loss: 0.0335 - val_accuracy: 0.9660 - val_loss: 0.0269\n",
            "Epoch 5/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9659 - loss: 0.0312 - val_accuracy: 0.9636 - val_loss: 0.0301\n",
            "Epoch 6/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 65ms/step - accuracy: 0.9650 - loss: 0.0310 - val_accuracy: 0.9602 - val_loss: 0.0320\n",
            "Epoch 7/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9667 - loss: 0.0298 - val_accuracy: 0.9636 - val_loss: 0.0267\n",
            "Epoch 8/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9660 - loss: 0.0297 - val_accuracy: 0.9661 - val_loss: 0.0257\n",
            "Epoch 9/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9679 - loss: 0.0289 - val_accuracy: 0.9677 - val_loss: 0.0245\n",
            "Epoch 10/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9666 - loss: 0.0292 - val_accuracy: 0.9670 - val_loss: 0.0246\n",
            "Epoch 11/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9682 - loss: 0.0274 - val_accuracy: 0.9665 - val_loss: 0.0243\n",
            "Epoch 12/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9668 - loss: 0.0284 - val_accuracy: 0.9652 - val_loss: 0.0250\n",
            "Epoch 13/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9679 - loss: 0.0280 - val_accuracy: 0.9674 - val_loss: 0.0239\n",
            "Epoch 14/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9679 - loss: 0.0286 - val_accuracy: 0.9676 - val_loss: 0.0242\n",
            "Epoch 15/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9683 - loss: 0.0274 - val_accuracy: 0.9679 - val_loss: 0.0234\n",
            "Epoch 16/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9685 - loss: 0.0283 - val_accuracy: 0.9687 - val_loss: 0.0240\n",
            "Epoch 17/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.0278 - val_accuracy: 0.9656 - val_loss: 0.0253\n",
            "Epoch 18/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9687 - loss: 0.0271 - val_accuracy: 0.9699 - val_loss: 0.0225\n",
            "Epoch 19/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9673 - val_loss: 0.0242\n",
            "Epoch 20/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9684 - loss: 0.0274 - val_accuracy: 0.9698 - val_loss: 0.0219\n",
            "Epoch 21/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9689 - loss: 0.0268 - val_accuracy: 0.9662 - val_loss: 0.0252\n",
            "Epoch 22/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9694 - loss: 0.0264 - val_accuracy: 0.9695 - val_loss: 0.0235\n",
            "Epoch 23/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9698 - loss: 0.0268 - val_accuracy: 0.9682 - val_loss: 0.0235\n",
            "Epoch 24/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9690 - loss: 0.0261 - val_accuracy: 0.9604 - val_loss: 0.0270\n",
            "Epoch 25/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9698 - loss: 0.0262 - val_accuracy: 0.9678 - val_loss: 0.0239\n",
            "Epoch 26/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9705 - loss: 0.0255 - val_accuracy: 0.9663 - val_loss: 0.0238\n",
            "Epoch 27/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9708 - loss: 0.0256 - val_accuracy: 0.9692 - val_loss: 0.0225\n",
            "Epoch 28/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9704 - loss: 0.0260 - val_accuracy: 0.9691 - val_loss: 0.0229\n",
            "Epoch 29/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9704 - loss: 0.0254 - val_accuracy: 0.9700 - val_loss: 0.0226\n",
            "Epoch 30/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9704 - loss: 0.0255 - val_accuracy: 0.9677 - val_loss: 0.0238\n",
            "Epoch 30: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.0328  Acc: 0.9300\n",
            "  Fair F1 (val-chosen threshold=0.439): 0.2857  Acc: 0.9407\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-18-13-08-43_449ee30d-3245-47ca-9769-752cf0d2edb7\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - accuracy: 0.9425 - loss: 0.0528 - val_accuracy: 0.9626 - val_loss: 0.0302\n",
            "Epoch 2/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9592 - loss: 0.0379 - val_accuracy: 0.9637 - val_loss: 0.0255\n",
            "Epoch 3/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9631 - loss: 0.0336 - val_accuracy: 0.9645 - val_loss: 0.0251\n",
            "Epoch 4/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9625 - loss: 0.0339 - val_accuracy: 0.9629 - val_loss: 0.0249\n",
            "Epoch 5/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9644 - loss: 0.0328 - val_accuracy: 0.9664 - val_loss: 0.0240\n",
            "Epoch 6/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9638 - loss: 0.0325 - val_accuracy: 0.9642 - val_loss: 0.0260\n",
            "Epoch 7/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9662 - loss: 0.0308 - val_accuracy: 0.9670 - val_loss: 0.0229\n",
            "Epoch 8/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9665 - loss: 0.0306 - val_accuracy: 0.9671 - val_loss: 0.0229\n",
            "Epoch 9/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9661 - loss: 0.0302 - val_accuracy: 0.9667 - val_loss: 0.0227\n",
            "Epoch 10/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9656 - loss: 0.0298 - val_accuracy: 0.9597 - val_loss: 0.0265\n",
            "Epoch 11/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9670 - loss: 0.0300 - val_accuracy: 0.9654 - val_loss: 0.0230\n",
            "Epoch 12/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9663 - loss: 0.0295 - val_accuracy: 0.9657 - val_loss: 0.0242\n",
            "Epoch 13/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9665 - loss: 0.0298 - val_accuracy: 0.9654 - val_loss: 0.0253\n",
            "Epoch 14/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9661 - loss: 0.0298 - val_accuracy: 0.9671 - val_loss: 0.0222\n",
            "Epoch 15/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9673 - loss: 0.0297 - val_accuracy: 0.9665 - val_loss: 0.0224\n",
            "Epoch 16/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9665 - loss: 0.0293 - val_accuracy: 0.9666 - val_loss: 0.0259\n",
            "Epoch 17/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9673 - loss: 0.0287 - val_accuracy: 0.9665 - val_loss: 0.0270\n",
            "Epoch 18/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9673 - loss: 0.0290 - val_accuracy: 0.9656 - val_loss: 0.0249\n",
            "Epoch 19/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0286 - val_accuracy: 0.9689 - val_loss: 0.0226\n",
            "Epoch 20/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9673 - loss: 0.0287 - val_accuracy: 0.9671 - val_loss: 0.0232\n",
            "Epoch 21/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9675 - loss: 0.0284 - val_accuracy: 0.9675 - val_loss: 0.0237\n",
            "Epoch 22/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9691 - loss: 0.0277 - val_accuracy: 0.9682 - val_loss: 0.0226\n",
            "Epoch 23/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0271 - val_accuracy: 0.9706 - val_loss: 0.0211\n",
            "Epoch 24/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0280 - val_accuracy: 0.9686 - val_loss: 0.0233\n",
            "Epoch 25/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9686 - loss: 0.0281 - val_accuracy: 0.9689 - val_loss: 0.0217\n",
            "Epoch 26/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9683 - loss: 0.0278 - val_accuracy: 0.9699 - val_loss: 0.0225\n",
            "Epoch 27/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9675 - loss: 0.0280 - val_accuracy: 0.9668 - val_loss: 0.0233\n",
            "Epoch 28/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9691 - loss: 0.0268 - val_accuracy: 0.9684 - val_loss: 0.0217\n",
            "Epoch 29/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9688 - loss: 0.0274 - val_accuracy: 0.9657 - val_loss: 0.0249\n",
            "Epoch 30/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9698 - loss: 0.0269 - val_accuracy: 0.9712 - val_loss: 0.0220\n",
            "Epoch 31/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9691 - loss: 0.0274 - val_accuracy: 0.9631 - val_loss: 0.0258\n",
            "Epoch 32/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9692 - loss: 0.0270 - val_accuracy: 0.9707 - val_loss: 0.0221\n",
            "Epoch 33/100\n",
            "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9692 - loss: 0.0261 - val_accuracy: 0.9666 - val_loss: 0.0226\n",
            "Epoch 33: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.4557  Acc: 0.9640\n",
            "  Fair F1 (val-chosen threshold=0.467): 0.5529  Acc: 0.9682\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-18-22-38-29_37959204-490b-4cd9-b647-94e743071951\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 63ms/step - accuracy: 0.9450 - loss: 0.0508 - val_accuracy: 0.9623 - val_loss: 0.0317\n",
            "Epoch 2/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9583 - loss: 0.0378 - val_accuracy: 0.9675 - val_loss: 0.0236\n",
            "Epoch 3/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9601 - loss: 0.0352 - val_accuracy: 0.9675 - val_loss: 0.0242\n",
            "Epoch 4/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9609 - loss: 0.0335 - val_accuracy: 0.9686 - val_loss: 0.0238\n",
            "Epoch 5/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9631 - loss: 0.0316 - val_accuracy: 0.9673 - val_loss: 0.0250\n",
            "Epoch 6/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9629 - loss: 0.0317 - val_accuracy: 0.9694 - val_loss: 0.0233\n",
            "Epoch 7/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9642 - loss: 0.0321 - val_accuracy: 0.9682 - val_loss: 0.0230\n",
            "Epoch 8/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9639 - loss: 0.0302 - val_accuracy: 0.9706 - val_loss: 0.0215\n",
            "Epoch 9/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9648 - loss: 0.0303 - val_accuracy: 0.9701 - val_loss: 0.0219\n",
            "Epoch 10/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9632 - loss: 0.0312 - val_accuracy: 0.9676 - val_loss: 0.0280\n",
            "Epoch 11/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9630 - loss: 0.0317 - val_accuracy: 0.9697 - val_loss: 0.0239\n",
            "Epoch 12/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9647 - loss: 0.0303 - val_accuracy: 0.9675 - val_loss: 0.0218\n",
            "Epoch 13/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9649 - loss: 0.0300 - val_accuracy: 0.9668 - val_loss: 0.0243\n",
            "Epoch 14/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9634 - loss: 0.0292 - val_accuracy: 0.9690 - val_loss: 0.0225\n",
            "Epoch 15/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9650 - loss: 0.0292 - val_accuracy: 0.9685 - val_loss: 0.0224\n",
            "Epoch 16/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9653 - loss: 0.0292 - val_accuracy: 0.9699 - val_loss: 0.0231\n",
            "Epoch 17/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9651 - loss: 0.0291 - val_accuracy: 0.9705 - val_loss: 0.0229\n",
            "Epoch 18/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9655 - loss: 0.0290 - val_accuracy: 0.9704 - val_loss: 0.0205\n",
            "Epoch 19/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9659 - loss: 0.0286 - val_accuracy: 0.9684 - val_loss: 0.0205\n",
            "Epoch 20/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9650 - loss: 0.0286 - val_accuracy: 0.9699 - val_loss: 0.0202\n",
            "Epoch 21/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9671 - loss: 0.0275 - val_accuracy: 0.9697 - val_loss: 0.0223\n",
            "Epoch 22/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9663 - loss: 0.0285 - val_accuracy: 0.9691 - val_loss: 0.0219\n",
            "Epoch 23/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9662 - loss: 0.0280 - val_accuracy: 0.9716 - val_loss: 0.0210\n",
            "Epoch 24/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9655 - loss: 0.0284 - val_accuracy: 0.9718 - val_loss: 0.0208\n",
            "Epoch 25/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0286 - val_accuracy: 0.9707 - val_loss: 0.0203\n",
            "Epoch 26/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0270 - val_accuracy: 0.9731 - val_loss: 0.0203\n",
            "Epoch 27/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9663 - loss: 0.0276 - val_accuracy: 0.9703 - val_loss: 0.0203\n",
            "Epoch 28/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0280 - val_accuracy: 0.9711 - val_loss: 0.0223\n",
            "Epoch 29/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9666 - loss: 0.0267 - val_accuracy: 0.9713 - val_loss: 0.0211\n",
            "Epoch 30/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0276 - val_accuracy: 0.9721 - val_loss: 0.0199\n",
            "Epoch 31/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9678 - loss: 0.0266 - val_accuracy: 0.9722 - val_loss: 0.0210\n",
            "Epoch 32/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9674 - loss: 0.0267 - val_accuracy: 0.9732 - val_loss: 0.0201\n",
            "Epoch 33/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9673 - loss: 0.0266 - val_accuracy: 0.9741 - val_loss: 0.0207\n",
            "Epoch 34/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9670 - loss: 0.0263 - val_accuracy: 0.9732 - val_loss: 0.0192\n",
            "Epoch 35/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.0269 - val_accuracy: 0.9731 - val_loss: 0.0206\n",
            "Epoch 36/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9668 - loss: 0.0270 - val_accuracy: 0.9696 - val_loss: 0.0226\n",
            "Epoch 37/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9675 - loss: 0.0265 - val_accuracy: 0.9745 - val_loss: 0.0201\n",
            "Epoch 38/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9672 - loss: 0.0260 - val_accuracy: 0.9722 - val_loss: 0.0202\n",
            "Epoch 39/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9677 - loss: 0.0266 - val_accuracy: 0.9696 - val_loss: 0.0220\n",
            "Epoch 40/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9670 - loss: 0.0267 - val_accuracy: 0.9727 - val_loss: 0.0209\n",
            "Epoch 41/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9687 - loss: 0.0257 - val_accuracy: 0.9721 - val_loss: 0.0204\n",
            "Epoch 42/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9688 - loss: 0.0257 - val_accuracy: 0.9742 - val_loss: 0.0203\n",
            "Epoch 43/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9671 - loss: 0.0254 - val_accuracy: 0.9717 - val_loss: 0.0221\n",
            "Epoch 44/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.0252 - val_accuracy: 0.9737 - val_loss: 0.0198\n",
            "Epoch 44: early stopping\n",
            "Restoring model weights from the end of the best epoch: 34.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.3077  Acc: 0.9633\n",
            "  Fair F1 (val-chosen threshold=0.443): 0.2169  Acc: 0.8938\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-19-18-41-39_c4d73c9a-93b2-4c1b-9f76-492d76f7731d\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - accuracy: 0.9433 - loss: 0.0531 - val_accuracy: 0.9592 - val_loss: 0.0313\n",
            "Epoch 2/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9577 - loss: 0.0391 - val_accuracy: 0.9611 - val_loss: 0.0272\n",
            "Epoch 3/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9595 - loss: 0.0349 - val_accuracy: 0.9607 - val_loss: 0.0273\n",
            "Epoch 4/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9616 - loss: 0.0327 - val_accuracy: 0.9628 - val_loss: 0.0262\n",
            "Epoch 5/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9620 - loss: 0.0326 - val_accuracy: 0.9585 - val_loss: 0.0305\n",
            "Epoch 6/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9627 - loss: 0.0334 - val_accuracy: 0.9627 - val_loss: 0.0283\n",
            "Epoch 7/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9633 - loss: 0.0328 - val_accuracy: 0.9579 - val_loss: 0.0292\n",
            "Epoch 8/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9641 - loss: 0.0313 - val_accuracy: 0.9601 - val_loss: 0.0278\n",
            "Epoch 9/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9645 - loss: 0.0316 - val_accuracy: 0.9614 - val_loss: 0.0273\n",
            "Epoch 10/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9641 - loss: 0.0312 - val_accuracy: 0.9649 - val_loss: 0.0249\n",
            "Epoch 11/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9650 - loss: 0.0301 - val_accuracy: 0.9634 - val_loss: 0.0258\n",
            "Epoch 12/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9655 - loss: 0.0302 - val_accuracy: 0.9619 - val_loss: 0.0261\n",
            "Epoch 13/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9655 - loss: 0.0295 - val_accuracy: 0.9632 - val_loss: 0.0252\n",
            "Epoch 14/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9648 - loss: 0.0299 - val_accuracy: 0.9601 - val_loss: 0.0278\n",
            "Epoch 15/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9658 - loss: 0.0302 - val_accuracy: 0.9635 - val_loss: 0.0247\n",
            "Epoch 16/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9663 - loss: 0.0288 - val_accuracy: 0.9613 - val_loss: 0.0295\n",
            "Epoch 17/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9655 - loss: 0.0285 - val_accuracy: 0.9668 - val_loss: 0.0256\n",
            "Epoch 18/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9666 - loss: 0.0289 - val_accuracy: 0.9660 - val_loss: 0.0242\n",
            "Epoch 19/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9664 - loss: 0.0287 - val_accuracy: 0.9609 - val_loss: 0.0254\n",
            "Epoch 20/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9662 - loss: 0.0278 - val_accuracy: 0.9642 - val_loss: 0.0244\n",
            "Epoch 21/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9670 - loss: 0.0283 - val_accuracy: 0.9652 - val_loss: 0.0244\n",
            "Epoch 22/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9668 - loss: 0.0280 - val_accuracy: 0.9615 - val_loss: 0.0255\n",
            "Epoch 23/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9673 - loss: 0.0284 - val_accuracy: 0.9630 - val_loss: 0.0251\n",
            "Epoch 24/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9673 - loss: 0.0275 - val_accuracy: 0.9649 - val_loss: 0.0238\n",
            "Epoch 25/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9667 - loss: 0.0282 - val_accuracy: 0.9645 - val_loss: 0.0247\n",
            "Epoch 26/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9672 - loss: 0.0271 - val_accuracy: 0.9640 - val_loss: 0.0242\n",
            "Epoch 27/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0276 - val_accuracy: 0.9611 - val_loss: 0.0251\n",
            "Epoch 28/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9672 - loss: 0.0269 - val_accuracy: 0.9659 - val_loss: 0.0233\n",
            "Epoch 29/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9674 - loss: 0.0269 - val_accuracy: 0.9559 - val_loss: 0.0297\n",
            "Epoch 30/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0279 - val_accuracy: 0.9647 - val_loss: 0.0249\n",
            "Epoch 31/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9674 - loss: 0.0272 - val_accuracy: 0.9681 - val_loss: 0.0232\n",
            "Epoch 32/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9681 - loss: 0.0271 - val_accuracy: 0.9669 - val_loss: 0.0234\n",
            "Epoch 33/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9672 - loss: 0.0269 - val_accuracy: 0.9672 - val_loss: 0.0244\n",
            "Epoch 34/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9678 - loss: 0.0266 - val_accuracy: 0.9631 - val_loss: 0.0258\n",
            "Epoch 35/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9676 - loss: 0.0269 - val_accuracy: 0.9669 - val_loss: 0.0242\n",
            "Epoch 36/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.0269 - val_accuracy: 0.9653 - val_loss: 0.0250\n",
            "Epoch 37/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - accuracy: 0.9677 - loss: 0.0270 - val_accuracy: 0.9566 - val_loss: 0.0280\n",
            "Epoch 38/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.0264 - val_accuracy: 0.9684 - val_loss: 0.0230\n",
            "Epoch 39/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9696 - loss: 0.0262 - val_accuracy: 0.9681 - val_loss: 0.0222\n",
            "Epoch 40/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9527 - val_loss: 0.0273\n",
            "Epoch 41/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9685 - loss: 0.0264 - val_accuracy: 0.9611 - val_loss: 0.0262\n",
            "Epoch 42/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9674 - loss: 0.0271 - val_accuracy: 0.9648 - val_loss: 0.0249\n",
            "Epoch 43/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - accuracy: 0.9695 - loss: 0.0266 - val_accuracy: 0.9679 - val_loss: 0.0236\n",
            "Epoch 44/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9692 - loss: 0.0265 - val_accuracy: 0.9671 - val_loss: 0.0227\n",
            "Epoch 45/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9694 - loss: 0.0262 - val_accuracy: 0.9650 - val_loss: 0.0238\n",
            "Epoch 46/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9698 - loss: 0.0254 - val_accuracy: 0.9684 - val_loss: 0.0224\n",
            "Epoch 47/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9694 - loss: 0.0259 - val_accuracy: 0.9609 - val_loss: 0.0254\n",
            "Epoch 48/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9691 - loss: 0.0253 - val_accuracy: 0.9674 - val_loss: 0.0231\n",
            "Epoch 49/100\n",
            "\u001b[1m1158/1158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9697 - loss: 0.0259 - val_accuracy: 0.9662 - val_loss: 0.0236\n",
            "Epoch 49: early stopping\n",
            "Restoring model weights from the end of the best epoch: 39.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.5055  Acc: 0.9797\n",
            "  Fair F1 (val-chosen threshold=0.429): 0.6466  Acc: 0.9788\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-19-19-48-01_c2031779-881c-4c5c-9c6e-b3f4d57601a9\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 63ms/step - accuracy: 0.9407 - loss: 0.0541 - val_accuracy: 0.9612 - val_loss: 0.0300\n",
            "Epoch 2/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9588 - loss: 0.0376 - val_accuracy: 0.9610 - val_loss: 0.0280\n",
            "Epoch 3/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9599 - loss: 0.0382 - val_accuracy: 0.9612 - val_loss: 0.0306\n",
            "Epoch 4/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9619 - loss: 0.0346 - val_accuracy: 0.9623 - val_loss: 0.0285\n",
            "Epoch 5/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9639 - loss: 0.0326 - val_accuracy: 0.9598 - val_loss: 0.0282\n",
            "Epoch 6/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9633 - loss: 0.0336 - val_accuracy: 0.9621 - val_loss: 0.0258\n",
            "Epoch 7/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9648 - loss: 0.0323 - val_accuracy: 0.9614 - val_loss: 0.0252\n",
            "Epoch 8/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9653 - loss: 0.0314 - val_accuracy: 0.9596 - val_loss: 0.0268\n",
            "Epoch 9/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9654 - loss: 0.0314 - val_accuracy: 0.9634 - val_loss: 0.0250\n",
            "Epoch 10/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9651 - loss: 0.0307 - val_accuracy: 0.9627 - val_loss: 0.0249\n",
            "Epoch 11/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9656 - loss: 0.0306 - val_accuracy: 0.9643 - val_loss: 0.0248\n",
            "Epoch 12/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9662 - loss: 0.0302 - val_accuracy: 0.9498 - val_loss: 0.0322\n",
            "Epoch 13/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9657 - loss: 0.0298 - val_accuracy: 0.9642 - val_loss: 0.0242\n",
            "Epoch 14/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0293 - val_accuracy: 0.9656 - val_loss: 0.0242\n",
            "Epoch 15/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9663 - loss: 0.0290 - val_accuracy: 0.9621 - val_loss: 0.0287\n",
            "Epoch 16/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9663 - loss: 0.0293 - val_accuracy: 0.9659 - val_loss: 0.0234\n",
            "Epoch 17/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9672 - loss: 0.0287 - val_accuracy: 0.9634 - val_loss: 0.0242\n",
            "Epoch 18/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0285 - val_accuracy: 0.9471 - val_loss: 0.0328\n",
            "Epoch 19/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9666 - loss: 0.0296 - val_accuracy: 0.9636 - val_loss: 0.0271\n",
            "Epoch 20/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9674 - loss: 0.0281 - val_accuracy: 0.9660 - val_loss: 0.0230\n",
            "Epoch 21/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9674 - loss: 0.0283 - val_accuracy: 0.9663 - val_loss: 0.0233\n",
            "Epoch 22/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0284 - val_accuracy: 0.9654 - val_loss: 0.0240\n",
            "Epoch 23/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9672 - loss: 0.0271 - val_accuracy: 0.9641 - val_loss: 0.0243\n",
            "Epoch 24/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9683 - loss: 0.0278 - val_accuracy: 0.9618 - val_loss: 0.0276\n",
            "Epoch 25/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9688 - loss: 0.0278 - val_accuracy: 0.9661 - val_loss: 0.0230\n",
            "Epoch 26/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9673 - loss: 0.0278 - val_accuracy: 0.9662 - val_loss: 0.0236\n",
            "Epoch 27/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9683 - loss: 0.0280 - val_accuracy: 0.9666 - val_loss: 0.0230\n",
            "Epoch 28/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9683 - loss: 0.0267 - val_accuracy: 0.9635 - val_loss: 0.0243\n",
            "Epoch 29/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9685 - loss: 0.0274 - val_accuracy: 0.9629 - val_loss: 0.0263\n",
            "Epoch 30/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9689 - loss: 0.0271 - val_accuracy: 0.9651 - val_loss: 0.0247\n",
            "Epoch 31/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0267 - val_accuracy: 0.9666 - val_loss: 0.0235\n",
            "Epoch 32/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9699 - loss: 0.0260 - val_accuracy: 0.9679 - val_loss: 0.0231\n",
            "Epoch 33/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9698 - loss: 0.0268 - val_accuracy: 0.9648 - val_loss: 0.0234\n",
            "Epoch 34/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9697 - loss: 0.0262 - val_accuracy: 0.9678 - val_loss: 0.0225\n",
            "Epoch 35/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9699 - loss: 0.0260 - val_accuracy: 0.9686 - val_loss: 0.0212\n",
            "Epoch 36/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9690 - loss: 0.0261 - val_accuracy: 0.9680 - val_loss: 0.0224\n",
            "Epoch 37/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9702 - loss: 0.0256 - val_accuracy: 0.9669 - val_loss: 0.0218\n",
            "Epoch 38/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9693 - loss: 0.0259 - val_accuracy: 0.9527 - val_loss: 0.0295\n",
            "Epoch 39/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9694 - loss: 0.0271 - val_accuracy: 0.9629 - val_loss: 0.0267\n",
            "Epoch 40/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9696 - loss: 0.0257 - val_accuracy: 0.9660 - val_loss: 0.0241\n",
            "Epoch 41/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9694 - loss: 0.0258 - val_accuracy: 0.9638 - val_loss: 0.0242\n",
            "Epoch 42/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9693 - loss: 0.0260 - val_accuracy: 0.9646 - val_loss: 0.0270\n",
            "Epoch 43/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9694 - loss: 0.0264 - val_accuracy: 0.9664 - val_loss: 0.0233\n",
            "Epoch 44/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9704 - loss: 0.0249 - val_accuracy: 0.9685 - val_loss: 0.0217\n",
            "Epoch 45/100\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9699 - loss: 0.0263 - val_accuracy: 0.9666 - val_loss: 0.0227\n",
            "Epoch 45: early stopping\n",
            "Restoring model weights from the end of the best epoch: 35.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.4602  Acc: 0.9744\n",
            "  Fair F1 (val-chosen threshold=0.419): 0.5970  Acc: 0.9773\n",
            "\n",
            "============================================================\n",
            "Test subject: 2025-01-28-21-43-21_e4380fee-3c78-4e38-936f-acd60513e279\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 62ms/step - accuracy: 0.9453 - loss: 0.0494 - val_accuracy: 0.9645 - val_loss: 0.0261\n",
            "Epoch 2/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 65ms/step - accuracy: 0.9592 - loss: 0.0351 - val_accuracy: 0.9643 - val_loss: 0.0273\n",
            "Epoch 3/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9610 - loss: 0.0337 - val_accuracy: 0.9640 - val_loss: 0.0250\n",
            "Epoch 4/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 65ms/step - accuracy: 0.9610 - loss: 0.0319 - val_accuracy: 0.9659 - val_loss: 0.0238\n",
            "Epoch 5/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9624 - loss: 0.0320 - val_accuracy: 0.9665 - val_loss: 0.0258\n",
            "Epoch 6/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9635 - loss: 0.0325 - val_accuracy: 0.9637 - val_loss: 0.0239\n",
            "Epoch 7/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9641 - loss: 0.0307 - val_accuracy: 0.9620 - val_loss: 0.0288\n",
            "Epoch 8/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9653 - loss: 0.0307 - val_accuracy: 0.9629 - val_loss: 0.0251\n",
            "Epoch 9/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9650 - loss: 0.0307 - val_accuracy: 0.9633 - val_loss: 0.0256\n",
            "Epoch 10/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9645 - loss: 0.0303 - val_accuracy: 0.9648 - val_loss: 0.0230\n",
            "Epoch 11/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9632 - loss: 0.0309 - val_accuracy: 0.9648 - val_loss: 0.0245\n",
            "Epoch 12/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9645 - loss: 0.0295 - val_accuracy: 0.9598 - val_loss: 0.0262\n",
            "Epoch 13/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9665 - loss: 0.0297 - val_accuracy: 0.9631 - val_loss: 0.0255\n",
            "Epoch 14/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9662 - loss: 0.0293 - val_accuracy: 0.9669 - val_loss: 0.0227\n",
            "Epoch 15/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9659 - loss: 0.0285 - val_accuracy: 0.9661 - val_loss: 0.0227\n",
            "Epoch 16/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9661 - loss: 0.0287 - val_accuracy: 0.9650 - val_loss: 0.0225\n",
            "Epoch 17/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0282 - val_accuracy: 0.9668 - val_loss: 0.0219\n",
            "Epoch 18/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0289 - val_accuracy: 0.9648 - val_loss: 0.0238\n",
            "Epoch 19/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9671 - loss: 0.0284 - val_accuracy: 0.9648 - val_loss: 0.0238\n",
            "Epoch 20/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9669 - loss: 0.0280 - val_accuracy: 0.9666 - val_loss: 0.0210\n",
            "Epoch 21/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9673 - loss: 0.0278 - val_accuracy: 0.9666 - val_loss: 0.0225\n",
            "Epoch 22/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9687 - loss: 0.0274 - val_accuracy: 0.9680 - val_loss: 0.0219\n",
            "Epoch 23/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9678 - loss: 0.0280 - val_accuracy: 0.9689 - val_loss: 0.0214\n",
            "Epoch 24/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9673 - loss: 0.0269 - val_accuracy: 0.9628 - val_loss: 0.0240\n",
            "Epoch 25/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9677 - loss: 0.0271 - val_accuracy: 0.9684 - val_loss: 0.0209\n",
            "Epoch 26/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9680 - loss: 0.0263 - val_accuracy: 0.9673 - val_loss: 0.0215\n",
            "Epoch 27/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9683 - loss: 0.0268 - val_accuracy: 0.9645 - val_loss: 0.0240\n",
            "Epoch 28/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9687 - loss: 0.0269 - val_accuracy: 0.9688 - val_loss: 0.0210\n",
            "Epoch 29/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0261 - val_accuracy: 0.9680 - val_loss: 0.0222\n",
            "Epoch 30/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9695 - loss: 0.0255 - val_accuracy: 0.9678 - val_loss: 0.0227\n",
            "Epoch 31/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9686 - loss: 0.0260 - val_accuracy: 0.9656 - val_loss: 0.0230\n",
            "Epoch 32/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9699 - loss: 0.0260 - val_accuracy: 0.9639 - val_loss: 0.0231\n",
            "Epoch 33/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 65ms/step - accuracy: 0.9694 - loss: 0.0261 - val_accuracy: 0.9692 - val_loss: 0.0202\n",
            "Epoch 34/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9704 - loss: 0.0251 - val_accuracy: 0.9705 - val_loss: 0.0205\n",
            "Epoch 35/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9685 - loss: 0.0260 - val_accuracy: 0.9702 - val_loss: 0.0202\n",
            "Epoch 36/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9677 - loss: 0.0257 - val_accuracy: 0.9635 - val_loss: 0.0238\n",
            "Epoch 37/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9704 - loss: 0.0251 - val_accuracy: 0.9589 - val_loss: 0.0265\n",
            "Epoch 38/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9696 - loss: 0.0248 - val_accuracy: 0.9658 - val_loss: 0.0221\n",
            "Epoch 39/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9706 - loss: 0.0253 - val_accuracy: 0.9695 - val_loss: 0.0208\n",
            "Epoch 40/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9704 - loss: 0.0247 - val_accuracy: 0.9696 - val_loss: 0.0206\n",
            "Epoch 41/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9696 - loss: 0.0251 - val_accuracy: 0.9695 - val_loss: 0.0209\n",
            "Epoch 42/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9700 - loss: 0.0246 - val_accuracy: 0.9684 - val_loss: 0.0214\n",
            "Epoch 43/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9706 - loss: 0.0245 - val_accuracy: 0.9697 - val_loss: 0.0213\n",
            "Epoch 44/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9710 - loss: 0.0246 - val_accuracy: 0.9704 - val_loss: 0.0199\n",
            "Epoch 45/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9699 - loss: 0.0248 - val_accuracy: 0.9707 - val_loss: 0.0211\n",
            "Epoch 46/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9702 - loss: 0.0243 - val_accuracy: 0.9660 - val_loss: 0.0234\n",
            "Epoch 47/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9706 - loss: 0.0235 - val_accuracy: 0.9695 - val_loss: 0.0206\n",
            "Epoch 48/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9698 - loss: 0.0241 - val_accuracy: 0.9678 - val_loss: 0.0218\n",
            "Epoch 49/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9700 - loss: 0.0241 - val_accuracy: 0.9634 - val_loss: 0.0238\n",
            "Epoch 50/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9700 - loss: 0.0245 - val_accuracy: 0.9682 - val_loss: 0.0215\n",
            "Epoch 51/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9716 - loss: 0.0240 - val_accuracy: 0.9675 - val_loss: 0.0212\n",
            "Epoch 52/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9714 - loss: 0.0242 - val_accuracy: 0.9684 - val_loss: 0.0213\n",
            "Epoch 53/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9719 - loss: 0.0239 - val_accuracy: 0.9714 - val_loss: 0.0210\n",
            "Epoch 54/100\n",
            "\u001b[1m1141/1141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 66ms/step - accuracy: 0.9723 - loss: 0.0228 - val_accuracy: 0.9688 - val_loss: 0.0207\n",
            "Epoch 54: early stopping\n",
            "Restoring model weights from the end of the best epoch: 44.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.1682  Acc: 0.9693\n",
            "  Fair F1 (val-chosen threshold=0.480): 0.2167  Acc: 0.9676\n",
            "\n",
            "============================================================\n",
            "Test subject: 34414785-1f38-4ff1-a709-e3bd0f5e7d42\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 64ms/step - accuracy: 0.9335 - loss: 0.0599 - val_accuracy: 0.9619 - val_loss: 0.0298\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9568 - loss: 0.0385 - val_accuracy: 0.9614 - val_loss: 0.0286\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9597 - loss: 0.0368 - val_accuracy: 0.9647 - val_loss: 0.0258\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9611 - loss: 0.0341 - val_accuracy: 0.9582 - val_loss: 0.0292\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9613 - loss: 0.0345 - val_accuracy: 0.9648 - val_loss: 0.0252\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9620 - loss: 0.0341 - val_accuracy: 0.9611 - val_loss: 0.0274\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9618 - loss: 0.0315 - val_accuracy: 0.9601 - val_loss: 0.0286\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9630 - loss: 0.0324 - val_accuracy: 0.9656 - val_loss: 0.0241\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9628 - loss: 0.0313 - val_accuracy: 0.9672 - val_loss: 0.0239\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9651 - loss: 0.0310 - val_accuracy: 0.9669 - val_loss: 0.0243\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9652 - loss: 0.0306 - val_accuracy: 0.9649 - val_loss: 0.0246\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9640 - loss: 0.0306 - val_accuracy: 0.9649 - val_loss: 0.0241\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9642 - loss: 0.0310 - val_accuracy: 0.9616 - val_loss: 0.0246\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9657 - loss: 0.0297 - val_accuracy: 0.9673 - val_loss: 0.0241\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9649 - loss: 0.0294 - val_accuracy: 0.9672 - val_loss: 0.0240\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9664 - loss: 0.0296 - val_accuracy: 0.9674 - val_loss: 0.0227\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9654 - loss: 0.0297 - val_accuracy: 0.9594 - val_loss: 0.0290\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9659 - loss: 0.0295 - val_accuracy: 0.9673 - val_loss: 0.0249\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9657 - loss: 0.0296 - val_accuracy: 0.9686 - val_loss: 0.0231\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9662 - loss: 0.0288 - val_accuracy: 0.9674 - val_loss: 0.0243\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9659 - loss: 0.0294 - val_accuracy: 0.9671 - val_loss: 0.0238\n",
            "Epoch 22/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9664 - loss: 0.0287 - val_accuracy: 0.9686 - val_loss: 0.0224\n",
            "Epoch 23/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - accuracy: 0.9670 - loss: 0.0281 - val_accuracy: 0.9693 - val_loss: 0.0217\n",
            "Epoch 24/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9675 - loss: 0.0278 - val_accuracy: 0.9605 - val_loss: 0.0265\n",
            "Epoch 25/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9680 - loss: 0.0279 - val_accuracy: 0.9688 - val_loss: 0.0225\n",
            "Epoch 26/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.0271 - val_accuracy: 0.9660 - val_loss: 0.0235\n",
            "Epoch 27/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9673 - loss: 0.0275 - val_accuracy: 0.9687 - val_loss: 0.0233\n",
            "Epoch 28/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9671 - loss: 0.0278 - val_accuracy: 0.9693 - val_loss: 0.0219\n",
            "Epoch 29/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9672 - loss: 0.0272 - val_accuracy: 0.9680 - val_loss: 0.0233\n",
            "Epoch 30/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9680 - loss: 0.0271 - val_accuracy: 0.9705 - val_loss: 0.0212\n",
            "Epoch 31/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9675 - loss: 0.0275 - val_accuracy: 0.9688 - val_loss: 0.0227\n",
            "Epoch 32/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9673 - loss: 0.0267 - val_accuracy: 0.9701 - val_loss: 0.0230\n",
            "Epoch 33/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9682 - loss: 0.0271 - val_accuracy: 0.9690 - val_loss: 0.0217\n",
            "Epoch 34/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9676 - loss: 0.0269 - val_accuracy: 0.9695 - val_loss: 0.0240\n",
            "Epoch 35/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.0276 - val_accuracy: 0.9715 - val_loss: 0.0219\n",
            "Epoch 36/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9672 - loss: 0.0275 - val_accuracy: 0.9702 - val_loss: 0.0215\n",
            "Epoch 37/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9677 - loss: 0.0264 - val_accuracy: 0.9718 - val_loss: 0.0218\n",
            "Epoch 38/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9688 - loss: 0.0265 - val_accuracy: 0.9702 - val_loss: 0.0231\n",
            "Epoch 39/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9687 - loss: 0.0262 - val_accuracy: 0.9690 - val_loss: 0.0222\n",
            "Epoch 40/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9678 - loss: 0.0279 - val_accuracy: 0.9679 - val_loss: 0.0248\n",
            "Epoch 40: early stopping\n",
            "Restoring model weights from the end of the best epoch: 30.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.8054  Acc: 0.9883\n",
            "  Fair F1 (val-chosen threshold=0.440): 0.7644  Acc: 0.9818\n",
            "\n",
            "============================================================\n",
            "Test subject: 383ea87a-3396-400b-9497-ee6f9ad7c093\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 64ms/step - accuracy: 0.9439 - loss: 0.0506 - val_accuracy: 0.9354 - val_loss: 0.0410\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9563 - loss: 0.0377 - val_accuracy: 0.9647 - val_loss: 0.0267\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9601 - loss: 0.0356 - val_accuracy: 0.9604 - val_loss: 0.0334\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9604 - loss: 0.0349 - val_accuracy: 0.9647 - val_loss: 0.0302\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9599 - loss: 0.0371 - val_accuracy: 0.9660 - val_loss: 0.0264\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9617 - loss: 0.0348 - val_accuracy: 0.9645 - val_loss: 0.0270\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9619 - loss: 0.0330 - val_accuracy: 0.9635 - val_loss: 0.0256\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9627 - loss: 0.0331 - val_accuracy: 0.9665 - val_loss: 0.0232\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9625 - loss: 0.0315 - val_accuracy: 0.9650 - val_loss: 0.0263\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9641 - loss: 0.0301 - val_accuracy: 0.9657 - val_loss: 0.0250\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9640 - loss: 0.0303 - val_accuracy: 0.9673 - val_loss: 0.0247\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9636 - loss: 0.0305 - val_accuracy: 0.9646 - val_loss: 0.0259\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9645 - loss: 0.0304 - val_accuracy: 0.9661 - val_loss: 0.0253\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9655 - loss: 0.0294 - val_accuracy: 0.9671 - val_loss: 0.0234\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9650 - loss: 0.0301 - val_accuracy: 0.9670 - val_loss: 0.0249\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9636 - loss: 0.0310 - val_accuracy: 0.9684 - val_loss: 0.0229\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9661 - loss: 0.0293 - val_accuracy: 0.9686 - val_loss: 0.0229\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9657 - loss: 0.0290 - val_accuracy: 0.9663 - val_loss: 0.0243\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9657 - loss: 0.0293 - val_accuracy: 0.9626 - val_loss: 0.0260\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9660 - loss: 0.0287 - val_accuracy: 0.9670 - val_loss: 0.0238\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9671 - loss: 0.0287 - val_accuracy: 0.9679 - val_loss: 0.0239\n",
            "Epoch 22/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9660 - loss: 0.0281 - val_accuracy: 0.9675 - val_loss: 0.0232\n",
            "Epoch 23/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9659 - loss: 0.0281 - val_accuracy: 0.9685 - val_loss: 0.0219\n",
            "Epoch 24/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9674 - loss: 0.0282 - val_accuracy: 0.9672 - val_loss: 0.0230\n",
            "Epoch 25/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9662 - loss: 0.0279 - val_accuracy: 0.9662 - val_loss: 0.0238\n",
            "Epoch 26/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9664 - loss: 0.0277 - val_accuracy: 0.9689 - val_loss: 0.0227\n",
            "Epoch 27/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9668 - loss: 0.0286 - val_accuracy: 0.9656 - val_loss: 0.0233\n",
            "Epoch 28/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9661 - loss: 0.0278 - val_accuracy: 0.9648 - val_loss: 0.0241\n",
            "Epoch 29/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9663 - loss: 0.0279 - val_accuracy: 0.9662 - val_loss: 0.0248\n",
            "Epoch 30/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 78ms/step - accuracy: 0.9666 - loss: 0.0276 - val_accuracy: 0.9679 - val_loss: 0.0234\n",
            "Epoch 31/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 79ms/step - accuracy: 0.9670 - loss: 0.0278 - val_accuracy: 0.9691 - val_loss: 0.0244\n",
            "Epoch 32/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 80ms/step - accuracy: 0.9678 - loss: 0.0274 - val_accuracy: 0.9678 - val_loss: 0.0228\n",
            "Epoch 33/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 80ms/step - accuracy: 0.9678 - loss: 0.0276 - val_accuracy: 0.9681 - val_loss: 0.0226\n",
            "Epoch 33: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.7368  Acc: 0.9880\n",
            "  Fair F1 (val-chosen threshold=0.423): 0.8714  Acc: 0.9928\n",
            "\n",
            "============================================================\n",
            "Test subject: 6c516a60-1d5e-4d7c-a1dd-158099033fe7\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 82ms/step - accuracy: 0.9479 - loss: 0.0482 - val_accuracy: 0.9615 - val_loss: 0.0284\n",
            "Epoch 2/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9587 - loss: 0.0404 - val_accuracy: 0.9611 - val_loss: 0.0268\n",
            "Epoch 3/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9601 - loss: 0.0367 - val_accuracy: 0.9622 - val_loss: 0.0256\n",
            "Epoch 4/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 82ms/step - accuracy: 0.9603 - loss: 0.0359 - val_accuracy: 0.9643 - val_loss: 0.0254\n",
            "Epoch 5/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9629 - loss: 0.0333 - val_accuracy: 0.9653 - val_loss: 0.0273\n",
            "Epoch 6/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 84ms/step - accuracy: 0.9634 - loss: 0.0331 - val_accuracy: 0.9646 - val_loss: 0.0296\n",
            "Epoch 7/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 86ms/step - accuracy: 0.9632 - loss: 0.0328 - val_accuracy: 0.9637 - val_loss: 0.0247\n",
            "Epoch 8/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 85ms/step - accuracy: 0.9627 - loss: 0.0328 - val_accuracy: 0.9681 - val_loss: 0.0243\n",
            "Epoch 9/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 87ms/step - accuracy: 0.9644 - loss: 0.0318 - val_accuracy: 0.9632 - val_loss: 0.0260\n",
            "Epoch 10/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 89ms/step - accuracy: 0.9646 - loss: 0.0324 - val_accuracy: 0.9629 - val_loss: 0.0270\n",
            "Epoch 11/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9637 - loss: 0.0307 - val_accuracy: 0.9668 - val_loss: 0.0248\n",
            "Epoch 12/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 95ms/step - accuracy: 0.9655 - loss: 0.0315 - val_accuracy: 0.9663 - val_loss: 0.0233\n",
            "Epoch 13/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9658 - loss: 0.0311 - val_accuracy: 0.9671 - val_loss: 0.0226\n",
            "Epoch 14/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 89ms/step - accuracy: 0.9654 - loss: 0.0307 - val_accuracy: 0.9644 - val_loss: 0.0267\n",
            "Epoch 15/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 91ms/step - accuracy: 0.9638 - loss: 0.0315 - val_accuracy: 0.9573 - val_loss: 0.0270\n",
            "Epoch 16/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 90ms/step - accuracy: 0.9637 - loss: 0.0303 - val_accuracy: 0.9676 - val_loss: 0.0239\n",
            "Epoch 17/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 91ms/step - accuracy: 0.9644 - loss: 0.0301 - val_accuracy: 0.9665 - val_loss: 0.0228\n",
            "Epoch 18/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9654 - loss: 0.0298 - val_accuracy: 0.9642 - val_loss: 0.0227\n",
            "Epoch 19/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9658 - loss: 0.0301 - val_accuracy: 0.9660 - val_loss: 0.0236\n",
            "Epoch 20/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 91ms/step - accuracy: 0.9650 - loss: 0.0293 - val_accuracy: 0.9684 - val_loss: 0.0231\n",
            "Epoch 21/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9665 - loss: 0.0293 - val_accuracy: 0.9689 - val_loss: 0.0225\n",
            "Epoch 22/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9661 - loss: 0.0298 - val_accuracy: 0.9653 - val_loss: 0.0242\n",
            "Epoch 23/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 91ms/step - accuracy: 0.9648 - loss: 0.0298 - val_accuracy: 0.9690 - val_loss: 0.0215\n",
            "Epoch 24/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 92ms/step - accuracy: 0.9671 - loss: 0.0291 - val_accuracy: 0.9693 - val_loss: 0.0246\n",
            "Epoch 25/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9661 - loss: 0.0292 - val_accuracy: 0.9686 - val_loss: 0.0235\n",
            "Epoch 26/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 93ms/step - accuracy: 0.9664 - loss: 0.0284 - val_accuracy: 0.9668 - val_loss: 0.0229\n",
            "Epoch 27/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 91ms/step - accuracy: 0.9672 - loss: 0.0286 - val_accuracy: 0.9683 - val_loss: 0.0243\n",
            "Epoch 28/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 83ms/step - accuracy: 0.9667 - loss: 0.0283 - val_accuracy: 0.9693 - val_loss: 0.0210\n",
            "Epoch 29/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 81ms/step - accuracy: 0.9664 - loss: 0.0280 - val_accuracy: 0.9649 - val_loss: 0.0230\n",
            "Epoch 30/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 79ms/step - accuracy: 0.9657 - loss: 0.0280 - val_accuracy: 0.9704 - val_loss: 0.0216\n",
            "Epoch 31/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 80ms/step - accuracy: 0.9667 - loss: 0.0279 - val_accuracy: 0.9708 - val_loss: 0.0220\n",
            "Epoch 32/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 77ms/step - accuracy: 0.9677 - loss: 0.0273 - val_accuracy: 0.9694 - val_loss: 0.0216\n",
            "Epoch 33/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 77ms/step - accuracy: 0.9677 - loss: 0.0275 - val_accuracy: 0.9689 - val_loss: 0.0208\n",
            "Epoch 34/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 76ms/step - accuracy: 0.9686 - loss: 0.0277 - val_accuracy: 0.9679 - val_loss: 0.0234\n",
            "Epoch 35/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - accuracy: 0.9672 - loss: 0.0269 - val_accuracy: 0.9706 - val_loss: 0.0204\n",
            "Epoch 36/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9682 - loss: 0.0267 - val_accuracy: 0.9696 - val_loss: 0.0216\n",
            "Epoch 37/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 75ms/step - accuracy: 0.9676 - loss: 0.0273 - val_accuracy: 0.9696 - val_loss: 0.0223\n",
            "Epoch 38/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9679 - loss: 0.0276 - val_accuracy: 0.9660 - val_loss: 0.0245\n",
            "Epoch 39/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9676 - loss: 0.0279 - val_accuracy: 0.9697 - val_loss: 0.0219\n",
            "Epoch 40/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 74ms/step - accuracy: 0.9673 - loss: 0.0270 - val_accuracy: 0.9676 - val_loss: 0.0231\n",
            "Epoch 41/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 73ms/step - accuracy: 0.9684 - loss: 0.0267 - val_accuracy: 0.9669 - val_loss: 0.0234\n",
            "Epoch 42/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 72ms/step - accuracy: 0.9680 - loss: 0.0269 - val_accuracy: 0.9695 - val_loss: 0.0208\n",
            "Epoch 43/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9685 - loss: 0.0268 - val_accuracy: 0.9717 - val_loss: 0.0208\n",
            "Epoch 44/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9679 - loss: 0.0263 - val_accuracy: 0.9728 - val_loss: 0.0209\n",
            "Epoch 45/100\n",
            "\u001b[1m1149/1149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 72ms/step - accuracy: 0.9684 - loss: 0.0265 - val_accuracy: 0.9708 - val_loss: 0.0216\n",
            "Epoch 45: early stopping\n",
            "Restoring model weights from the end of the best epoch: 35.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.8416  Acc: 0.9864\n",
            "  Fair F1 (val-chosen threshold=0.442): 0.7747  Acc: 0.9779\n",
            "\n",
            "============================================================\n",
            "Test subject: 8bb7b2a8-0d9b-4aaa-ad3a-c15fedb2ad31\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 70ms/step - accuracy: 0.9406 - loss: 0.0550 - val_accuracy: 0.9649 - val_loss: 0.0290\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9561 - loss: 0.0400 - val_accuracy: 0.9645 - val_loss: 0.0268\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9594 - loss: 0.0348 - val_accuracy: 0.9644 - val_loss: 0.0299\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9622 - loss: 0.0332 - val_accuracy: 0.9653 - val_loss: 0.0244\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9626 - loss: 0.0329 - val_accuracy: 0.9634 - val_loss: 0.0259\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 71ms/step - accuracy: 0.9620 - loss: 0.0333 - val_accuracy: 0.9654 - val_loss: 0.0248\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9630 - loss: 0.0327 - val_accuracy: 0.9587 - val_loss: 0.0306\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9632 - loss: 0.0317 - val_accuracy: 0.9660 - val_loss: 0.0243\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9642 - loss: 0.0312 - val_accuracy: 0.9628 - val_loss: 0.0249\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9636 - loss: 0.0304 - val_accuracy: 0.9576 - val_loss: 0.0289\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9655 - loss: 0.0298 - val_accuracy: 0.9653 - val_loss: 0.0247\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9642 - loss: 0.0303 - val_accuracy: 0.9662 - val_loss: 0.0243\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 71ms/step - accuracy: 0.9654 - loss: 0.0300 - val_accuracy: 0.9661 - val_loss: 0.0257\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 71ms/step - accuracy: 0.9672 - loss: 0.0294 - val_accuracy: 0.9674 - val_loss: 0.0227\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9659 - loss: 0.0301 - val_accuracy: 0.9677 - val_loss: 0.0241\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9661 - loss: 0.0295 - val_accuracy: 0.9550 - val_loss: 0.0303\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9669 - loss: 0.0284 - val_accuracy: 0.9677 - val_loss: 0.0226\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 71ms/step - accuracy: 0.9656 - loss: 0.0289 - val_accuracy: 0.9581 - val_loss: 0.0286\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9660 - loss: 0.0298 - val_accuracy: 0.9651 - val_loss: 0.0240\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9663 - loss: 0.0286 - val_accuracy: 0.9663 - val_loss: 0.0234\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9686 - loss: 0.0276 - val_accuracy: 0.9676 - val_loss: 0.0228\n",
            "Epoch 22/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9676 - loss: 0.0283 - val_accuracy: 0.9656 - val_loss: 0.0231\n",
            "Epoch 23/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9671 - loss: 0.0286 - val_accuracy: 0.9653 - val_loss: 0.0236\n",
            "Epoch 24/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9675 - loss: 0.0277 - val_accuracy: 0.9660 - val_loss: 0.0242\n",
            "Epoch 25/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9665 - loss: 0.0274 - val_accuracy: 0.9679 - val_loss: 0.0224\n",
            "Epoch 26/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9673 - loss: 0.0283 - val_accuracy: 0.9681 - val_loss: 0.0224\n",
            "Epoch 27/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9681 - loss: 0.0272 - val_accuracy: 0.9689 - val_loss: 0.0214\n",
            "Epoch 28/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9679 - loss: 0.0269 - val_accuracy: 0.9673 - val_loss: 0.0227\n",
            "Epoch 29/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9681 - loss: 0.0277 - val_accuracy: 0.9670 - val_loss: 0.0229\n",
            "Epoch 30/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9678 - loss: 0.0271 - val_accuracy: 0.9710 - val_loss: 0.0212\n",
            "Epoch 31/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9684 - loss: 0.0268 - val_accuracy: 0.9687 - val_loss: 0.0228\n",
            "Epoch 32/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9684 - loss: 0.0272 - val_accuracy: 0.9700 - val_loss: 0.0220\n",
            "Epoch 33/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9682 - loss: 0.0266 - val_accuracy: 0.9692 - val_loss: 0.0209\n",
            "Epoch 34/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9678 - loss: 0.0269 - val_accuracy: 0.9649 - val_loss: 0.0239\n",
            "Epoch 35/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9695 - loss: 0.0269 - val_accuracy: 0.9637 - val_loss: 0.0247\n",
            "Epoch 36/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9688 - loss: 0.0263 - val_accuracy: 0.9628 - val_loss: 0.0253\n",
            "Epoch 37/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9690 - loss: 0.0262 - val_accuracy: 0.9607 - val_loss: 0.0263\n",
            "Epoch 38/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9691 - loss: 0.0264 - val_accuracy: 0.9697 - val_loss: 0.0224\n",
            "Epoch 39/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9692 - loss: 0.0257 - val_accuracy: 0.9626 - val_loss: 0.0251\n",
            "Epoch 40/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9692 - loss: 0.0256 - val_accuracy: 0.9644 - val_loss: 0.0231\n",
            "Epoch 41/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9702 - loss: 0.0257 - val_accuracy: 0.9662 - val_loss: 0.0233\n",
            "Epoch 42/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9687 - loss: 0.0261 - val_accuracy: 0.9685 - val_loss: 0.0226\n",
            "Epoch 43/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9698 - loss: 0.0258 - val_accuracy: 0.9688 - val_loss: 0.0216\n",
            "Epoch 43: early stopping\n",
            "Restoring model weights from the end of the best epoch: 33.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.6211  Acc: 0.9756\n",
            "  Fair F1 (val-chosen threshold=0.423): 0.6294  Acc: 0.9708\n",
            "\n",
            "============================================================\n",
            "Test subject: 8f0ce2c4-d123-4c1c-aac2-61844abfa8ca\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 66ms/step - accuracy: 0.9388 - loss: 0.0542 - val_accuracy: 0.9598 - val_loss: 0.0301\n",
            "Epoch 2/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9562 - loss: 0.0405 - val_accuracy: 0.9602 - val_loss: 0.0319\n",
            "Epoch 3/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9595 - loss: 0.0373 - val_accuracy: 0.9640 - val_loss: 0.0282\n",
            "Epoch 4/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9594 - loss: 0.0367 - val_accuracy: 0.9641 - val_loss: 0.0290\n",
            "Epoch 5/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 69ms/step - accuracy: 0.9606 - loss: 0.0354 - val_accuracy: 0.9624 - val_loss: 0.0280\n",
            "Epoch 6/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9627 - loss: 0.0338 - val_accuracy: 0.9623 - val_loss: 0.0265\n",
            "Epoch 7/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9629 - loss: 0.0336 - val_accuracy: 0.9641 - val_loss: 0.0255\n",
            "Epoch 8/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9635 - loss: 0.0325 - val_accuracy: 0.9651 - val_loss: 0.0266\n",
            "Epoch 9/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9627 - loss: 0.0323 - val_accuracy: 0.9649 - val_loss: 0.0301\n",
            "Epoch 10/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9635 - loss: 0.0325 - val_accuracy: 0.9652 - val_loss: 0.0263\n",
            "Epoch 11/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9639 - loss: 0.0319 - val_accuracy: 0.9635 - val_loss: 0.0256\n",
            "Epoch 12/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 69ms/step - accuracy: 0.9642 - loss: 0.0311 - val_accuracy: 0.9640 - val_loss: 0.0249\n",
            "Epoch 13/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9653 - loss: 0.0306 - val_accuracy: 0.9598 - val_loss: 0.0286\n",
            "Epoch 14/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9651 - loss: 0.0307 - val_accuracy: 0.9675 - val_loss: 0.0239\n",
            "Epoch 15/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9652 - loss: 0.0298 - val_accuracy: 0.9659 - val_loss: 0.0253\n",
            "Epoch 16/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9658 - loss: 0.0306 - val_accuracy: 0.9656 - val_loss: 0.0256\n",
            "Epoch 17/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9650 - loss: 0.0302 - val_accuracy: 0.9662 - val_loss: 0.0236\n",
            "Epoch 18/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9664 - loss: 0.0294 - val_accuracy: 0.9652 - val_loss: 0.0244\n",
            "Epoch 19/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9667 - loss: 0.0296 - val_accuracy: 0.9664 - val_loss: 0.0245\n",
            "Epoch 20/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9666 - loss: 0.0289 - val_accuracy: 0.9676 - val_loss: 0.0231\n",
            "Epoch 21/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9668 - loss: 0.0284 - val_accuracy: 0.9652 - val_loss: 0.0238\n",
            "Epoch 22/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9660 - loss: 0.0281 - val_accuracy: 0.9671 - val_loss: 0.0233\n",
            "Epoch 23/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9668 - loss: 0.0285 - val_accuracy: 0.9665 - val_loss: 0.0241\n",
            "Epoch 24/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9663 - loss: 0.0283 - val_accuracy: 0.9673 - val_loss: 0.0237\n",
            "Epoch 25/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9662 - loss: 0.0279 - val_accuracy: 0.9685 - val_loss: 0.0227\n",
            "Epoch 26/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9670 - loss: 0.0279 - val_accuracy: 0.9673 - val_loss: 0.0229\n",
            "Epoch 27/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 69ms/step - accuracy: 0.9669 - loss: 0.0282 - val_accuracy: 0.9688 - val_loss: 0.0235\n",
            "Epoch 28/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9675 - loss: 0.0280 - val_accuracy: 0.9683 - val_loss: 0.0229\n",
            "Epoch 29/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9685 - loss: 0.0282 - val_accuracy: 0.9668 - val_loss: 0.0250\n",
            "Epoch 30/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9667 - loss: 0.0285 - val_accuracy: 0.9678 - val_loss: 0.0241\n",
            "Epoch 31/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9688 - loss: 0.0273 - val_accuracy: 0.9640 - val_loss: 0.0252\n",
            "Epoch 32/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9676 - loss: 0.0263 - val_accuracy: 0.9681 - val_loss: 0.0231\n",
            "Epoch 33/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9685 - loss: 0.0272 - val_accuracy: 0.9666 - val_loss: 0.0233\n",
            "Epoch 34/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9685 - loss: 0.0263 - val_accuracy: 0.9689 - val_loss: 0.0224\n",
            "Epoch 35/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9681 - loss: 0.0260 - val_accuracy: 0.9702 - val_loss: 0.0223\n",
            "Epoch 36/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9685 - loss: 0.0265 - val_accuracy: 0.9650 - val_loss: 0.0237\n",
            "Epoch 37/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9693 - loss: 0.0265 - val_accuracy: 0.9644 - val_loss: 0.0248\n",
            "Epoch 38/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9687 - loss: 0.0264 - val_accuracy: 0.9689 - val_loss: 0.0224\n",
            "Epoch 39/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9691 - loss: 0.0256 - val_accuracy: 0.9677 - val_loss: 0.0225\n",
            "Epoch 40/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9696 - loss: 0.0261 - val_accuracy: 0.9678 - val_loss: 0.0225\n",
            "Epoch 41/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9692 - loss: 0.0259 - val_accuracy: 0.9641 - val_loss: 0.0246\n",
            "Epoch 42/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9690 - loss: 0.0262 - val_accuracy: 0.9686 - val_loss: 0.0223\n",
            "Epoch 43/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9691 - loss: 0.0256 - val_accuracy: 0.9691 - val_loss: 0.0224\n",
            "Epoch 44/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9687 - loss: 0.0266 - val_accuracy: 0.9681 - val_loss: 0.0220\n",
            "Epoch 45/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9693 - loss: 0.0262 - val_accuracy: 0.9698 - val_loss: 0.0226\n",
            "Epoch 46/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9697 - loss: 0.0262 - val_accuracy: 0.9694 - val_loss: 0.0218\n",
            "Epoch 47/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9692 - loss: 0.0256 - val_accuracy: 0.9659 - val_loss: 0.0251\n",
            "Epoch 48/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9700 - loss: 0.0259 - val_accuracy: 0.9619 - val_loss: 0.0254\n",
            "Epoch 49/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9698 - loss: 0.0252 - val_accuracy: 0.9659 - val_loss: 0.0237\n",
            "Epoch 50/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9703 - loss: 0.0253 - val_accuracy: 0.9690 - val_loss: 0.0236\n",
            "Epoch 51/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9701 - loss: 0.0262 - val_accuracy: 0.9673 - val_loss: 0.0241\n",
            "Epoch 52/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 68ms/step - accuracy: 0.9701 - loss: 0.0256 - val_accuracy: 0.9686 - val_loss: 0.0233\n",
            "Epoch 53/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9698 - loss: 0.0253 - val_accuracy: 0.9691 - val_loss: 0.0224\n",
            "Epoch 54/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9707 - loss: 0.0249 - val_accuracy: 0.9695 - val_loss: 0.0234\n",
            "Epoch 55/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9710 - loss: 0.0241 - val_accuracy: 0.9667 - val_loss: 0.0232\n",
            "Epoch 56/100\n",
            "\u001b[1m1143/1143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9704 - loss: 0.0247 - val_accuracy: 0.9695 - val_loss: 0.0224\n",
            "Epoch 56: early stopping\n",
            "Restoring model weights from the end of the best epoch: 46.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.8060  Acc: 0.9861\n",
            "  Fair F1 (val-chosen threshold=0.444): 0.7788  Acc: 0.9822\n",
            "\n",
            "============================================================\n",
            "Test subject: Participant_1_Data_4\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 65ms/step - accuracy: 0.9403 - loss: 0.0547 - val_accuracy: 0.9586 - val_loss: 0.0316\n",
            "Epoch 2/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9575 - loss: 0.0385 - val_accuracy: 0.9622 - val_loss: 0.0310\n",
            "Epoch 3/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9603 - loss: 0.0355 - val_accuracy: 0.9663 - val_loss: 0.0275\n",
            "Epoch 4/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9624 - loss: 0.0335 - val_accuracy: 0.9647 - val_loss: 0.0252\n",
            "Epoch 5/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9622 - loss: 0.0321 - val_accuracy: 0.9640 - val_loss: 0.0250\n",
            "Epoch 6/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9649 - loss: 0.0320 - val_accuracy: 0.9609 - val_loss: 0.0272\n",
            "Epoch 7/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9640 - loss: 0.0316 - val_accuracy: 0.9635 - val_loss: 0.0250\n",
            "Epoch 8/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9652 - loss: 0.0305 - val_accuracy: 0.9684 - val_loss: 0.0237\n",
            "Epoch 9/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9652 - loss: 0.0296 - val_accuracy: 0.9674 - val_loss: 0.0234\n",
            "Epoch 10/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9652 - loss: 0.0295 - val_accuracy: 0.9678 - val_loss: 0.0260\n",
            "Epoch 11/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9653 - loss: 0.0293 - val_accuracy: 0.9674 - val_loss: 0.0244\n",
            "Epoch 12/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9653 - loss: 0.0289 - val_accuracy: 0.9680 - val_loss: 0.0237\n",
            "Epoch 13/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9654 - loss: 0.0290 - val_accuracy: 0.9688 - val_loss: 0.0239\n",
            "Epoch 14/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9672 - loss: 0.0283 - val_accuracy: 0.9675 - val_loss: 0.0236\n",
            "Epoch 15/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9665 - loss: 0.0281 - val_accuracy: 0.9620 - val_loss: 0.0262\n",
            "Epoch 16/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9667 - loss: 0.0278 - val_accuracy: 0.9657 - val_loss: 0.0244\n",
            "Epoch 17/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9681 - loss: 0.0270 - val_accuracy: 0.9654 - val_loss: 0.0243\n",
            "Epoch 18/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9666 - loss: 0.0273 - val_accuracy: 0.9653 - val_loss: 0.0255\n",
            "Epoch 19/100\n",
            "\u001b[1m1159/1159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9679 - loss: 0.0272 - val_accuracy: 0.9657 - val_loss: 0.0259\n",
            "Epoch 19: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.2124  Acc: 0.9588\n",
            "  Fair F1 (val-chosen threshold=0.392): 0.5500  Acc: 0.9584\n",
            "\n",
            "============================================================\n",
            "Test subject: Participant_3_Data_1\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 63ms/step - accuracy: 0.9382 - loss: 0.0548 - val_accuracy: 0.9636 - val_loss: 0.0297\n",
            "Epoch 2/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9573 - loss: 0.0385 - val_accuracy: 0.9633 - val_loss: 0.0310\n",
            "Epoch 3/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9600 - loss: 0.0351 - val_accuracy: 0.9657 - val_loss: 0.0237\n",
            "Epoch 4/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9631 - loss: 0.0331 - val_accuracy: 0.9650 - val_loss: 0.0253\n",
            "Epoch 5/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9619 - loss: 0.0334 - val_accuracy: 0.9676 - val_loss: 0.0234\n",
            "Epoch 6/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9644 - loss: 0.0314 - val_accuracy: 0.9611 - val_loss: 0.0257\n",
            "Epoch 7/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9638 - loss: 0.0305 - val_accuracy: 0.9647 - val_loss: 0.0253\n",
            "Epoch 8/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9644 - loss: 0.0306 - val_accuracy: 0.9673 - val_loss: 0.0259\n",
            "Epoch 9/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 68ms/step - accuracy: 0.9661 - loss: 0.0293 - val_accuracy: 0.9594 - val_loss: 0.0272\n",
            "Epoch 10/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9651 - loss: 0.0288 - val_accuracy: 0.9661 - val_loss: 0.0236\n",
            "Epoch 11/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 68ms/step - accuracy: 0.9666 - loss: 0.0296 - val_accuracy: 0.9662 - val_loss: 0.0245\n",
            "Epoch 12/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9663 - loss: 0.0291 - val_accuracy: 0.9691 - val_loss: 0.0220\n",
            "Epoch 13/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9664 - loss: 0.0290 - val_accuracy: 0.9696 - val_loss: 0.0215\n",
            "Epoch 14/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9656 - loss: 0.0289 - val_accuracy: 0.9657 - val_loss: 0.0235\n",
            "Epoch 15/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9663 - loss: 0.0285 - val_accuracy: 0.9653 - val_loss: 0.0248\n",
            "Epoch 16/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 69ms/step - accuracy: 0.9664 - loss: 0.0276 - val_accuracy: 0.9687 - val_loss: 0.0216\n",
            "Epoch 17/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9665 - loss: 0.0277 - val_accuracy: 0.9694 - val_loss: 0.0226\n",
            "Epoch 18/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9675 - loss: 0.0273 - val_accuracy: 0.9677 - val_loss: 0.0228\n",
            "Epoch 19/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9676 - loss: 0.0276 - val_accuracy: 0.9694 - val_loss: 0.0240\n",
            "Epoch 20/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9681 - loss: 0.0279 - val_accuracy: 0.9678 - val_loss: 0.0224\n",
            "Epoch 21/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9681 - loss: 0.0260 - val_accuracy: 0.9239 - val_loss: 0.0383\n",
            "Epoch 22/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9681 - loss: 0.0265 - val_accuracy: 0.9692 - val_loss: 0.0222\n",
            "Epoch 23/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9679 - loss: 0.0265 - val_accuracy: 0.9702 - val_loss: 0.0214\n",
            "Epoch 24/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9682 - loss: 0.0273 - val_accuracy: 0.9698 - val_loss: 0.0213\n",
            "Epoch 25/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9690 - loss: 0.0260 - val_accuracy: 0.9679 - val_loss: 0.0223\n",
            "Epoch 26/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9682 - loss: 0.0264 - val_accuracy: 0.9687 - val_loss: 0.0225\n",
            "Epoch 27/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9675 - loss: 0.0260 - val_accuracy: 0.9660 - val_loss: 0.0231\n",
            "Epoch 28/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9686 - loss: 0.0262 - val_accuracy: 0.9657 - val_loss: 0.0235\n",
            "Epoch 29/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 69ms/step - accuracy: 0.9691 - loss: 0.0258 - val_accuracy: 0.9693 - val_loss: 0.0214\n",
            "Epoch 30/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9695 - loss: 0.0254 - val_accuracy: 0.9707 - val_loss: 0.0220\n",
            "Epoch 31/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9698 - loss: 0.0254 - val_accuracy: 0.9696 - val_loss: 0.0209\n",
            "Epoch 32/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 69ms/step - accuracy: 0.9684 - loss: 0.0264 - val_accuracy: 0.9671 - val_loss: 0.0227\n",
            "Epoch 33/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9676 - loss: 0.0266 - val_accuracy: 0.9675 - val_loss: 0.0226\n",
            "Epoch 34/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9691 - loss: 0.0255 - val_accuracy: 0.9702 - val_loss: 0.0214\n",
            "Epoch 35/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9690 - loss: 0.0246 - val_accuracy: 0.9627 - val_loss: 0.0239\n",
            "Epoch 36/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 68ms/step - accuracy: 0.9690 - loss: 0.0248 - val_accuracy: 0.9648 - val_loss: 0.0223\n",
            "Epoch 37/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9675 - loss: 0.0258 - val_accuracy: 0.9642 - val_loss: 0.0226\n",
            "Epoch 38/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9695 - loss: 0.0246 - val_accuracy: 0.9705 - val_loss: 0.0211\n",
            "Epoch 39/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9697 - loss: 0.0250 - val_accuracy: 0.9662 - val_loss: 0.0234\n",
            "Epoch 40/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9690 - loss: 0.0254 - val_accuracy: 0.9699 - val_loss: 0.0213\n",
            "Epoch 41/100\n",
            "\u001b[1m1161/1161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9702 - loss: 0.0245 - val_accuracy: 0.9648 - val_loss: 0.0235\n",
            "Epoch 41: early stopping\n",
            "Restoring model weights from the end of the best epoch: 31.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.4819  Acc: 0.9588\n",
            "  Fair F1 (val-chosen threshold=0.462): 0.4467  Acc: 0.9478\n",
            "\n",
            "============================================================\n",
            "Test subject: a43187d2-c663-42c5-8da5-750dbb9b72bd\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 62ms/step - accuracy: 0.9377 - loss: 0.0553 - val_accuracy: 0.9612 - val_loss: 0.0298\n",
            "Epoch 2/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9568 - loss: 0.0402 - val_accuracy: 0.9636 - val_loss: 0.0278\n",
            "Epoch 3/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9599 - loss: 0.0357 - val_accuracy: 0.9593 - val_loss: 0.0276\n",
            "Epoch 4/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9618 - loss: 0.0339 - val_accuracy: 0.9643 - val_loss: 0.0253\n",
            "Epoch 5/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9624 - loss: 0.0329 - val_accuracy: 0.9640 - val_loss: 0.0252\n",
            "Epoch 6/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9629 - loss: 0.0329 - val_accuracy: 0.9627 - val_loss: 0.0259\n",
            "Epoch 7/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9627 - loss: 0.0325 - val_accuracy: 0.9637 - val_loss: 0.0271\n",
            "Epoch 8/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9632 - loss: 0.0326 - val_accuracy: 0.9657 - val_loss: 0.0256\n",
            "Epoch 9/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9625 - loss: 0.0320 - val_accuracy: 0.9665 - val_loss: 0.0237\n",
            "Epoch 10/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9633 - loss: 0.0320 - val_accuracy: 0.9663 - val_loss: 0.0242\n",
            "Epoch 11/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9656 - loss: 0.0310 - val_accuracy: 0.9672 - val_loss: 0.0278\n",
            "Epoch 12/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9641 - loss: 0.0308 - val_accuracy: 0.9400 - val_loss: 0.0375\n",
            "Epoch 13/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9641 - loss: 0.0306 - val_accuracy: 0.9673 - val_loss: 0.0235\n",
            "Epoch 14/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9650 - loss: 0.0312 - val_accuracy: 0.9671 - val_loss: 0.0243\n",
            "Epoch 15/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9637 - loss: 0.0309 - val_accuracy: 0.9650 - val_loss: 0.0273\n",
            "Epoch 16/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9649 - loss: 0.0297 - val_accuracy: 0.9674 - val_loss: 0.0232\n",
            "Epoch 17/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9651 - loss: 0.0301 - val_accuracy: 0.9669 - val_loss: 0.0237\n",
            "Epoch 18/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9655 - loss: 0.0294 - val_accuracy: 0.9668 - val_loss: 0.0225\n",
            "Epoch 19/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9651 - loss: 0.0298 - val_accuracy: 0.9692 - val_loss: 0.0237\n",
            "Epoch 20/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9663 - loss: 0.0289 - val_accuracy: 0.9678 - val_loss: 0.0233\n",
            "Epoch 21/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9668 - loss: 0.0281 - val_accuracy: 0.9658 - val_loss: 0.0241\n",
            "Epoch 22/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9661 - loss: 0.0290 - val_accuracy: 0.9691 - val_loss: 0.0228\n",
            "Epoch 23/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9668 - loss: 0.0283 - val_accuracy: 0.9673 - val_loss: 0.0258\n",
            "Epoch 24/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9661 - loss: 0.0288 - val_accuracy: 0.9678 - val_loss: 0.0219\n",
            "Epoch 25/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9659 - loss: 0.0282 - val_accuracy: 0.9686 - val_loss: 0.0235\n",
            "Epoch 26/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9667 - loss: 0.0283 - val_accuracy: 0.9591 - val_loss: 0.0287\n",
            "Epoch 27/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9670 - loss: 0.0279 - val_accuracy: 0.9664 - val_loss: 0.0241\n",
            "Epoch 28/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9666 - loss: 0.0279 - val_accuracy: 0.9695 - val_loss: 0.0235\n",
            "Epoch 29/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9669 - loss: 0.0283 - val_accuracy: 0.9652 - val_loss: 0.0249\n",
            "Epoch 30/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9671 - loss: 0.0276 - val_accuracy: 0.9683 - val_loss: 0.0237\n",
            "Epoch 31/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9675 - loss: 0.0276 - val_accuracy: 0.9683 - val_loss: 0.0226\n",
            "Epoch 32/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9675 - loss: 0.0264 - val_accuracy: 0.9694 - val_loss: 0.0233\n",
            "Epoch 33/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9672 - loss: 0.0273 - val_accuracy: 0.9667 - val_loss: 0.0231\n",
            "Epoch 34/100\n",
            "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9676 - loss: 0.0275 - val_accuracy: 0.9629 - val_loss: 0.0262\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 24.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.8477  Acc: 0.9899\n",
            "  Fair F1 (val-chosen threshold=0.434): 0.8500  Acc: 0.9894\n",
            "\n",
            "============================================================\n",
            "Test subject: ab0a6b0c-b0f2-4bda-8806-a4e39175f027\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 64ms/step - accuracy: 0.9455 - loss: 0.0512 - val_accuracy: 0.9585 - val_loss: 0.0315\n",
            "Epoch 2/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9581 - loss: 0.0398 - val_accuracy: 0.9608 - val_loss: 0.0292\n",
            "Epoch 3/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9599 - loss: 0.0358 - val_accuracy: 0.9644 - val_loss: 0.0272\n",
            "Epoch 4/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9616 - loss: 0.0341 - val_accuracy: 0.9624 - val_loss: 0.0291\n",
            "Epoch 5/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9632 - loss: 0.0327 - val_accuracy: 0.9648 - val_loss: 0.0262\n",
            "Epoch 6/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9635 - loss: 0.0325 - val_accuracy: 0.9621 - val_loss: 0.0299\n",
            "Epoch 7/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9626 - loss: 0.0327 - val_accuracy: 0.9634 - val_loss: 0.0264\n",
            "Epoch 8/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9637 - loss: 0.0321 - val_accuracy: 0.9641 - val_loss: 0.0267\n",
            "Epoch 9/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9638 - loss: 0.0314 - val_accuracy: 0.9654 - val_loss: 0.0246\n",
            "Epoch 10/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9649 - loss: 0.0313 - val_accuracy: 0.9658 - val_loss: 0.0258\n",
            "Epoch 11/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9658 - loss: 0.0315 - val_accuracy: 0.9654 - val_loss: 0.0243\n",
            "Epoch 12/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9654 - loss: 0.0305 - val_accuracy: 0.9657 - val_loss: 0.0249\n",
            "Epoch 13/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9653 - loss: 0.0311 - val_accuracy: 0.9624 - val_loss: 0.0278\n",
            "Epoch 14/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9657 - loss: 0.0303 - val_accuracy: 0.9653 - val_loss: 0.0245\n",
            "Epoch 15/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9669 - loss: 0.0302 - val_accuracy: 0.9645 - val_loss: 0.0257\n",
            "Epoch 16/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9669 - loss: 0.0297 - val_accuracy: 0.9650 - val_loss: 0.0250\n",
            "Epoch 17/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9670 - loss: 0.0292 - val_accuracy: 0.9629 - val_loss: 0.0260\n",
            "Epoch 18/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9661 - loss: 0.0293 - val_accuracy: 0.9616 - val_loss: 0.0281\n",
            "Epoch 19/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9668 - loss: 0.0298 - val_accuracy: 0.9659 - val_loss: 0.0230\n",
            "Epoch 20/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9672 - loss: 0.0290 - val_accuracy: 0.9620 - val_loss: 0.0287\n",
            "Epoch 21/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9660 - loss: 0.0294 - val_accuracy: 0.9670 - val_loss: 0.0240\n",
            "Epoch 22/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9661 - loss: 0.0293 - val_accuracy: 0.9635 - val_loss: 0.0251\n",
            "Epoch 23/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9678 - loss: 0.0287 - val_accuracy: 0.9673 - val_loss: 0.0245\n",
            "Epoch 24/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9675 - loss: 0.0291 - val_accuracy: 0.9667 - val_loss: 0.0250\n",
            "Epoch 25/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9687 - loss: 0.0283 - val_accuracy: 0.9661 - val_loss: 0.0253\n",
            "Epoch 26/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9669 - loss: 0.0286 - val_accuracy: 0.9676 - val_loss: 0.0227\n",
            "Epoch 27/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9672 - loss: 0.0275 - val_accuracy: 0.9668 - val_loss: 0.0239\n",
            "Epoch 28/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9676 - loss: 0.0287 - val_accuracy: 0.9659 - val_loss: 0.0243\n",
            "Epoch 29/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9675 - loss: 0.0278 - val_accuracy: 0.9664 - val_loss: 0.0257\n",
            "Epoch 30/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9686 - loss: 0.0273 - val_accuracy: 0.9675 - val_loss: 0.0222\n",
            "Epoch 31/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9679 - loss: 0.0276 - val_accuracy: 0.9676 - val_loss: 0.0228\n",
            "Epoch 32/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9685 - loss: 0.0274 - val_accuracy: 0.9675 - val_loss: 0.0237\n",
            "Epoch 33/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9679 - loss: 0.0275 - val_accuracy: 0.9676 - val_loss: 0.0231\n",
            "Epoch 34/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9681 - loss: 0.0272 - val_accuracy: 0.9669 - val_loss: 0.0235\n",
            "Epoch 35/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9682 - loss: 0.0276 - val_accuracy: 0.9676 - val_loss: 0.0223\n",
            "Epoch 36/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9677 - loss: 0.0274 - val_accuracy: 0.9677 - val_loss: 0.0224\n",
            "Epoch 37/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9687 - loss: 0.0269 - val_accuracy: 0.9669 - val_loss: 0.0237\n",
            "Epoch 38/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9691 - loss: 0.0270 - val_accuracy: 0.9686 - val_loss: 0.0221\n",
            "Epoch 39/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9694 - loss: 0.0269 - val_accuracy: 0.9676 - val_loss: 0.0227\n",
            "Epoch 40/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9691 - loss: 0.0261 - val_accuracy: 0.9677 - val_loss: 0.0238\n",
            "Epoch 41/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9694 - loss: 0.0263 - val_accuracy: 0.9685 - val_loss: 0.0232\n",
            "Epoch 42/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9692 - loss: 0.0269 - val_accuracy: 0.9669 - val_loss: 0.0237\n",
            "Epoch 43/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9689 - loss: 0.0275 - val_accuracy: 0.9661 - val_loss: 0.0234\n",
            "Epoch 44/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9680 - loss: 0.0267 - val_accuracy: 0.9656 - val_loss: 0.0238\n",
            "Epoch 45/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9685 - loss: 0.0264 - val_accuracy: 0.9666 - val_loss: 0.0241\n",
            "Epoch 46/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9690 - loss: 0.0265 - val_accuracy: 0.9664 - val_loss: 0.0232\n",
            "Epoch 47/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9689 - loss: 0.0262 - val_accuracy: 0.9653 - val_loss: 0.0240\n",
            "Epoch 48/100\n",
            "\u001b[1m1152/1152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9690 - loss: 0.0265 - val_accuracy: 0.9682 - val_loss: 0.0227\n",
            "Epoch 48: early stopping\n",
            "Restoring model weights from the end of the best epoch: 38.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.5610  Acc: 0.9854\n",
            "  Fair F1 (val-chosen threshold=0.416): 0.7015  Acc: 0.9837\n",
            "\n",
            "============================================================\n",
            "Test subject: ebc39e6c-2770-4821-a747-c174a7855b30\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 65ms/step - accuracy: 0.9404 - loss: 0.0541 - val_accuracy: 0.9620 - val_loss: 0.0304\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9572 - loss: 0.0393 - val_accuracy: 0.9643 - val_loss: 0.0283\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9615 - loss: 0.0358 - val_accuracy: 0.9664 - val_loss: 0.0259\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9601 - loss: 0.0347 - val_accuracy: 0.9620 - val_loss: 0.0299\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9609 - loss: 0.0349 - val_accuracy: 0.9661 - val_loss: 0.0284\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9627 - loss: 0.0329 - val_accuracy: 0.9655 - val_loss: 0.0251\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9634 - loss: 0.0322 - val_accuracy: 0.9657 - val_loss: 0.0257\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9638 - loss: 0.0319 - val_accuracy: 0.9673 - val_loss: 0.0261\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9632 - loss: 0.0313 - val_accuracy: 0.9554 - val_loss: 0.0311\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9639 - loss: 0.0319 - val_accuracy: 0.9670 - val_loss: 0.0257\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9635 - loss: 0.0329 - val_accuracy: 0.9676 - val_loss: 0.0249\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - accuracy: 0.9632 - loss: 0.0319 - val_accuracy: 0.9669 - val_loss: 0.0263\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 70ms/step - accuracy: 0.9635 - loss: 0.0326 - val_accuracy: 0.9637 - val_loss: 0.0273\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - accuracy: 0.9639 - loss: 0.0313 - val_accuracy: 0.9671 - val_loss: 0.0248\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9645 - loss: 0.0311 - val_accuracy: 0.9679 - val_loss: 0.0235\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 65ms/step - accuracy: 0.9653 - loss: 0.0312 - val_accuracy: 0.9674 - val_loss: 0.0240\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9652 - loss: 0.0294 - val_accuracy: 0.9688 - val_loss: 0.0233\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9648 - loss: 0.0298 - val_accuracy: 0.9671 - val_loss: 0.0242\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9652 - loss: 0.0303 - val_accuracy: 0.9676 - val_loss: 0.0222\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9655 - loss: 0.0302 - val_accuracy: 0.9684 - val_loss: 0.0225\n",
            "Epoch 21/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9653 - loss: 0.0296 - val_accuracy: 0.9687 - val_loss: 0.0234\n",
            "Epoch 22/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9662 - loss: 0.0298 - val_accuracy: 0.9674 - val_loss: 0.0230\n",
            "Epoch 23/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9661 - loss: 0.0295 - val_accuracy: 0.9683 - val_loss: 0.0241\n",
            "Epoch 24/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9657 - loss: 0.0292 - val_accuracy: 0.9699 - val_loss: 0.0226\n",
            "Epoch 25/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9650 - loss: 0.0296 - val_accuracy: 0.9681 - val_loss: 0.0228\n",
            "Epoch 26/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9663 - loss: 0.0291 - val_accuracy: 0.9680 - val_loss: 0.0253\n",
            "Epoch 27/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9656 - loss: 0.0287 - val_accuracy: 0.9686 - val_loss: 0.0238\n",
            "Epoch 28/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9651 - loss: 0.0291 - val_accuracy: 0.9682 - val_loss: 0.0231\n",
            "Epoch 29/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9657 - loss: 0.0292 - val_accuracy: 0.9670 - val_loss: 0.0239\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 19.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.5472  Acc: 0.9806\n",
            "  Fair F1 (val-chosen threshold=0.401): 0.6234  Acc: 0.9765\n",
            "\n",
            "============================================================\n",
            "Test subject: ebff48bd-b1c8-44e3-af35-0941b6c405b1\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 64ms/step - accuracy: 0.9393 - loss: 0.0587 - val_accuracy: 0.9634 - val_loss: 0.0315\n",
            "Epoch 2/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9573 - loss: 0.0395 - val_accuracy: 0.9648 - val_loss: 0.0261\n",
            "Epoch 3/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9595 - loss: 0.0353 - val_accuracy: 0.9644 - val_loss: 0.0264\n",
            "Epoch 4/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9615 - loss: 0.0336 - val_accuracy: 0.9654 - val_loss: 0.0307\n",
            "Epoch 5/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9628 - loss: 0.0329 - val_accuracy: 0.9627 - val_loss: 0.0265\n",
            "Epoch 6/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9627 - loss: 0.0326 - val_accuracy: 0.9664 - val_loss: 0.0253\n",
            "Epoch 7/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9635 - loss: 0.0330 - val_accuracy: 0.9452 - val_loss: 0.0347\n",
            "Epoch 8/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9641 - loss: 0.0317 - val_accuracy: 0.9668 - val_loss: 0.0243\n",
            "Epoch 9/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9646 - loss: 0.0311 - val_accuracy: 0.9609 - val_loss: 0.0281\n",
            "Epoch 10/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9666 - loss: 0.0302 - val_accuracy: 0.9673 - val_loss: 0.0236\n",
            "Epoch 11/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9654 - loss: 0.0304 - val_accuracy: 0.9689 - val_loss: 0.0238\n",
            "Epoch 12/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9654 - loss: 0.0303 - val_accuracy: 0.9682 - val_loss: 0.0229\n",
            "Epoch 13/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9663 - loss: 0.0299 - val_accuracy: 0.9678 - val_loss: 0.0233\n",
            "Epoch 14/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9664 - loss: 0.0291 - val_accuracy: 0.9655 - val_loss: 0.0251\n",
            "Epoch 15/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9662 - loss: 0.0292 - val_accuracy: 0.9684 - val_loss: 0.0230\n",
            "Epoch 16/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9675 - loss: 0.0281 - val_accuracy: 0.9676 - val_loss: 0.0238\n",
            "Epoch 17/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9674 - loss: 0.0287 - val_accuracy: 0.9678 - val_loss: 0.0229\n",
            "Epoch 18/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9676 - loss: 0.0287 - val_accuracy: 0.9634 - val_loss: 0.0251\n",
            "Epoch 19/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9672 - loss: 0.0288 - val_accuracy: 0.9677 - val_loss: 0.0226\n",
            "Epoch 20/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9659 - loss: 0.0289 - val_accuracy: 0.9692 - val_loss: 0.0226\n",
            "Epoch 21/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9671 - loss: 0.0286 - val_accuracy: 0.9668 - val_loss: 0.0247\n",
            "Epoch 22/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9679 - loss: 0.0286 - val_accuracy: 0.9669 - val_loss: 0.0243\n",
            "Epoch 23/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9681 - loss: 0.0281 - val_accuracy: 0.9687 - val_loss: 0.0228\n",
            "Epoch 24/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9682 - loss: 0.0278 - val_accuracy: 0.9689 - val_loss: 0.0221\n",
            "Epoch 25/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9679 - loss: 0.0277 - val_accuracy: 0.9668 - val_loss: 0.0239\n",
            "Epoch 26/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9673 - val_loss: 0.0235\n",
            "Epoch 27/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9687 - loss: 0.0278 - val_accuracy: 0.9676 - val_loss: 0.0227\n",
            "Epoch 28/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9682 - loss: 0.0279 - val_accuracy: 0.9655 - val_loss: 0.0243\n",
            "Epoch 29/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9683 - loss: 0.0273 - val_accuracy: 0.9637 - val_loss: 0.0245\n",
            "Epoch 30/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9686 - loss: 0.0266 - val_accuracy: 0.9654 - val_loss: 0.0247\n",
            "Epoch 31/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9691 - loss: 0.0267 - val_accuracy: 0.9668 - val_loss: 0.0241\n",
            "Epoch 32/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9688 - loss: 0.0272 - val_accuracy: 0.9693 - val_loss: 0.0224\n",
            "Epoch 33/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9695 - loss: 0.0254 - val_accuracy: 0.9694 - val_loss: 0.0224\n",
            "Epoch 34/100\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 69ms/step - accuracy: 0.9696 - loss: 0.0255 - val_accuracy: 0.9615 - val_loss: 0.0267\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 24.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.2632  Acc: 0.9668\n",
            "  Fair F1 (val-chosen threshold=0.438): 0.5838  Acc: 0.9695\n",
            "\n",
            "============================================================\n",
            "Test subject: fa94190b-92d3-484c-8133-744b797dfc81\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 63ms/step - accuracy: 0.9407 - loss: 0.0541 - val_accuracy: 0.9649 - val_loss: 0.0288\n",
            "Epoch 2/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9541 - loss: 0.0406 - val_accuracy: 0.9664 - val_loss: 0.0255\n",
            "Epoch 3/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - accuracy: 0.9592 - loss: 0.0360 - val_accuracy: 0.9647 - val_loss: 0.0264\n",
            "Epoch 4/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9612 - loss: 0.0328 - val_accuracy: 0.9675 - val_loss: 0.0232\n",
            "Epoch 5/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9612 - loss: 0.0339 - val_accuracy: 0.9648 - val_loss: 0.0241\n",
            "Epoch 6/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9623 - loss: 0.0322 - val_accuracy: 0.9635 - val_loss: 0.0261\n",
            "Epoch 7/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9637 - loss: 0.0316 - val_accuracy: 0.9667 - val_loss: 0.0220\n",
            "Epoch 8/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9632 - loss: 0.0317 - val_accuracy: 0.9674 - val_loss: 0.0231\n",
            "Epoch 9/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9631 - loss: 0.0317 - val_accuracy: 0.9677 - val_loss: 0.0224\n",
            "Epoch 10/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9634 - loss: 0.0310 - val_accuracy: 0.9685 - val_loss: 0.0209\n",
            "Epoch 11/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9639 - loss: 0.0298 - val_accuracy: 0.9680 - val_loss: 0.0218\n",
            "Epoch 12/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9648 - loss: 0.0294 - val_accuracy: 0.9650 - val_loss: 0.0240\n",
            "Epoch 13/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 67ms/step - accuracy: 0.9647 - loss: 0.0297 - val_accuracy: 0.9659 - val_loss: 0.0227\n",
            "Epoch 14/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9645 - loss: 0.0298 - val_accuracy: 0.9642 - val_loss: 0.0273\n",
            "Epoch 15/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9653 - loss: 0.0299 - val_accuracy: 0.9687 - val_loss: 0.0219\n",
            "Epoch 16/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9657 - loss: 0.0289 - val_accuracy: 0.9660 - val_loss: 0.0234\n",
            "Epoch 17/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 67ms/step - accuracy: 0.9646 - loss: 0.0288 - val_accuracy: 0.9686 - val_loss: 0.0233\n",
            "Epoch 18/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9656 - loss: 0.0291 - val_accuracy: 0.9685 - val_loss: 0.0234\n",
            "Epoch 19/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - accuracy: 0.9658 - loss: 0.0282 - val_accuracy: 0.9678 - val_loss: 0.0231\n",
            "Epoch 20/100\n",
            "\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - accuracy: 0.9658 - loss: 0.0288 - val_accuracy: 0.9647 - val_loss: 0.0246\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Fair F1 (fixed 0.5 + median filter): 0.6196  Acc: 0.9720\n",
            "  Fair F1 (val-chosen threshold=0.407): 0.3695  Acc: 0.9141\n"
          ]
        }
      ],
      "source": [
        "all_y_test_list = []\n",
        "all_y_test_prob_list = []\n",
        "for test_subject in subjects:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Test subject: {test_subject}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    test_dfs = [df for df in labeled_dfs if df[\"subject\"].iloc[0] == test_subject]\n",
        "    train_dfs = [df for df in labeled_dfs if df[\"subject\"].iloc[0] != test_subject]\n",
        "\n",
        "    X_seq_train, X_feat_train, y_train = [], [], []\n",
        "    for df in train_dfs:\n",
        "        mag_seq, mag_feat, hum_feat, labels = create_windows(df, WINDOW_SIZE, STEP_SIZE)\n",
        "        X_seq_train.append(mag_seq)\n",
        "        X_feat_train.append(np.hstack([mag_feat, hum_feat]))\n",
        "        y_train.append(labels)\n",
        "    X_seq_train = np.concatenate(X_seq_train, axis=0)\n",
        "    X_feat_train = np.concatenate(X_feat_train, axis=0)\n",
        "    y_train = np.concatenate(y_train, axis=0)\n",
        "\n",
        "    X_seq_test, X_feat_test, y_test = [], [], []\n",
        "    for df in test_dfs:\n",
        "        mag_seq, mag_feat, hum_feat, labels = create_windows(df, WINDOW_SIZE, STEP_SIZE)\n",
        "        X_seq_test.append(mag_seq)\n",
        "        X_feat_test.append(np.hstack([mag_feat, hum_feat]))\n",
        "        y_test.append(labels)\n",
        "    X_seq_test = np.concatenate(X_seq_test, axis=0)\n",
        "    X_feat_test = np.concatenate(X_feat_test, axis=0)\n",
        "    y_test = np.concatenate(y_test, axis=0)\n",
        "\n",
        "    n_train = len(y_train)\n",
        "    val_size = int(n_train * VAL_FRACTION)\n",
        "    idx = np.arange(n_train)\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(idx)\n",
        "    train_idx, val_idx = idx[val_size:], idx[:val_size]\n",
        "\n",
        "    X_seq_tr, X_seq_val = X_seq_train[train_idx], X_seq_train[val_idx]\n",
        "    X_feat_tr, X_feat_val = X_feat_train[train_idx], X_feat_train[val_idx]\n",
        "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    scaler_seq = StandardScaler()\n",
        "    scaler_feat = StandardScaler()\n",
        "    X_seq_tr_flat = X_seq_tr.reshape(-1, X_seq_tr.shape[-1])\n",
        "    scaler_seq.fit(X_seq_tr_flat)\n",
        "    X_seq_tr = scaler_seq.transform(X_seq_tr_flat).reshape(X_seq_tr.shape)\n",
        "    X_seq_val = scaler_seq.transform(X_seq_val.reshape(-1, X_seq_val.shape[-1])).reshape(X_seq_val.shape)\n",
        "    X_seq_test_norm = scaler_seq.transform(X_seq_test.reshape(-1, X_seq_test.shape[-1])).reshape(X_seq_test.shape)\n",
        "    X_feat_tr = scaler_feat.fit_transform(X_feat_tr)\n",
        "    X_feat_val = scaler_feat.transform(X_feat_val)\n",
        "    X_feat_test_norm = scaler_feat.transform(X_feat_test)\n",
        "\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_tr), y=y_tr)\n",
        "    class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "    alpha = 1 - np.mean(y_tr)\n",
        "\n",
        "    sequence_shape = (X_seq_tr.shape[1], X_seq_tr.shape[2])\n",
        "    feature_dim = X_feat_tr.shape[1]\n",
        "    model = build_cnn_lstm_model(sequence_shape, feature_dim)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss=focal_loss(alpha=alpha, gamma=2.0), metrics=['accuracy'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "    model.fit(\n",
        "        [X_seq_tr, X_feat_tr], y_tr,\n",
        "        epochs=100, batch_size=32,\n",
        "        validation_data=([X_seq_val, X_feat_val], y_val),\n",
        "        class_weight=class_weight_dict, callbacks=[early_stopping], verbose=1\n",
        "    )\n",
        "\n",
        "    y_val_prob = model.predict([X_seq_val, X_feat_val], verbose=0)\n",
        "    if hasattr(y_val_prob, 'numpy'):\n",
        "        y_val_prob = y_val_prob.numpy().flatten()\n",
        "    else:\n",
        "        y_val_prob = np.array(y_val_prob).flatten()\n",
        "    optimal_threshold = threshold_from_validation(y_val, y_val_prob)\n",
        "\n",
        "    y_test_prob = model.predict([X_seq_test_norm, X_feat_test_norm], verbose=0)\n",
        "    if hasattr(y_test_prob, 'numpy'):\n",
        "        y_test_prob = y_test_prob.numpy().flatten()\n",
        "    else:\n",
        "        y_test_prob = np.array(y_test_prob).flatten()\n",
        "    all_y_test_list.append(y_test)\n",
        "    all_y_test_prob_list.append(y_test_prob)\n",
        "\n",
        "    y_pred_fixed = apply_fixed_pipeline(y_test_prob, threshold=FIXED_THRESHOLD, min_duration_samples=MIN_DURATION_SAMPLES, step_size=STEP_SIZE)\n",
        "    y_pred_val_threshold = apply_fixed_pipeline(y_test_prob, threshold=optimal_threshold, min_duration_samples=MIN_DURATION_SAMPLES, step_size=STEP_SIZE)\n",
        "\n",
        "    fair_f1_fixed = f1_score(y_test, y_pred_fixed)\n",
        "    fair_acc_fixed = accuracy_score(y_test, y_pred_fixed)\n",
        "    fair_f1_val = f1_score(y_test, y_pred_val_threshold)\n",
        "    fair_acc_val = accuracy_score(y_test, y_pred_val_threshold)\n",
        "\n",
        "    print(f\"  Fair F1 (fixed 0.5 + median filter): {fair_f1_fixed:.4f}  Acc: {fair_acc_fixed:.4f}\")\n",
        "    print(f\"  Fair F1 (val-chosen threshold={optimal_threshold:.3f}): {fair_f1_val:.4f}  Acc: {fair_acc_val:.4f}\")\n",
        "\n",
        "    results.append({\n",
        "        \"subject\": test_subject,\n",
        "        \"fair_f1_fixed\": fair_f1_fixed,\n",
        "        \"fair_acc_fixed\": fair_acc_fixed,\n",
        "        \"fair_f1_val_threshold\": fair_f1_val,\n",
        "        \"fair_acc_val_threshold\": fair_acc_val,\n",
        "        \"val_threshold\": optimal_threshold\n",
        "    })\n",
        "\n",
        "    model.save(os.path.join(save_model_path, f\"compare_fair_{test_subject}.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "FAIR F1 SUMMARY (scientifically comparable to paper)\n",
            "============================================================\n",
            "                                                     subject  fair_f1_fixed  fair_acc_fixed  fair_f1_val_threshold  fair_acc_val_threshold  val_threshold\n",
            "0   2024-12-04-18-49-30_c5c72868-633a-4672-8bdd-3a457f994ddb       0.140541        0.920777               0.476190                0.939711       0.397590\n",
            "1   2024-12-08-21-41-18_c1291a19-92af-431e-9608-6044389d26b0       0.075314        0.903662               0.456376                0.929381       0.395255\n",
            "2   2024-12-10-19-42-27_4734a243-b638-4004-aa82-c698f3ef7aba       0.032787        0.930040               0.285714                0.940711       0.438994\n",
            "3   2025-01-18-13-08-43_449ee30d-3245-47ca-9769-752cf0d2edb7       0.455696        0.964047               0.552941                0.968227       0.466603\n",
            "4   2025-01-18-22-38-29_37959204-490b-4cd9-b647-94e743071951       0.307692        0.963250               0.216867                0.893834       0.442708\n",
            "5   2025-01-19-18-41-39_c4d73c9a-93b2-4c1b-9f76-492d76f7731d       0.505495        0.979693               0.646617                0.978791       0.429009\n",
            "6   2025-01-19-19-48-01_c2031779-881c-4c5c-9c6e-b3f4d57601a9       0.460177        0.974370               0.597015                0.977311       0.418731\n",
            "7   2025-01-28-21-43-21_e4380fee-3c78-4e38-936f-acd60513e279       0.168224        0.969321               0.216667                0.967597       0.479947\n",
            "8                       34414785-1f38-4ff1-a709-e3bd0f5e7d42       0.805369        0.988273               0.764398                0.981803       0.439643\n",
            "9                       383ea87a-3396-400b-9497-ee6f9ad7c093       0.736842        0.987990               0.871429                0.992794       0.423162\n",
            "10                      6c516a60-1d5e-4d7c-a1dd-158099033fe7       0.841629        0.986424               0.774704                0.977890       0.441711\n",
            "11                      8bb7b2a8-0d9b-4aaa-ad3a-c15fedb2ad31       0.621118        0.975580               0.629442                0.970777       0.422540\n",
            "12                      8f0ce2c4-d123-4c1c-aac2-61844abfa8ca       0.805970        0.986111               0.778761                0.982194       0.444124\n",
            "13                                      Participant_1_Data_4       0.212389        0.958815               0.550000                0.958353       0.392313\n",
            "14                                      Participant_3_Data_1       0.481928        0.958832               0.446701                0.947822       0.462415\n",
            "15                      a43187d2-c663-42c5-8da5-750dbb9b72bd       0.847682        0.989886               0.850000                0.989446       0.434305\n",
            "16                      ab0a6b0c-b0f2-4bda-8806-a4e39175f027       0.560976        0.985366               0.701493                0.983740       0.415962\n",
            "17                      ebc39e6c-2770-4821-a747-c174a7855b30       0.547170        0.980567               0.623377                0.976518       0.400771\n",
            "18                      ebff48bd-b1c8-44e3-af35-0941b6c405b1       0.263158        0.966772               0.583784                0.969541       0.438386\n",
            "19                      fa94190b-92d3-484c-8133-744b797dfc81       0.619565        0.972022               0.369501                0.914069       0.406692\n",
            "\n",
            "--- Means ---\n",
            "Mean Fair F1 (fixed 0.5 + median filter):     0.4745\n",
            "Mean Fair F1 (validation-chosen threshold):   0.5696\n",
            "Mean Fair Accuracy (fixed):                   0.9671\n",
            "Mean Fair Accuracy (val threshold):           0.9620\n",
            "\n",
            "Results saved to /Users/sonalimanoharan/Desktop/scientific_research/hw/fair_model/compare_fair_f1_results.csv\n"
          ]
        }
      ],
      "source": [
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FAIR F1 SUMMARY (scientifically comparable to paper)\")\n",
        "print(\"=\"*60)\n",
        "print(df_results.to_string())\n",
        "print(\"\\n--- Means ---\")\n",
        "print(f\"Mean Fair F1 (fixed 0.5 + median filter):     {df_results['fair_f1_fixed'].mean():.4f}\")\n",
        "print(f\"Mean Fair F1 (validation-chosen threshold):   {df_results['fair_f1_val_threshold'].mean():.4f}\")\n",
        "print(f\"Mean Fair Accuracy (fixed):                   {df_results['fair_acc_fixed'].mean():.4f}\")\n",
        "print(f\"Mean Fair Accuracy (val threshold):           {df_results['fair_acc_val_threshold'].mean():.4f}\")\n",
        "df_results.to_csv(os.path.join(save_model_path, \"compare_fair_f1_results.csv\"), index=False)\n",
        "print(f\"\\nResults saved to {os.path.join(save_model_path, 'compare_fair_f1_results.csv')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'all_y_test_list' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ROC curve and optimal threshold (Youden: max sensitivity + specificity - 1)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_all = np.concatenate(\u001b[43mall_y_test_list\u001b[49m)\n\u001b[32m      3\u001b[39m prob_all = np.concatenate(all_y_test_prob_list)\n\u001b[32m      4\u001b[39m fpr, tpr, thresholds = roc_curve(y_all, prob_all)\n",
            "\u001b[31mNameError\u001b[39m: name 'all_y_test_list' is not defined"
          ]
        }
      ],
      "source": [
        "# ROC curve and optimal threshold (Youden: max sensitivity + specificity - 1)\n",
        "y_all = np.concatenate(all_y_test_list)\n",
        "prob_all = np.concatenate(all_y_test_prob_list)\n",
        "fpr, tpr, thresholds = roc_curve(y_all, prob_all)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "# Youden's J statistic\n",
        "J = tpr - fpr\n",
        "optimal_idx = np.argmax(J)\n",
        "optimal_threshold_youden = thresholds[optimal_idx]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "# Left: ROC curve with optimal point\n",
        "axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
        "axes[0].plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "axes[0].scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=80, zorder=5,\n",
        "                label=f\"Optimal threshold = {optimal_threshold_youden:.3f}\")\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('ROC Curve (pooled test across LOSO)')\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "# Right: Validation-chosen threshold per subject\n",
        "axes[1].bar(range(len(df_results)), df_results['val_threshold'], color='steelblue', alpha=0.8)\n",
        "axes[1].axhline(y=optimal_threshold_youden, color='red', linestyle='--', label=f'Youden optimal ({optimal_threshold_youden:.3f})')\n",
        "axes[1].set_xlabel('Subject index')\n",
        "axes[1].set_ylabel('Threshold')\n",
        "axes[1].set_title('Validation-chosen threshold per subject')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hw (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
